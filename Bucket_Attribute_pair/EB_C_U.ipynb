{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "from ftfy import fix_text\n",
    "# from util import UnitConversion, mapping_list_values, perl_to_posix\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 500\n",
    "from flashtext import KeywordProcessor\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import ast\n",
    "import warnings\n",
    "import regex as re\n",
    "warnings.filterwarnings('ignore')\n",
    "from decimal import *\n",
    "TWOPLACES = Decimal(10) ** -2\n",
    "from natsort import natsorted\n",
    "import ast\n",
    "import time\n",
    "today = time.strftime(\"%Y_%m_%d\")\n",
    "from enrich_dimensions.rounds import rounds, rounding_inch_feet,rounding_lbs,rounding_w,rounding_oz, rounding_lb,rounding_gal, re_extract, curate, round_string_float, clean_data,reg_ex,rounding_period_after_unit \n",
    "from enrich_dimensions.params import parameters, query_from_file\n",
    "from enrich_dimensions.query_file import query_from_file \n",
    "from enrich_dimensions.custom import custom_field \n",
    "\n",
    "\n",
    "def get_unique_list(material_list):\n",
    "    unique_list = []\n",
    "    for item in material_list:\n",
    "        if isinstance(item, str) and \"[\" in item and \"]\" in item:\n",
    "            item_values = ast.literal_eval(item)\n",
    "            unique_list.extend(item_values)\n",
    "        else:\n",
    "            unique_list.append(item)\n",
    "    return sorted(list(set(unique_list)))\n",
    "\n",
    "\n",
    "\n",
    "customer_id = '32'\n",
    "customer_name='%eddiebauer%'\n",
    "client='EB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Query of Curated Data\n",
      "461758\n"
     ]
    }
   ],
   "source": [
    "dateszs='2001-08-11'\n",
    "attribut='features'\n",
    "dateszs='2001-11-01'\n",
    "curation_col = f'Q:{attribut}'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribut':attribut}\n",
    "\n",
    "print('Start Query of Curated Data')\n",
    "cb = query_from_file(file_name='query/curated_all_attributes_date_family.sql', params=params)\n",
    "print(len(cb))\n",
    "\n",
    "fill_dict = cb.groupby('external_id')['buckets'].last().to_dict()\n",
    "cb['buckets'] = cb['buckets'].fillna(cb['external_id'].map(fill_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Attribute bucket Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "Number of attributes: 54\n",
      "\n",
      "Start Buckets\n",
      "0 Attribute: bag_style\n",
      "Number of SKUs for the attribute bag_style: 188\n",
      "Start Buckets\n",
      "1 Attribute: bed_size\n",
      "Number of SKUs for the attribute bed_size: 36\n",
      "Start Buckets\n",
      "2 Attribute: bedding_size\n",
      "Number of SKUs for the attribute bedding_size: 53\n",
      "Start Buckets\n",
      "3 Attribute: capacity_by_ounce\n",
      "Number of SKUs for the attribute capacity_by_ounce: 49\n",
      "Start Buckets\n",
      "4 Attribute: care\n",
      "Number of SKUs for the attribute care: 32109\n",
      "Start Buckets\n",
      "5 Attribute: closure\n",
      "Number of SKUs for the attribute closure: 37767\n",
      "Start Buckets\n",
      "6 Attribute: collar_style\n",
      "Number of SKUs for the attribute collar_style: 0\n",
      "Start Buckets\n",
      "7 Attribute: color\n",
      "Number of SKUs for the attribute color: 41310\n",
      "Start Buckets\n",
      "8 Attribute: drinkware_type\n",
      "Number of SKUs for the attribute drinkware_type: 67\n",
      "Start Buckets\n",
      "9 Attribute: fabric\n",
      "Number of SKUs for the attribute fabric: 38466\n",
      "Start Buckets\n",
      "10 Attribute: features\n",
      "Number of SKUs for the attribute features: 38104\n",
      "Buckets Effected: 1\n",
      "Number of SKUs to be wiped: 1\n",
      "\n",
      "\n",
      "Start Buckets\n",
      "11 Attribute: fill_power\n",
      "Number of SKUs for the attribute fill_power: 2880\n",
      "Start Buckets\n",
      "12 Attribute: frame_color\n",
      "Number of SKUs for the attribute frame_color: 68\n",
      "Start Buckets\n",
      "13 Attribute: glove_style\n",
      "Number of SKUs for the attribute glove_style: 135\n",
      "Start Buckets\n",
      "14 Attribute: hat_style\n",
      "Number of SKUs for the attribute hat_style: 77\n",
      "Start Buckets\n",
      "15 Attribute: insulation_type\n",
      "Number of SKUs for the attribute insulation_type: 4359\n",
      "Start Buckets\n",
      "16 Attribute: jacket_style\n",
      "Number of SKUs for the attribute jacket_style: 6288\n",
      "Start Buckets\n",
      "17 Attribute: length\n",
      "Number of SKUs for the attribute length: 21\n",
      "Start Buckets\n",
      "18 Attribute: lens_color\n",
      "Number of SKUs for the attribute lens_color: 55\n",
      "Start Buckets\n",
      "19 Attribute: lens_shape\n",
      "Number of SKUs for the attribute lens_shape: 2\n",
      "Start Buckets\n",
      "20 Attribute: lens_type\n",
      "Number of SKUs for the attribute lens_type: 66\n",
      "Start Buckets\n",
      "21 Attribute: lighting_type\n",
      "Number of SKUs for the attribute lighting_type: 17\n",
      "Start Buckets\n",
      "22 Attribute: liner_material\n",
      "Number of SKUs for the attribute liner_material: 701\n",
      "Start Buckets\n",
      "23 Attribute: luggage_size\n",
      "Number of SKUs for the attribute luggage_size: 19\n",
      "Start Buckets\n",
      "24 Attribute: lumens\n",
      "Number of SKUs for the attribute lumens: 13\n",
      "Start Buckets\n",
      "25 Attribute: material\n",
      "Number of SKUs for the attribute material: 676\n",
      "Start Buckets\n",
      "26 Attribute: metal_tone\n",
      "Number of SKUs for the attribute metal_tone: 28\n",
      "Start Buckets\n",
      "27 Attribute: neckline\n",
      "Number of SKUs for the attribute neckline: 9466\n",
      "Start Buckets\n",
      "28 Attribute: pack_size\n",
      "Number of SKUs for the attribute pack_size: 10\n",
      "Start Buckets\n",
      "29 Attribute: package_quantity\n",
      "Number of SKUs for the attribute package_quantity: 129\n",
      "Start Buckets\n",
      "30 Attribute: pant_style\n",
      "Number of SKUs for the attribute pant_style: 6573\n",
      "Start Buckets\n",
      "31 Attribute: pattern\n",
      "Number of SKUs for the attribute pattern: 18725\n",
      "Buckets Effected: 5\n",
      "Number of SKUs to be wiped: 263\n",
      "\n",
      "\n",
      "Start Buckets\n",
      "32 Attribute: product_type\n",
      "Number of SKUs for the attribute product_type: 40532\n",
      "Buckets Effected: 1\n",
      "Number of SKUs to be wiped: 3\n",
      "\n",
      "\n",
      "Start Buckets\n",
      "33 Attribute: season\n",
      "Number of SKUs for the attribute season: 16\n",
      "Start Buckets\n",
      "34 Attribute: shape\n",
      "Number of SKUs for the attribute shape: 58\n",
      "Start Buckets\n",
      "35 Attribute: shoe_style\n",
      "Number of SKUs for the attribute shoe_style: 1337\n",
      "Start Buckets\n",
      "36 Attribute: size\n",
      "Number of SKUs for the attribute size: 175\n",
      "Start Buckets\n",
      "37 Attribute: sleeve_length\n",
      "Number of SKUs for the attribute sleeve_length: 27552\n",
      "Start Buckets\n",
      "38 Attribute: sleeve_style\n",
      "Number of SKUs for the attribute sleeve_style: 1192\n",
      "Start Buckets\n",
      "39 Attribute: sock_style\n",
      "Number of SKUs for the attribute sock_style: 146\n",
      "Start Buckets\n",
      "40 Attribute: sole_material\n",
      "Number of SKUs for the attribute sole_material: 366\n",
      "Start Buckets\n",
      "41 Attribute: style\n",
      "Number of SKUs for the attribute style: 617\n",
      "Start Buckets\n",
      "42 Attribute: sustainability\n",
      "Number of SKUs for the attribute sustainability: 4657\n",
      "Start Buckets\n",
      "43 Attribute: technology\n",
      "Number of SKUs for the attribute technology: 10517\n",
      "Start Buckets\n",
      "44 Attribute: temperature_rating\n",
      "Number of SKUs for the attribute temperature_rating: 502\n",
      "Start Buckets\n",
      "45 Attribute: tent_capacity\n",
      "Number of SKUs for the attribute tent_capacity: 7\n",
      "Start Buckets\n",
      "46 Attribute: tent_type\n",
      "Number of SKUs for the attribute tent_type: 12\n",
      "Start Buckets\n",
      "47 Attribute: tight_style\n",
      "Number of SKUs for the attribute tight_style: 1099\n",
      "Start Buckets\n",
      "48 Attribute: tight_type\n",
      "Number of SKUs for the attribute tight_type: 2\n",
      "Start Buckets\n",
      "49 Attribute: toe_shape\n",
      "Number of SKUs for the attribute toe_shape: 1615\n",
      "Start Buckets\n",
      "50 Attribute: upf\n",
      "Number of SKUs for the attribute upf: 10524\n",
      "Start Buckets\n",
      "51 Attribute: upper_material\n",
      "Number of SKUs for the attribute upper_material: 276\n",
      "Start Buckets\n",
      "52 Attribute: wash\n",
      "Number of SKUs for the attribute wash: 5028\n",
      "Start Buckets\n",
      "53 Attribute: width\n",
      "Number of SKUs for the attribute width: 31\n"
     ]
    }
   ],
   "source": [
    "print(len(sorted(cb['attribute'].explode().value_counts().reset_index()['index'].to_list())))\n",
    "lst_attribute=sorted(cb['attribute'].explode().value_counts().reset_index()['index'].to_list())\n",
    "print('Number of attributes: '+str(len(lst_attribute)))\n",
    "print('')\n",
    "\n",
    "# lst_attribute=['color']\n",
    "for i in range(len(lst_attribute)):\n",
    "    attri=lst_attribute[i]\n",
    "    dateszs='2001-08-11'\n",
    "    attribut=attri\n",
    "    dateszs='2001-11-01'\n",
    "    curation_col = f'Q:{attribut}'\n",
    "    params = {'customer_id': customer_id,\n",
    "              'customer_name':customer_name,\n",
    "             'dateszs':dateszs,\n",
    "             'attribut':attribut}\n",
    "\n",
    "    print('Start Buckets')\n",
    "    print(str(i)+' Attribute: '+str(attri))\n",
    "    bucket_value = query_from_file(file_name='query/Bucket_Value_Strategy.sql', params=params)\n",
    "\n",
    "    brand=cb[(cb['value'].astype(str)!='[\"n/a\"]')&(cb['value'].astype(str)!='n/a')&(cb['attribute'].astype(str)==attri)]\n",
    "#     print('Number of SKUs for the attribute '+str(attri)+': '+str(len(brand)))\n",
    "    list_of_all_buckets=sorted(list(set(bucket_value['buckets'].to_list())))\n",
    "\n",
    "    brand=cb[(cb['value'].astype(str)!='[\"n/a\"]')&(cb['value'].astype(str)!='n/a')&(cb['attribute'].astype(str)==attri)]\n",
    "    print('Number of SKUs for the attribute '+str(attri)+': '+str(len(brand)))\n",
    "    list_of_all_buckets=sorted(list(set(bucket_value['buckets'].to_list())))\n",
    "\n",
    "    filtered_dfs = {}\n",
    "    b_lst=[]\n",
    "\n",
    "    for i in range(len(list_of_all_buckets)):\n",
    "\n",
    "        # values that are supposed to be in the buckets\n",
    "        action_bucket_values=bucket_value[bucket_value['buckets'].astype(str)==list_of_all_buckets[i]]['values'].to_list()\n",
    "\n",
    "        # values that are actually in the curation\n",
    "        action=brand[brand['buckets'].astype(str)==list_of_all_buckets[i]]['value'].to_list()\n",
    "\n",
    "        unique_values=get_unique_list(action)\n",
    "\n",
    "        target=[x for x in unique_values if x not in action_bucket_values]\n",
    "        if len(target) > 0:\n",
    "            target = target[0]\n",
    "            pat=f'''(?i)({target})|()'''\n",
    "            bucket_filtered_df=brand[brand['buckets'].astype(str)==list_of_all_buckets[i]]\n",
    "            bucket_filtered_df['match']=bucket_filtered_df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "            fil=bucket_filtered_df[bucket_filtered_df['match'].astype(str)!='[]']\n",
    "            filtered_dfs[list_of_all_buckets[i]] = fil\n",
    "            b_lst.append(list_of_all_buckets[i])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    b_lst[0:10]\n",
    "    valuez = {}\n",
    "    external_id_list=[]\n",
    "    for i in range(len(b_lst)):\n",
    "        valuez[b_lst[i]]=filtered_dfs[b_lst[i]][['external_id','value']]\n",
    "        external_id_list.append(filtered_dfs[b_lst[i]]['external_id'].tolist())\n",
    "    import itertools\n",
    "    flattened_list = list(itertools.chain.from_iterable(external_id_list))\n",
    "    if len(flattened_list)>0:\n",
    "        print('Buckets Effected: '+str(len(b_lst)))\n",
    "        df_name = f'match_{attri}'\n",
    "        data = {'external_id': flattened_list, f'Q:{attri}': '[]'}\n",
    "        df_dict = {df_name: pd.DataFrame(data)}\n",
    "        new_df = df_dict[df_name]\n",
    "        print('Number of SKUs to be wiped: '+str(len(new_df)))\n",
    "        print('')\n",
    "        print('')\n",
    "\n",
    "        def get_df_name(df):\n",
    "            name =[x for x in globals() if globals()[x] is df][0]\n",
    "            return name\n",
    "        def looks_good(customer, matches,attri): \n",
    "            drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "            matches.to_csv(f'{drive_path}/{client} --{get_df_name(matches)}match_{attri}-{today}.csv',index=False) \n",
    "        looks_good(client, new_df,attri) \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Freetext Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns = {\n",
    "#     'appliance_cubic_feet': r'(cu ft)|(n\\/a)|()',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_empty_matches(dataframe, attribute, pattern):\n",
    "    matches = dataframe[dataframe['attribute'].astype(str) == attribute]['value'].apply(lambda x: re_extract(pattern,str(x)))\n",
    "    empty_matches = matches.apply(lambda x: len(x) == 0)\n",
    "    return dataframe[dataframe['attribute'].astype(str) == attribute][empty_matches]\n",
    "\n",
    "def count_empty_matches(dataframe, attribute, pattern):\n",
    "    print(f'Number of SKUs for {attribute}: '+str(len(dataframe[dataframe['attribute'].astype(str) == attribute])))\n",
    "    matches = dataframe[dataframe['attribute'].astype(str) == attribute]['value'].apply(lambda x: re_extract(pattern,str(x)))\n",
    "    return sum(len(match) == 0 for match in matches)\n",
    "\n",
    "\n",
    "filtered_dataframes = {}\n",
    "for attribute, pattern in patterns.items():\n",
    "    filtered_dataframes[attribute] = filter_empty_matches(cb, attribute, pattern)\n",
    "    \n",
    "counts = {}\n",
    "for attribute, pattern in patterns.items():\n",
    "    counts[attribute] = count_empty_matches(cb, attribute, pattern)\n",
    "#     print(f'Rows that need to be wiped for {attribute}: '+f': {counts[attribute]}')\n",
    "   \n",
    "\n",
    "    try:\n",
    "        flattened_list = filtered_dataframes[attribute]['external_id'].to_list()\n",
    "        if len(flattened_list) > 0:\n",
    "            df_name = f'match_{attribute}'\n",
    "            data = {'external_id': flattened_list, f'Q:{attribute}': '[]'}\n",
    "            df_dict = {df_name: pd.DataFrame(data)}\n",
    "            new_df = df_dict[df_name]\n",
    "            print('Number of SKUs to be wiped: ' + str(len(new_df)))\n",
    "            print('')\n",
    "            print('')\n",
    "\n",
    "            def get_df_name(df):\n",
    "                name = [x for x in globals() if globals()[x] is df][0]\n",
    "                return name\n",
    "\n",
    "            def looks_good(customer, matches, attribute):\n",
    "                today = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n",
    "                drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload'\n",
    "                matches.to_csv(f'{drive_path}/{client} --{get_df_name(matches)}match_{attribute}-{today}.csv', index=False)\n",
    "            looks_good(client, new_df, attribute)\n",
    "            \n",
    "        else:\n",
    "            print('No SKUs to be wiped for ' + attribute)\n",
    "    except KeyError:\n",
    "        print('Error: DataFrame with name ' + df_name + ' does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncurated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "formatted_attribute = 'sustainability'\n",
    "buckets = \"\"\"Office Chairs\"\"\"\n",
    "\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_')\n",
    "value='%n/a%'\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "          'buckets': str(buckets.split('\\t'))[1:-1],\n",
    "          'value':value,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "\n",
    "\n",
    "df = query_from_file(file_name='./query/custom_fields.sql', params=params)\n",
    "print(len(df))\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# send to the folder for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, attribute,matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/{client} - {attribute}-{get_df_name(matches)}-{today}-matches.csv',index=False) \n",
    "    \n",
    "looks_good(client, attribute,matchesna,today)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, attribute,matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/{client} - {attribute}-{get_df_name(matches)}-{today}-matches.csv',index=False) \n",
    "    \n",
    "looks_good(client, attribute,matchesdiam,today)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

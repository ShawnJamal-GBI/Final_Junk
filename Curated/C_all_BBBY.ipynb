{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "from ftfy import fix_text\n",
    "# from util import UnitConversion, mapping_list_values, perl_to_posix\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_rows = 500\n",
    "from flashtext import KeywordProcessor\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 500\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from natsort import natsorted\n",
    "def query_from_file(file_name, params):\n",
    "    with open(f'{file_name}', mode='r') as f:\n",
    "        text = f.read()\n",
    "        query = text.format(**params)\n",
    "        return enrich_db(query)\n",
    "def re_extract(pattern, txt):\n",
    "    matches = re.findall(pattern, txt)\n",
    "    tmp_matches = []\n",
    "    for match in matches:\n",
    "        for tup in match:\n",
    "            if tup != '':\n",
    "                tmp_matches.append(tup)\n",
    "    return list(set(tmp_matches))\n",
    "import time\n",
    "today = time.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "import ast\n",
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A\n",
    "\n",
    "# importing the sys module\n",
    "import sys        \n",
    " \n",
    "# appending the directory of mod.py\n",
    "# in the sys.path list\n",
    "sys.path.append('C:/Users/groupby/Documents/GitHub/SQL Extract And Apply') \n",
    "from enrich_dimensions.rounds import rounds, rounding,re_extract, curate, round_string_float,reg_ex,clean_data#,rounding_kimball\n",
    "from enrich_dimensions.params import parameters, query_from_file\n",
    "from enrich_dimensions.query_file import query_from_file \n",
    "from enrich_dimensions.custom import custom_field \n",
    "\n",
    "def three(usa,reg):\n",
    "    trip=fr'''(?i){reg}|()''' \n",
    "    usa['m_name']=usa['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    usa['m_desc']=usa['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    usa['m_custom']=usa['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    imported=usa[(usa['m_name'].astype(str)!='[]')|(usa['m_desc'].astype(str)!='[]')|(usa['m_custom'].astype(str)!='[]')]\n",
    "    impor=usa[(usa['m_name'].astype(str)=='[]')&(usa['m_desc'].astype(str)=='[]')&(usa['m_custom'].astype(str)=='[]')]\n",
    "    print('values: '+str(len(imported)))\n",
    "    print('no values: '+str(len(impor)))\n",
    "    return imported,impor\n",
    "\n",
    "print('Done')\n",
    "# rounding(inside, 'Q:inside_diameter','a-eghj-lo-su-z*')\n",
    "\n",
    "# .apply(lambda x: re.sub(r'(\\s?(?<!\")(?=\\]))|(\"\")','\"',str(x))).apply(lambda x: re.sub(r'(\"\")','\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|(\\s?'\\s?(?=\\,))|((?<=\\,)\\s?'\\s?)''','\"',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_id = '26'\n",
    "# customer_name='%discountschoolsupply%'\n",
    "# dateszs='2001-08-11'\n",
    "# attribut='bed_bedding_size'\n",
    "\n",
    "\n",
    "# params = {'customer_id': customer_id,\n",
    "#           'customer_name':customer_name,\n",
    "#          'dateszs':dateszs,\n",
    "#          'attribute':attribut}\n",
    "# print('start')\n",
    "# dfs = query_from_file(file_name='../query/strategy_period.sql', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"customer_id: \"+str(customer_id))\n",
    "# print(\"customer_: \"+str(customer_name[1:-1]))\n",
    "# tripz='''([a-z](?<!st)\\.)|()''' \n",
    "# dfs['match']=dfs['curated_product_fields.value'].apply(lambda x: re_extract(tripz,str(x)))\n",
    "# dot=dfs[dfs['match'].astype(str)!='[]']\n",
    "# dot['attributes.snake_case_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "continuing\n"
     ]
    }
   ],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2001-08-11'\n",
    "attribut='rug_size'\n",
    "\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print('continuing')\n",
    "# dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "# print('dfs')\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# print('customs')\n",
    "# custom_field_df=pd.json_normalize(dfs['custom_fields'])\n",
    "# df=pd.concat([dfs.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(\\d+(?:''?|\")[\\sA-z]{0,10}(?:round|square))|((?:\\d+\\.|\\d+\\s?\\\\?\\'\\s?|\\d+\\s?\\\\?\\\"\\s?)?\\d+(?:[^\\w]{1,10}|.?inc?h?.?|.?fo?o?t\\.?)?x[^\\w]{0,10}\\d+\\s?(?:\\.\\d+\\\\?\\s?\"?|\\\\?\\s?\\'\\s?\\d+|\\\\?\\s?\"\\s?\\d*|.?inc?h?.?|.?fo?o?t\\.?)?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?4\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?5\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?6\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?7\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?8\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?9\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?10\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?11\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?12\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?1[3-9]\\'?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:2)((?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:[0-6]))?\\s?x\\s?(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:18|24)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:36)(?:\\\\?\\s?\"|\".?inch)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:36)(?:\\\\?\\s?\"|\".?inch)?[^\\w]?x[^\\w]?(?:18|24)(?:\\\\?\"|\"|.?inch)?[^\\w])|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)2\\s?(?:\\'|\\\\?\")?\\s?x\\s?3\\s?(?:\\'|\\\\?\")?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?(?:\\s[0-6])?)?[^\\w]?x[^\\w]?(?:[45])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s?[0-6])?))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)3\\s?(?:\\'|\\\\?\")?\\s?x\\s?5\\s?(?:\\'|\\\\?\")?)|((?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:66)(?:\\\\?\\s?\"|\".?inch)?)|([^\\w](?:66)(?:\\\\?\\s?\"|\".?inch)?^\\w]?x[^\\w]?(?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w])|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:1[0-1])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:9)(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:6)\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:[6-9|1[0-6]]))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11)(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11|7))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:10)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?[^\\w]?x[^\\w]?(?:3)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:3)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:3)'')|(SKU_SIZE[^\\w](0, 4)(?:3)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?[^\\w]?x[^\\w]?(?:4)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:4)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:4)'')|(SKU_SIZE[^\\w](0, 4)(?:4)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?[^\\w]?x[^\\w]?(?:5)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:5)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:5)'')|(SKU_SIZE[^\\w](0, 4)(?:5)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?[^\\w]?x[^\\w]?(?:6)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:6)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:6)'')|(SKU_SIZE[^\\w](0, 4)(?:6)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?[^\\w]?x[^\\w]?(?:7)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:7)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:7)'')|(SKU_SIZE[^\\w](0, 4)(?:7)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?[^\\w]?x[^\\w]?(?:8)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:8)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:8)'')|(SKU_SIZE[^\\w](0, 4)(?:8)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'9'')'''                            \n",
    "\n",
    "\n",
    "\n",
    "# pat=\"(\\d+(?:''?)[\\sA-z]{0,10}(?:round|square))\"\n",
    "\n",
    "\n",
    "def three(usa,reg):\n",
    "    print('Start')\n",
    "    trip=fr'''(?i){reg}|()''' \n",
    "    print('one')\n",
    "    usa['m_name']=usa['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "#     print('two')\n",
    "#     usa['m_desc']=usa['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "#     print('three')\n",
    "#     usa['m_custom']=usa['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    \n",
    "#     main=usa[(usa['m_name'].astype(str)!='[]')]\n",
    "#     middle=usa[(usa['m_name'].astype(str)=='[]')&((usa['m_desc'].astype(str)!='[]')|(usa['m_custom'].astype(str)!='[]'))]\n",
    "#     na=usa[(usa['m_name'].astype(str)=='[]')&(usa['m_desc'].astype(str)=='[]')&(usa['m_custom'].astype(str)=='[]')]\n",
    "#     print('')\n",
    "#     print('values: '+str(len(main)))\n",
    "#     print('No name but call outs: '+str(len(middle)))\n",
    "#     print('no values: '+str(len(na)))\n",
    "#     print('')\n",
    "    return usa\n",
    "\n",
    "# print(len(dfs))\n",
    "# pat='''(\\d+(?:''?|\")[\\sA-z]{0,10}(?:round|square))|((?:\\d+\\.|\\d+\\s?\\\\?\\'\\s?|\\d+\\s?\\\\?\\\"\\s?)?\\d+(?:[^\\w]{1,10}|.?inc?h?.?|.?fo?o?t\\.?)?x[^\\w]{0,10}\\d+\\s?(?:\\.\\d+\\\\?\\s?\"?|\\\\?\\s?\\'\\s?\\d+|\\\\?\\s?\"\\s?\\d*|.?inc?h?.?|.?fo?o?t\\.?)?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)'''                            \n",
    "# first=three(dfs[0:100000],pat)\n",
    "\n",
    "\n",
    "import time\n",
    "start_time=time.time()\n",
    "\n",
    "\n",
    "print(len(dfs))\n",
    "first=three(dfs[0:1000],pat)\n",
    "\n",
    "end_time=time.time()\n",
    "print(f\"Time Elaspsed: {end_time-start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def three(usa, reg):\n",
    "#     print('Start')\n",
    "#     trip = re.compile(fr'(?i){reg}|()')\n",
    "#     print('one')\n",
    "#     usa['m_custom'] = usa['custom_fields'].astype(str).str.findall(trip)\n",
    "#     usa['m_custom'] = usa['m_custom'].apply(lambda x: x if len(x) > 0 else [])\n",
    "#     usa['classification'] = ''\n",
    "#     usa.loc[usa['product_name'].astype(str).str.findall(trip).apply(len) > 0, 'classification'] = 'main'\n",
    "#     usa.loc[usa['classification'] == '', 'classification'] = 'middle'\n",
    "#     usa.loc[(usa['m_custom'].apply(len) == 0) & (usa['classification'] == 'middle'), 'classification'] = 'na'\n",
    "#     print('')\n",
    "#     print('values: ' + str(len(usa[usa['classification'] == 'main'])))\n",
    "#     print('No name but call outs: ' + str(len(usa[usa['classification'] == 'middle'])))\n",
    "#     print('no values: ' + str(len(usa[usa['classification'] == 'na'])))\n",
    "#     print('')\n",
    "#     return usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682282765.5877366\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "start_time=time.time()\n",
    "print(start_time)\n",
    "\n",
    "def re_extract(pat, text):\n",
    "    return re.findall(pat, text)\n",
    "\n",
    "def three_chunk(chunk, reg):\n",
    "    trip = re.compile(fr'(?i){reg}|()')\n",
    "    chunk['m_custom'] = chunk['custom_fields'].astype(str).str.findall(trip).apply(lambda x: x if x else [])\n",
    "    chunk['classification'] = ''\n",
    "    mask_main = chunk['product_name'].astype(str).str.contains(trip)\n",
    "    chunk.loc[mask_main, 'classification'] = 'main'\n",
    "    mask_middle = chunk['classification'].eq('')\n",
    "    mask_middle &= chunk['m_custom'].apply(len).eq(0)\n",
    "    chunk.loc[mask_middle, 'classification'] = 'middle'\n",
    "    chunk.loc[chunk['classification'].eq('middle') & chunk['m_custom'].apply(len).eq(0), 'classification'] = 'na'\n",
    "    return chunk\n",
    "\n",
    "def three(dfs, reg):\n",
    "    with Pool() as pool:\n",
    "        chunks = np.array_split(dfs, len(dfs)//100 + 1)\n",
    "        result_chunks = pool.starmap(three_chunk, [(chunk, reg) for chunk in chunks])\n",
    "    return pd.concat(result_chunks)\n",
    "\n",
    "first = three(dfs[0:1000], pat)\n",
    "\n",
    "\n",
    "end_time=time.time()\n",
    "print(f\"Time Elaspsed: {end_time-start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfs))\n",
    "pat='''(\\d+(?:''?|\")[\\sA-z]{0,10}(?:round|square))|((?:\\d+\\.|\\d+\\s?\\\\?\\'\\s?|\\d+\\s?\\\\?\\\"\\s?)?\\d+(?:[^\\w]{1,10}|.?inc?h?.?|.?fo?o?t\\.?)?x[^\\w]{0,10}\\d+\\s?(?:\\.\\d+\\\\?\\s?\"?|\\\\?\\s?\\'\\s?\\d+|\\\\?\\s?\"\\s?\\d*|.?inc?h?.?|.?fo?o?t\\.?)?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?4\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?5\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?6\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?7\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?8\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?9\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?10\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?11\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?12\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?1[3-9]\\'?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:2)((?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:[0-6]))?\\s?x\\s?(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:18|24)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:36)(?:\\\\?\\s?\"|\".?inch)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:36)(?:\\\\?\\s?\"|\".?inch)?[^\\w]?x[^\\w]?(?:18|24)(?:\\\\?\"|\"|.?inch)?[^\\w])|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)2\\s?(?:\\'|\\\\?\")?\\s?x\\s?3\\s?(?:\\'|\\\\?\")?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?(?:\\s[0-6])?)?[^\\w]?x[^\\w]?(?:[45])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s?[0-6])?))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)3\\s?(?:\\'|\\\\?\")?\\s?x\\s?5\\s?(?:\\'|\\\\?\")?)|((?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:66)(?:\\\\?\\s?\"|\".?inch)?)|([^\\w](?:66)(?:\\\\?\\s?\"|\".?inch)?^\\w]?x[^\\w]?(?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w])|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:1[0-1])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:9)(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:6)\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:[6-9|1[0-6]]))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11)(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11|7))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:10)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?[^\\w]?x[^\\w]?(?:3)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:3)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:3)'')|(SKU_SIZE[^\\w](0, 4)(?:3)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?[^\\w]?x[^\\w]?(?:4)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:4)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:4)'')|(SKU_SIZE[^\\w](0, 4)(?:4)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?[^\\w]?x[^\\w]?(?:5)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:5)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:5)'')|(SKU_SIZE[^\\w](0, 4)(?:5)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?[^\\w]?x[^\\w]?(?:6)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:6)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:6)'')|(SKU_SIZE[^\\w](0, 4)(?:6)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?[^\\w]?x[^\\w]?(?:7)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:7)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:7)'')|(SKU_SIZE[^\\w](0, 4)(?:7)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?[^\\w]?x[^\\w]?(?:8)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:8)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:8)'')|(SKU_SIZE[^\\w](0, 4)(?:8)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'9'')'''                            \n",
    "second=three(dfs[100000:200000],pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfs))\n",
    "pat='''(\\d+(?:''?|\")[\\sA-z]{0,10}(?:round|square))|((?:\\d+\\.|\\d+\\s?\\\\?\\'\\s?|\\d+\\s?\\\\?\\\"\\s?)?\\d+(?:[^\\w]{1,10}|.?inc?h?.?|.?fo?o?t\\.?)?x[^\\w]{0,10}\\d+\\s?(?:\\.\\d+\\\\?\\s?\"?|\\\\?\\s?\\'\\s?\\d+|\\\\?\\s?\"\\s?\\d*|.?inc?h?.?|.?fo?o?t\\.?)?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?4\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?5\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?6\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?7\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?8\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?9\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?10\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?11\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?12\\'?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?1[3-9]\\'?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:2)((?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:[0-6]))?\\s?x\\s?(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:18|24)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:36)(?:\\\\?\\s?\"|\".?inch)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:36)(?:\\\\?\\s?\"|\".?inch)?[^\\w]?x[^\\w]?(?:18|24)(?:\\\\?\"|\"|.?inch)?[^\\w])|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)2\\s?(?:\\'|\\\\?\")?\\s?x\\s?3\\s?(?:\\'|\\\\?\")?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?(?:\\s[0-6])?)?[^\\w]?x[^\\w]?(?:[45])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s?[0-6])?))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)3\\s?(?:\\'|\\\\?\")?\\s?x\\s?5\\s?(?:\\'|\\\\?\")?)|((?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:66)(?:\\\\?\\s?\"|\".?inch)?)|([^\\w](?:66)(?:\\\\?\\s?\"|\".?inch)?^\\w]?x[^\\w]?(?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w])|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:1[0-1])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:9)(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:6)\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:[6-9|1[0-6]]))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11)(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11|7))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:10)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?[^\\w]?x[^\\w]?(?:3)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:3)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:3)'')|(SKU_SIZE[^\\w](0, 4)(?:3)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?[^\\w]?x[^\\w]?(?:4)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:4)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:4)'')|(SKU_SIZE[^\\w](0, 4)(?:4)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?[^\\w]?x[^\\w]?(?:5)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:5)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:5)'')|(SKU_SIZE[^\\w](0, 4)(?:5)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?[^\\w]?x[^\\w]?(?:6)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:6)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:6)'')|(SKU_SIZE[^\\w](0, 4)(?:6)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?[^\\w]?x[^\\w]?(?:7)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:7)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:7)'')|(SKU_SIZE[^\\w](0, 4)(?:7)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?[^\\w]?x[^\\w]?(?:8)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:8)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:8)'')|(SKU_SIZE[^\\w](0, 4)(?:8)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))|((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'9'')'''                            \n",
    "third=three(dfs[200000:],pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "one\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 5, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'm_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3825\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3826\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3827\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'm_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6bead1ec4d28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# Apply the function to the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mfirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6bead1ec4d28>\u001b[0m in \u001b[0;36mthree\u001b[1;34m(usa, reg)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'one'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Extract the matching strings from each column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0musa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'm_name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'product_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0musa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'm_desc'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'long_desc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0musa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'm_custom'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'custom_fields'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3161\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3163\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3242\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3243\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3245\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3827\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3828\u001b[0m             \u001b[1;31m# This item wasn't present, just insert at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3829\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3830\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   1201\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_reshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         \u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[0;32m   2740\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2742\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    143\u001b[0m                 \u001b[1;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[1;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 5, placement implies 1"
     ]
    }
   ],
   "source": [
    "def three(usa, reg):\n",
    "    print('Start')\n",
    "    trip = fr'(?i){reg}|()'\n",
    "    print('one')\n",
    "    # Extract the matching strings from each column\n",
    "    usa['m_name'] = usa['product_name'].str.extract(trip, expand=False)\n",
    "    usa['m_desc'] = usa['long_desc'].str.extract(trip, expand=False)\n",
    "    usa['m_custom'] = usa['custom_fields'].str.extract(trip, expand=False)\n",
    "    \n",
    "    # Use boolean indexing to select the rows that match the conditions\n",
    "    main = usa[usa['m_name'].notnull()]\n",
    "    middle = usa[(usa['m_name'].isnull()) & \n",
    "                 (usa[['m_desc', 'm_custom']].astype(str).apply(lambda x: x.str.contains(reg, case=False)).any(axis=1))]\n",
    "    na = usa[(usa['m_name'].isnull()) & (usa['m_desc'].isnull()) & (usa['m_custom'].isnull())]\n",
    "    \n",
    "    print('')\n",
    "    print('values: ' + str(len(main)))\n",
    "    print('No name but call outs: ' + str(len(middle)))\n",
    "    print('no values: ' + str(len(na)))\n",
    "    print('')\n",
    "    return usa\n",
    "\n",
    "import time\n",
    "start_time=time.time()\n",
    "\n",
    "# Compile the regex pattern\n",
    "pat = re.compile(r'(\\d+(?:\\'|\")[\\sA-z]{0,10}(?:round|square))|((?:\\d+\\.|\\d+\\s?\\\\?\\'\\s?|\\d+\\s?\\\\?\\\"\\s?)?\\d+(?:[^\\w]{1,10}|.?inc?h?.?|.?fo?o?t\\.?)?x[^\\w]{0,10}\\d+\\s?(?:\\.\\d+\\\\?\\s?\"?|\\\\?\\s?\\'\\s?\\d+|\\\\?\\s?\"\\s?\\d*|.?inc?h?.?|.?fo?o?t\\.?)?)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:4)(?:(?:\\\\?\\'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|\\'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)')\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "first = three(dfs.iloc[:10000], pat.pattern)\n",
    "\n",
    "end_time=time.time()\n",
    "print(f\"Time Elaspsed: {end_time-start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2002-08-11'\n",
    "attribut='material'\n",
    "curation_col = f'Q:{attribut}'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribut':attribut}\n",
    "\n",
    "print('start')\n",
    "bucket_value = query_from_file(file_name='../query/Bucket_Value_Strategy.sql', params=params)\n",
    "\n",
    "lst=bucket_value['buckets'].explode().value_counts().reset_index()['index'].to_list()#.sort()\n",
    "# lst.sort()\n",
    "# lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_one_att(attribut):\n",
    "    customer_id = '5'\n",
    "    customer_name='%bedbathandbeyond%'\n",
    "    dateszs='2001-08-11'\n",
    "#     attribut='arm_style'\n",
    "\n",
    "\n",
    "    params = {'customer_id': customer_id,\n",
    "              'customer_name':customer_name,\n",
    "             'dateszs':dateszs,\n",
    "             'attribute':attribut}\n",
    "#     print('start')\n",
    "    dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "#     print('continuing')\n",
    "    # dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "    # print('dfs')\n",
    "    dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "    # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "#     print('customs')\n",
    "#     custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "#     df=pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "    return dfz\n",
    "\n",
    "def filters(df,pat):\n",
    "    df['match']=df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "    df_filtered=pd.DataFrame()\n",
    "    df_filtered=df.loc[df['match'].astype(str)!='[]']\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "continuing\n",
      "dfs\n",
      "customs\n"
     ]
    }
   ],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2001-08-11'\n",
    "attribut='arm_style'\n",
    "\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print('continuing')\n",
    "# dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "# print('dfs')\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "print('customs')\n",
    "custom_field_df=pd.json_normalize(dfs['custom_fields'])\n",
    "df=pd.concat([dfs.drop('custom_fields', axis=1), custom_field_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.google.com/spreadsheets/d/1ZLcEKIo5DAvoLzRd4iOTNfDDcy0gash_ZbSmSYy9hoA/edit#gid=891799168"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2001-10-01'\n",
    "dateszsz='2021-10-01'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'dateszsz':dateszsz}\n",
    "print('start')\n",
    "# dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "df_one = query_from_file(file_name='../query/curated_all_attributes_date_dates.sql', params=params)\n",
    "print(len(df_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2021-10-02'\n",
    "dateszsz='2022-10-02'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'dateszsz':dateszsz}\n",
    "print('start')\n",
    "# dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "df_two = query_from_file(file_name='../query/curated_all_attributes_date_dates.sql', params=params)\n",
    "print(len(df_two))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2022-10-03'\n",
    "dateszsz='2023-03-14'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'dateszsz':dateszsz}\n",
    "print('start')\n",
    "# dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "df_three = query_from_file(file_name='../query/curated_all_attributes_date_dates.sql', params=params)\n",
    "print(len(df_three))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_one.append(df_two).append(df_three)\n",
    "fill_dict = df.groupby('external_id')['buckets'].last().to_dict()\n",
    "df['buckets'] = df['buckets'].fillna(df['external_id'].map(fill_dict))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Attributes Finding Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_one_att_custom(attribut):\n",
    "    customer_id = '5'\n",
    "    customer_name='%bedbathandbeyond%'\n",
    "    dateszs='2001-08-11'\n",
    "#     attribut='arm_style'\n",
    "\n",
    "\n",
    "    params = {'customer_id': customer_id,\n",
    "              'customer_name':customer_name,\n",
    "             'dateszs':dateszs,\n",
    "             'attribute':attribut}\n",
    "#     print('start')\n",
    "    dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "#     print('continuing')\n",
    "    # dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "    # print('dfs')\n",
    "    # dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "    # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "#     print('customs')\n",
    "    custom_field_df=pd.json_normalize(dfs['custom_fields'])\n",
    "#     df=pd.concat([dfs.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att_custom('toy_age_range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n/a                                                          7652\n",
       "3+ Years                                                     2743\n",
       "[\"1 - 3 Years\",\"3+ Years\"]                                    982\n",
       "[\"0 - 6 Months\",\"1 - 3 Years\",\"3+ Years\",\"6 - 12 Months\"]     678\n",
       "[\"0 - 6 Months\",\"1 - 3 Years\",\"6 - 12 Months\"]                279\n",
       "[\"1 - 3 Years\",\"6 - 12 Months\"]                                84\n",
       "1 - 3 Years                                                    41\n",
       "[\"1 - 3 Years\",\"3+ Years\",\"6 - 12 Months\"]                     22\n",
       "[\"0 - 6 Months\",\"6 - 12 Months\"]                               11\n",
       "0 - 6 Months                                                    6\n",
       "6 - 12 Months                                                   1\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2811\n"
     ]
    }
   ],
   "source": [
    "pat='''(?i)((?<=Age_Requirements_Appropriateness'\\: )'.{0,30}(?='\\, '))|((?<=Age_Requirements_Appropriateness'\\: )'.{0,30}(?=\\}))|()'''\n",
    "df['match']=df['custom_fields'].apply(lambda x: re_extract(pat, str(x)))\n",
    "age=df.loc[df['match'].astype(str)!='[]']\n",
    "print(len(age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "age['matches']=age['match'].apply(lambda x: re.sub(r'(?i)((?<!\\- )(?<!\")(?<!to )(?<!\\.)(?<!\\d)(?:all ages|Birth to (?:(?:\\d{2,5}|[3-9]) years|\\d\\d\\d+ months|3[7-9] months|[4-9][0-9] months)|[0-6] months? and up|(?:0?[1-6] months?|0\\.[0-5] years?) to (?<!\\d)(?:[4-9] years|\\d\\d years|(?:\\d\\d\\d+ months|\\d\\d\\d+ years|[4-9]\\d+|(?:3[6-9]) months|[4-9]\\d months|\\d\\d\\d months))))','''0 - 6 Months\",\"6 - 12 Months\",\"1 - 3 Years\",\"3+ Years''',str(x)))                  \n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'''(?i)((?<!\\- )(?<!\")(?<!\\d)(?<!\\.)(?<!to )(?:(?:Birth|[0-6] months?) to (?:(?:1[0-8]|2[0-9]|3[0-6]) Months|[1-3] years?|1\\.5 years?)))''','''0 - 6 Months\",\"6 - 12 Months\",\"1 - 3 Years\"''',str(x)))\n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'''(?i)((?<!\\- )(?<!\")(?<!\\d)(?<!\\.)(?<!to )(?:(?:birth) to (?:[6-9] months|1[0-2] months|1 year)|0?[0-6] months? to (?:[0-9]|1[0-2]) months))''','''0 - 6 Months\",\"6 - 12 Months''',str(x)))\n",
    "\n",
    "\n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'''(?i)((?<!\\- )(?<!\")(?<!\\d)(?<!\\.)(?<!to )(?:(?:[1-3] years?|3[0-6] months|2[0-9] months|1[2-9] months) to (?:[3-9] years?|\\d\\d+ years|[1-3] years and up|\\d\\d\\d+ months|3[7-9] months|[4-9][0-9] months)))|(1\\.3\\+ years)|((?<!\\d)(?<!\\.)(?<!to )1\\.[0-9] years (?:and up|to (?:[3-9] years?|\\d\\d+ years|[1-3] years and up|\\d\\d\\d+ months|3[7-9] months|[4-9][0-9] months)))|((?<!\\- )(?<!\\d)(?<!\\.)(?<!to )[1-2] years and up)''','''1 - 3 Years\",\"3+ Years''',str(x)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'''(?i)((?<!\\- )(?<!\")(?<!\\d)(?<!\\.)(?<!to )(?:(?:[6-9] months|1[0-2] months) to (?:\\d\\d+ years|[4-9] years|(?:3[7-9]|4[0-9]|5[0-9]|6[0-9]|7[0-9]|8[0-9]|9[0-9]) months|\\d\\d\\d+ months)|(?:[6-9]|1[0-2]) months and up))''','''6 - 12 Months\",\"1 - 3 Years\",\"3+ Years''',str(x)))\n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'''(?i)((?<!\\- )(?<!\")(?<!\\d)(?<!\\.)(?<!to )(?:(?:[6-9] months|1[0-2] months|1 years?) to (?:1[3-9] months|2[0-9] months|3[0-6] months|[1-3] years?)|(?:[6-9] months|1[0-2] months|1 years?) to (?:1[3-9] months|3[0-6] months|2[0-9] months|[1-3] years?)))''','''6 - 12 Months\",\"1 - 3 Years''',str(x)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'''(?i)((?<!\\- )(?<!\")(?<!\\d)(?<!to )(?<!\\.)(?:(?:[0-6] months?|birth) to (?:[0-6] months?)))''','''0 - 6 Months''',str(x)))\n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'''(?i)((?<!\\- )(?<!\")(?<!\\d)(?<!\\.)(?<!to )(?:(?:[6-9] months|1[0-2] months) to (?:[6-9] months|1[0-2] months)))''','''6 - 12 Months''',str(x)))\n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'''(?i)((?<!\\- )(?<!\")(?<!\\d)(?<!\\.)(?<!to )(?:(?:1[2-9] months|2[0-9] months|3[0-6] months|[1-3]years?) to (?:1[2-9] months|2[0-9] months|3[0-6] months|[1-3] years?)|3 years|12 months)(?! to)(?! and up))''','''1 - 3 Years''',str(x)))\n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'(?i)((?<!\\- )(?<!\")(?<!\\d)(?<!\\.)(?<!to )(?:(?:[3-9] years|\\d\\d+ years|3[6-9] months|[4-9][0-9] months|\\d\\d\\d months) and up|(?:[3-9] years|\\d\\d years|3[6-9] months|[4-9][0-9] months) to (?:\\d+ years|[3-9] years|\\d\\d years|3[7-9] months|[4-9][0-9] months| and up|[6-9]\\d+ months|\\d\\d+ months)))','3+ Years',str(x)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "age['matches']=age['matches'].apply(lambda x: re.sub(r'''(\"')|(\"\")|('\")''','\"',str(x))).apply(lambda x: re.sub(r'''(\"\")''','\"',str(x))).apply(lambda x: re.sub(r'''(?i)(Years months)''','Years',str(x)))\n",
    "\n",
    "# .apply(lambda x: re.sub(r'''(?i)''','',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"1 - 3 Years\",\"3+ Years\"]                                   946\n",
       "[\"3+ Years\"]                                                 764\n",
       "[\"0 - 6 Months\",\"6 - 12 Months\",\"1 - 3 Years\",\"3+ Years\"]    675\n",
       "[\"0 - 6 Months\",\"6 - 12 Months\",\"1 - 3 Years\"]               273\n",
       "[\"6 - 12 Months\",\"1 - 3 Years\"]                               84\n",
       "[\"1 - 3 Years\"]                                               30\n",
       "[\"6 - 12 Months\",\"1 - 3 Years\",\"3+ Years\"]                    22\n",
       "[\"0 - 6 Months\",\"6 - 12 Months\"]                              11\n",
       "[\"0 - 6 Months\"]                                               6\n",
       "Name: matches, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age['matches'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "age['Q:toy_age_range']=age['matches']\n",
    "match_toy_age=age[['external_id','Q:toy_age_range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_toy_age{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_toy_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('arm_style')\n",
    "arm_style=df.loc[(df['attribute'].astype(str)=='arm_style')&((df['value'].astype(str)=='Cantilever')|(df['value'].astype(str)=='Curved')|(df['value'].astype(str)=='Flared')|(df['value'].astype(str)=='Roll Arm')|(df['value'].astype(str)=='Round')|(df['value'].astype(str)=='Sloping')|(df['value'].astype(str)=='Square')|(df['value'].astype(str)=='Straight')|(df['value'].astype(str)=='Track Arm'))]                    \n",
    "print(len(arm_style))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: value, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm_style['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_style['Q:arm_style']='n/a'\n",
    "match_arm_style=arm_style[['external_id','Q:arm_style']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_arm_style{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_arm_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arm_style\n",
    "Cantilever\n",
    "Curved\n",
    "Flared\n",
    "Roll Arm\n",
    "Round\n",
    "Sloping\n",
    "Square\n",
    "Straight\n",
    "Track Arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Armless\n",
    "English\n",
    "Key\n",
    "n/a\n",
    "Padded\n",
    "Panel\n",
    "Pleated\n",
    "Ruched\n",
    "Saddle\n",
    "Scroll\n",
    "Shelter\n",
    "Slope\n",
    "Sock\n",
    "Track\n",
    "Track With Nails\n",
    "Tuxedo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_one_att_custom(attribut):\n",
    "    customer_id = '5'\n",
    "    customer_name='%bedbathandbeyond%'\n",
    "    dateszs='2001-08-11'\n",
    "#     attribut='arm_style'\n",
    "\n",
    "\n",
    "    params = {'customer_id': customer_id,\n",
    "              'customer_name':customer_name,\n",
    "             'dateszs':dateszs,\n",
    "             'attribute':attribut}\n",
    "#     print('start')\n",
    "    dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "#     print('continuing')\n",
    "    # dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "    # print('dfs')\n",
    "    dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "    # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "#     print('customs')\n",
    "#     custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "#     df=pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "    return dfz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=import_one_att_custom('bed_bedding_size')\n",
    "print(len(dfz))\n",
    "# bed_bedding_size=df.loc[(df['attribute'].astype(str)=='bed_bedding_size')&((df['value'].astype(str)=='Crib')|(df['value'].astype(str)=='None')|(df['value'].astype(str)=='Trundle'))]                     \n",
    "# print(len(bed_bedding_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d4772e1e83b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dfz' is not defined"
     ]
    }
   ],
   "source": [
    "dfz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1632\n"
     ]
    }
   ],
   "source": [
    "pat='''(?i)((?:crib|Trundle))'''\n",
    "dfz['match']=dfz['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "df_filtered=pd.DataFrame()\n",
    "df_filtered=dfz.loc[dfz['match'].astype(str)!='[]']\n",
    "print(len(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "df_filtered['value'].explode().value_counts()\n",
    "bed_excluding_crib=df_filtered.loc[df_filtered['value'].astype(str)!='Crib']\n",
    "print(len(bed_excluding_crib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_excluding_crib['Q:bed_bedding_size']=''\n",
    "match_bed_excluding_crib=bed_excluding_crib[['external_id','Q:bed_bedding_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_bed_excluding_crib{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_bed_excluding_crib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1598\n"
     ]
    }
   ],
   "source": [
    "crib=df_filtered.loc[df_filtered['value'].astype(str)=='Crib']\n",
    "print(len(crib))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crib.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterz(pat,df):\n",
    "#     df['value_m']=df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "    df['custom_m']=df['custom_fields'].apply(lambda x: re_extract(pat,str(x)))\n",
    "    df['name_m']=df['product_name'].apply(lambda x: re_extract(pat,str(x)))\n",
    "    df['long_m']=df['long_desc'].apply(lambda x: re_extract(pat,str(x)))\n",
    "    df_filtered=pd.DataFrame()\n",
    "    df_filtered=df.loc[(df['custom_m'].astype(str)!='[]')|(df['name_m'].astype(str)!='[]')|(df['long_m'].astype(str)!='[]')]\n",
    "    df_na=df.loc[(df['custom_m'].astype(str)=='[]')&(df['name_m'].astype(str)=='[]')&(df['long_m'].astype(str)=='[]')]\n",
    "    return df_filtered,df_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?<![A-z])(?:california|king|european|full|\\bxl\\b|extral.?large|futon|queen|single|sofa|split|standard(?= matt)|twin)(?![A-z]))|()'''\n",
    "cribs,cribs_na=filterz(pat,crib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(cribs))\n",
    "# cribs[['external_id','custom_fields','custom_m','name_m','long_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1415\n"
     ]
    }
   ],
   "source": [
    "print(len(cribs_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cribs['Q:bed_bedding_size']=''\n",
    "match_cribz=cribs[['external_id','Q:bed_bedding_size']]\n",
    "\n",
    "cribs_na['Q:bed_bedding_size']='n/a'\n",
    "match_cribs_na=cribs_na[['external_id','Q:bed_bedding_size']]\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_cribz{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_cribz)\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_cribs_na{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_cribs_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bed_bedding_size\n",
    "Crib\n",
    "None\n",
    "Trundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "California King\n",
    "European\n",
    "Full\n",
    "Full XL\n",
    "Futon\n",
    "King\n",
    "n/a\n",
    "Queen\n",
    "Single\n",
    "Sofa\n",
    "Split\n",
    "Standard\n",
    "Twin\n",
    "Twin XL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4537\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('btu_range')\n",
    "print(len(df))\n",
    "btu_range=df.loc[(df['attribute'].astype(str)=='btu_range')&((df['value'].astype(str)=='0')|(df['value'].astype(str)=='2')|(df['value'].astype(str)=='500 - 5')|(df['value'].astype(str)=='Over 5')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(btu_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filters(df,pat):\n",
    "#     df['match']=df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "#     df_filtered=pd.DataFrame()\n",
    "#     df_filtered=df.loc[df['match'].astype(str)!='[]']\n",
    "#     return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:(?<!\\d)\\d(?!\\,)(?!\\d)))'''\n",
    "btu=filters(df,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>buckets</th>\n",
       "      <th>bucket_id</th>\n",
       "      <th>value</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>external_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>curated_date</th>\n",
       "      <th>resolution</th>\n",
       "      <th>curation_tasks.curated_by</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>COLOR_s</th>\n",
       "      <th>SKU_SIZE</th>\n",
       "      <th>SKU_TYPE</th>\n",
       "      <th>RecordType</th>\n",
       "      <th>SKU_SIZE_s</th>\n",
       "      <th>COLOR_GROUP</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>COLORGROUP_s</th>\n",
       "      <th>VDC_SKU_TYPE</th>\n",
       "      <th>SKU_DESCRIPTION</th>\n",
       "      <th>LONG_DESCRIPTION</th>\n",
       "      <th>ROLLUP_TYPE_CODE</th>\n",
       "      <th>PERSONALIZATION_TYPE</th>\n",
       "      <th>gbi_exp_product_type</th>\n",
       "      <th>gbi_syn_product_type</th>\n",
       "      <th>MARKETPLACE_ITEM_FLAG</th>\n",
       "      <th>ASSEMBLEDPRODUCTWIDTHIN</th>\n",
       "      <th>ASSEMBLEDPRODUCTHEIGHTIN</th>\n",
       "      <th>ASSEMBLEDPRODUCTLENGTHIN</th>\n",
       "      <th>ASSEMBLEDPRODUCTDIAMETERIN</th>\n",
       "      <th>Set_Size</th>\n",
       "      <th>s_f_Theme</th>\n",
       "      <th>s_f_Made_In</th>\n",
       "      <th>f_Product_Type</th>\n",
       "      <th>s_f_Anti_Tip_Kit</th>\n",
       "      <th>s_f_Construction</th>\n",
       "      <th>s_f_Product_Type</th>\n",
       "      <th>f_binProduct_Type</th>\n",
       "      <th>s_f_Exterior_Finish</th>\n",
       "      <th>s_f_Hardware_Finish</th>\n",
       "      <th>s_f_Lifestyle_multi</th>\n",
       "      <th>gbi_product_type_affinity</th>\n",
       "      <th>s_f_Assembly_Instructions</th>\n",
       "      <th>MAX_ASSEMBLEDPRODUCTWIDTHIN</th>\n",
       "      <th>MIN_ASSEMBLEDPRODUCTWIDTHIN</th>\n",
       "      <th>MAX_ASSEMBLEDPRODUCTHEIGHTIN</th>\n",
       "      <th>MAX_ASSEMBLEDPRODUCTLENGTHIN</th>\n",
       "      <th>MIN_ASSEMBLEDPRODUCTHEIGHTIN</th>\n",
       "      <th>MIN_ASSEMBLEDPRODUCTLENGTHIN</th>\n",
       "      <th>s_f_Does_this_item_have_Wheels</th>\n",
       "      <th>s_f_Maximum_Weight_Capacity_lb</th>\n",
       "      <th>s_f_binSet_Size</th>\n",
       "      <th>s_f_binProduct_Type</th>\n",
       "      <th>s_f_binHoliday_Tree_Height</th>\n",
       "      <th>s_f_binConstruction_Material</th>\n",
       "      <th>Cord_Length</th>\n",
       "      <th>s_f_binCord_Length</th>\n",
       "      <th>s_f_Number_of_Doors</th>\n",
       "      <th>s_f_Power_Source_multi</th>\n",
       "      <th>s_f_Number_of_Batteries</th>\n",
       "      <th>s_f_Detailed_Care_Instructions</th>\n",
       "      <th>s_f_binSize</th>\n",
       "      <th>gbi_syn_size</th>\n",
       "      <th>s_f_Wattage</th>\n",
       "      <th>s_f_External_Finish</th>\n",
       "      <th>s_f_Wood_Color_multi</th>\n",
       "      <th>s_f_Storage_Furniture_Design_Features_multi</th>\n",
       "      <th>s_f_Fixture_Mounts</th>\n",
       "      <th>s_f_Electrics_Safety_features_multi</th>\n",
       "      <th>SERVICE_TYPE_CD</th>\n",
       "      <th>s_f_Closure_Type</th>\n",
       "      <th>s_f_Soft_Textiles_Use_and_Care_Instructions</th>\n",
       "      <th>s_f_Indoor_Outdoor_Use</th>\n",
       "      <th>s_f_Fill_Material</th>\n",
       "      <th>s_f_binFill_Material</th>\n",
       "      <th>s_f_binUpholstered_Material</th>\n",
       "      <th>s_f_Tabletop_Style</th>\n",
       "      <th>s_f_binMaterial</th>\n",
       "      <th>s_f_Fabric_FiberType</th>\n",
       "      <th>s_f_binHanging_Style</th>\n",
       "      <th>s_f_Soft_Textiles_Material</th>\n",
       "      <th>s_f_Number_of_Hooks</th>\n",
       "      <th>s_f_Life_Stage_multi</th>\n",
       "      <th>s_f_Storage_Furniture_Includes_multi</th>\n",
       "      <th>Fabric_FiberType</th>\n",
       "      <th>s_f_binInterior_Construction_Material</th>\n",
       "      <th>s_f_Large_Drawer_Depth_in</th>\n",
       "      <th>s_f_Large_Drawer_Width_in</th>\n",
       "      <th>s_f_Small_Drawer_Depth_in</th>\n",
       "      <th>s_f_Small_Drawer_Width_in</th>\n",
       "      <th>s_f_Large_Drawer_Height_in</th>\n",
       "      <th>s_f_Medium_Drawer_Depth_in</th>\n",
       "      <th>s_f_Medium_Drawer_Width_in</th>\n",
       "      <th>s_f_Small_Drawer_Height_in</th>\n",
       "      <th>s_f_Medium_Drawer_Height_in</th>\n",
       "      <th>s_f_Number_of_Large_Size_Drawers</th>\n",
       "      <th>s_f_Number_of_Small_Size_Drawers</th>\n",
       "      <th>s_f_Number_of_Medium_Size_Drawers</th>\n",
       "      <th>s_f_Number_of_Unique_Drawer_Sizes</th>\n",
       "      <th>s_f_Interior_Construction</th>\n",
       "      <th>s_f_Embellishment_multi</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [attribute, buckets, bucket_id, value, customer_name, external_id, product_name, long_desc, curated_date, resolution, curation_tasks.curated_by, TYPE, COLOR, COLOR_s, SKU_SIZE, SKU_TYPE, RecordType, SKU_SIZE_s, COLOR_GROUP, DESCRIPTION, COLORGROUP_s, VDC_SKU_TYPE, SKU_DESCRIPTION, LONG_DESCRIPTION, ROLLUP_TYPE_CODE, PERSONALIZATION_TYPE, gbi_exp_product_type, gbi_syn_product_type, MARKETPLACE_ITEM_FLAG, ASSEMBLEDPRODUCTWIDTHIN, ASSEMBLEDPRODUCTHEIGHTIN, ASSEMBLEDPRODUCTLENGTHIN, ASSEMBLEDPRODUCTDIAMETERIN, Set_Size, s_f_Theme, s_f_Made_In, f_Product_Type, s_f_Anti_Tip_Kit, s_f_Construction, s_f_Product_Type, f_binProduct_Type, s_f_Exterior_Finish, s_f_Hardware_Finish, s_f_Lifestyle_multi, gbi_product_type_affinity, s_f_Assembly_Instructions, MAX_ASSEMBLEDPRODUCTWIDTHIN, MIN_ASSEMBLEDPRODUCTWIDTHIN, MAX_ASSEMBLEDPRODUCTHEIGHTIN, MAX_ASSEMBLEDPRODUCTLENGTHIN, MIN_ASSEMBLEDPRODUCTHEIGHTIN, MIN_ASSEMBLEDPRODUCTLENGTHIN, s_f_Does_this_item_have_Wheels, s_f_Maximum_Weight_Capacity_lb, s_f_binSet_Size, s_f_binProduct_Type, s_f_binHoliday_Tree_Height, s_f_binConstruction_Material, Cord_Length, s_f_binCord_Length, s_f_Number_of_Doors, s_f_Power_Source_multi, s_f_Number_of_Batteries, s_f_Detailed_Care_Instructions, s_f_binSize, gbi_syn_size, s_f_Wattage, s_f_External_Finish, s_f_Wood_Color_multi, s_f_Storage_Furniture_Design_Features_multi, s_f_Fixture_Mounts, s_f_Electrics_Safety_features_multi, SERVICE_TYPE_CD, s_f_Closure_Type, s_f_Soft_Textiles_Use_and_Care_Instructions, s_f_Indoor_Outdoor_Use, s_f_Fill_Material, s_f_binFill_Material, s_f_binUpholstered_Material, s_f_Tabletop_Style, s_f_binMaterial, s_f_Fabric_FiberType, s_f_binHanging_Style, s_f_Soft_Textiles_Material, s_f_Number_of_Hooks, s_f_Life_Stage_multi, s_f_Storage_Furniture_Includes_multi, Fabric_FiberType, s_f_binInterior_Construction_Material, s_f_Large_Drawer_Depth_in, s_f_Large_Drawer_Width_in, s_f_Small_Drawer_Depth_in, s_f_Small_Drawer_Width_in, s_f_Large_Drawer_Height_in, s_f_Medium_Drawer_Depth_in, s_f_Medium_Drawer_Width_in, s_f_Small_Drawer_Height_in, s_f_Medium_Drawer_Height_in, s_f_Number_of_Large_Size_Drawers, s_f_Number_of_Small_Size_Drawers, ...]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btu_range\n",
    "0\n",
    "2\n",
    "500 - 5\n",
    "Over 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2,500 - 5,000\n",
    "n/a\n",
    "Over 5,000\n",
    "Under 2,500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('bulb_type')\n",
    "print(len(df))\n",
    "bulb_type=df.loc[(df['attribute'].astype(str)=='bulb_type')&((df['value'].astype(str)=='Fluorescent Bulb')|(df['value'].astype(str)=='LED Bulb')|(df['value'].astype(str)=='Specialty Bulb')|(df['value'].astype(str)=='Standard Bulb')|(df['value'].astype(str)=='Fluorescent Bulb')|(df['value'].astype(str)=='LED Bulb')|(df['value'].astype(str)=='Specialty Bulb')|(df['value'].astype(str)=='Standard Bulb')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(bulb_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pat='''(?i)(Standard)'''\n",
    "bul=filters(df,pat)\n",
    "print(len(bul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulb_type\n",
    "# Fluorescent Bulb\n",
    "LED Bulb\n",
    "Specialty Bulb\n",
    "Standard Bulb\n",
    "Fluorescent Bulb\n",
    "LED Bulb\n",
    "Specialty Bulb\n",
    "Standard Bulb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFL\n",
    "Fluorescent\n",
    "Halogen\n",
    "Incandescent\n",
    "LED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71432\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('capacity_gal')\n",
    "print(len(df))\n",
    "capacity_gal=df.loc[(df['attribute'].astype(str)=='capacity_gal')&((df['value'].astype(str)=='5 gal')|(df['value'].astype(str)=='5 gal')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(capacity_gal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pat='''(?i)((?:(?<!\\.)(?<!\\- )(?<!\\-)(?<!\\d)\\d gal(?!\\.)))'''\n",
    "gal=filters(df,pat)\n",
    "print(len(gal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacity_gal\n",
    "5 gal\n",
    "5 gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 - 0.9 gal.\n",
    "0 - 2 gal\n",
    "0-5 Gallons\n",
    "11-15 Gallons\n",
    "1 - 1.9 gal.\n",
    "16-20 Gallons\n",
    "2.1 - 4 gal\n",
    "2 - 2.9 gal.\n",
    "3 - 3.9 gal.\n",
    "4.1 - 6 gal\n",
    "4 - 4.9 gal.\n",
    "5 gal. or Greater\n",
    "6-10 Gallons\n",
    "6.1 - 8 gal\n",
    "8.1 - 10 gal\n",
    "Greater than 10 gal\n",
    "n/a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('care')\n",
    "care=df.loc[(df['attribute'].astype(str)=='care')&((df['value'].astype(str)=='Spot Clean/Dry clean'))]                    \n",
    "print(len(care))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:spot))'''\n",
    "gal=filters(df,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# care\n",
    "Spot Clean/Dry clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Air Dry\n",
    "Dishwasher Safe\n",
    "Dishwasher Safe Parts & Attachments\n",
    "Disposable\n",
    "Do Not Use Acidic or Lemon Detergent\n",
    "Dry Clean Only\n",
    "Dust\n",
    "Gentle Cycle\n",
    "Hand Wash\n",
    "Line Dry\n",
    "Machine Washable\n",
    "n/a\n",
    "Spot Clean\n",
    "Steam Iron Low\n",
    "Top Rack Dishwasher Safe\n",
    "Tumble Dry\n",
    "Tumble Dry Low\n",
    "Vacuum\n",
    "Wipe Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('chew_style')\n",
    "chew_style=df.loc[(df['attribute'].astype(str)=='chew_style')&((df['value'].astype(str)=='Tough')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(chew_style))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:tough))'''\n",
    "gal=filters(df,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chew_style\n",
    "Tough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hide\n",
    "Dental\n",
    "Squeaky\n",
    "Teething\n",
    "Tough Chewer\n",
    "Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('countertop_width')\n",
    "countertop_width=df.loc[(df['attribute'].astype(str)=='countertop_width')&((df['value'].astype(str)=='Large (Over 50)')|(df['value'].astype(str)=='Medium (40 - 50)')|(df['value'].astype(str)=='Small (Under 40)')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(countertop_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countertop_width\n",
    "Large (Over 50)\n",
    "Medium (40 - 50)\n",
    "Small (Under 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Large (Over 50\")\n",
    "Medium (40\" - 50\")\n",
    "Small (Under 40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This needs to get done---Waiting on Jeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80282\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('depth_sheets')\n",
    "print(len(df))\n",
    "depth_sheets=df.loc[(df['attribute'].astype(str)=='depth_sheets')&((df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(depth_sheets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)(\\d+(?= in(?!ches)))|(\\d+(?! to)(?!\\d)(?! inches))'''   \n",
    "depth=filters(df,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "depth['value'].explode().value_counts()\n",
    "print(len(depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "metric='lbs'\n",
    "range_string = \"\"\"\n",
    "13 - 17 lbs\n",
    "18 and Greater\n",
    "3 - 12 lbs\n",
    " \"\"\"\n",
    "\n",
    "# 13 to 17 Inches\n",
    "# 18 Inches and Higher\n",
    "# 3 to 12 Inches\n",
    "\n",
    "range_params = {}\n",
    "for range_entry in range_string.split('\\n'):\n",
    "    range_nums = re.findall('\\d+', range_entry)\n",
    "    if len(range_nums) > 0: \n",
    "        range_params[tuple(map(int, range_nums))] = range_entry.strip()\n",
    "\n",
    "\n",
    "def  range_app(num_lst):\n",
    "    updated_labels = []\n",
    "    for num in num_lst:\n",
    "        num = float(num)\n",
    "        for range_param, range_label in range_params.items():\n",
    "            if len(range_param) == 1:\n",
    "                if num >= range_param[0]:\n",
    "                    updated_labels.append(range_label)\n",
    "            else:\n",
    "                if num >= range_param[0] and num <= range_param[1]:\n",
    "                    updated_labels.append(range_label)\n",
    "    return updated_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2 in                                           61\n",
       "1 in                                           17\n",
       "[\"13 to 17 Inches\",\"2 in\"]                     11\n",
       "[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]    10\n",
       "[\"1 in\",\"3 to 12 Inches\"]                       5\n",
       "[\"2 in\",\"3 to 12 Inches\"]                       3\n",
       "[\"18 Inches and Higher\",\"2 in\"]                 3\n",
       "[\"1 in\",\"2 in\"]                                 2\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth['matchez']=depth['value'].apply(lambda x: re.sub(r'(?<!\")(?<!\\d)((?:2 in|1 in))','[\"13 to 17 Inches\"]',str(x))).apply(lambda x: re.sub(r'(?<=\")(?<!\\d)((?:2 in|1 in))','13 to 17 Inches',str(x)))#.apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(range_app).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x)))                     \n",
    "depth['matchez']=depth['matchez'].apply(lambda x: re.sub(r'13 to 17 Inches\",\"13 to 17 Inches','13 to 17 Inches',str(x)))#.apply(lambda x: natsorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"13 to 17 Inches\"]                           91\n",
       "[\"13 to 17 Inches\",\"3 to 12 Inches\"]          18\n",
       "[\"18 Inches and Higher\",\"13 to 17 Inches\"]     3\n",
       "Name: matchez, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth['matchez'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>matchez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>[\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>[\"1 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>[\"1 in\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>[\"1 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>[\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>[\"1 in\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>[\"18 Inches and Higher\",\"2 in\"]</td>\n",
       "      <td>[\"18 Inches and Higher\",\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>[\"18 Inches and Higher\",\"2 in\"]</td>\n",
       "      <td>[\"18 Inches and Higher\",\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>[\"1 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>[\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3723</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\"]</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>[\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4429</th>\n",
       "      <td>[\"18 Inches and Higher\",\"2 in\"]</td>\n",
       "      <td>[\"18 Inches and Higher\",\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>1 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>[\"1 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>[\"1 in\",\"3 to 12 Inches\"]</td>\n",
       "      <td>[\"13 to 17 Inches\",\"3 to 12 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4440</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>2 in</td>\n",
       "      <td>[\"13 to 17 Inches\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            value  \\\n",
       "137                                          2 in   \n",
       "185                                          2 in   \n",
       "189                    [\"13 to 17 Inches\",\"2 in\"]   \n",
       "276                                          2 in   \n",
       "372                                          2 in   \n",
       "380                    [\"13 to 17 Inches\",\"2 in\"]   \n",
       "407                    [\"13 to 17 Inches\",\"2 in\"]   \n",
       "415                                          2 in   \n",
       "537                    [\"13 to 17 Inches\",\"2 in\"]   \n",
       "553                                          2 in   \n",
       "554                                          2 in   \n",
       "650                                          2 in   \n",
       "745                                          2 in   \n",
       "746                                          2 in   \n",
       "747                                          1 in   \n",
       "762                    [\"13 to 17 Inches\",\"2 in\"]   \n",
       "831                                          1 in   \n",
       "832                                          2 in   \n",
       "833                                          2 in   \n",
       "929                                          1 in   \n",
       "1077  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "1107                                         1 in   \n",
       "1108                                         2 in   \n",
       "1109                                         2 in   \n",
       "1110                                         2 in   \n",
       "1111                    [\"2 in\",\"3 to 12 Inches\"]   \n",
       "1302                                         2 in   \n",
       "1492                                         2 in   \n",
       "1493                                         2 in   \n",
       "1494                                         2 in   \n",
       "1495                    [\"1 in\",\"3 to 12 Inches\"]   \n",
       "1496                                         1 in   \n",
       "1526  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "1635  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "1664                                         1 in   \n",
       "1665                              [\"1 in\",\"2 in\"]   \n",
       "1666                                         2 in   \n",
       "1667                                         2 in   \n",
       "1668                                         2 in   \n",
       "1669                                         2 in   \n",
       "2155                   [\"13 to 17 Inches\",\"2 in\"]   \n",
       "2156  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "2215                                         1 in   \n",
       "2216                                         1 in   \n",
       "2217                    [\"1 in\",\"3 to 12 Inches\"]   \n",
       "2218                                         2 in   \n",
       "2219                                         2 in   \n",
       "2220                                         2 in   \n",
       "2221                                         2 in   \n",
       "2222                                         2 in   \n",
       "2223                                         2 in   \n",
       "2224                                         2 in   \n",
       "2603                                         2 in   \n",
       "2606                                         2 in   \n",
       "2985                    [\"2 in\",\"3 to 12 Inches\"]   \n",
       "2986                                         2 in   \n",
       "2987                                         2 in   \n",
       "2988                                         2 in   \n",
       "2989                                         2 in   \n",
       "2990                                         2 in   \n",
       "2991                                         2 in   \n",
       "2992                                         2 in   \n",
       "2993                              [\"1 in\",\"2 in\"]   \n",
       "2994                                         1 in   \n",
       "2995                                         1 in   \n",
       "2996              [\"18 Inches and Higher\",\"2 in\"]   \n",
       "3053  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "3054  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "3055                   [\"13 to 17 Inches\",\"2 in\"]   \n",
       "3271                   [\"13 to 17 Inches\",\"2 in\"]   \n",
       "3272                   [\"13 to 17 Inches\",\"2 in\"]   \n",
       "3273  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "3329              [\"18 Inches and Higher\",\"2 in\"]   \n",
       "3331                                         1 in   \n",
       "3332                                         1 in   \n",
       "3333                    [\"1 in\",\"3 to 12 Inches\"]   \n",
       "3334                                         2 in   \n",
       "3335                                         2 in   \n",
       "3336                                         2 in   \n",
       "3337                                         2 in   \n",
       "3338                                         2 in   \n",
       "3339                                         2 in   \n",
       "3340                                         2 in   \n",
       "3341                    [\"2 in\",\"3 to 12 Inches\"]   \n",
       "3720                                         1 in   \n",
       "3723                                         2 in   \n",
       "4311                   [\"13 to 17 Inches\",\"2 in\"]   \n",
       "4312                   [\"13 to 17 Inches\",\"2 in\"]   \n",
       "4313  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "4314  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "4315  [\"13 to 17 Inches\",\"2 in\",\"3 to 12 Inches\"]   \n",
       "4429              [\"18 Inches and Higher\",\"2 in\"]   \n",
       "4431                                         1 in   \n",
       "4432                                         1 in   \n",
       "4433                                         1 in   \n",
       "4434                                         1 in   \n",
       "4435                    [\"1 in\",\"3 to 12 Inches\"]   \n",
       "4436                    [\"1 in\",\"3 to 12 Inches\"]   \n",
       "4437                                         2 in   \n",
       "4438                                         2 in   \n",
       "4439                                         2 in   \n",
       "4440                                         2 in   \n",
       "4441                                         2 in   \n",
       "4442                                         2 in   \n",
       "4443                                         2 in   \n",
       "4444                                         2 in   \n",
       "4445                                         2 in   \n",
       "4446                                         2 in   \n",
       "4447                                         2 in   \n",
       "4448                                         2 in   \n",
       "4449                                         2 in   \n",
       "4450                                         2 in   \n",
       "\n",
       "                                         matchez  \n",
       "137                          [\"13 to 17 Inches\"]  \n",
       "185                          [\"13 to 17 Inches\"]  \n",
       "189                          [\"13 to 17 Inches\"]  \n",
       "276                          [\"13 to 17 Inches\"]  \n",
       "372                          [\"13 to 17 Inches\"]  \n",
       "380                          [\"13 to 17 Inches\"]  \n",
       "407                          [\"13 to 17 Inches\"]  \n",
       "415                          [\"13 to 17 Inches\"]  \n",
       "537                          [\"13 to 17 Inches\"]  \n",
       "553                          [\"13 to 17 Inches\"]  \n",
       "554                          [\"13 to 17 Inches\"]  \n",
       "650                          [\"13 to 17 Inches\"]  \n",
       "745                          [\"13 to 17 Inches\"]  \n",
       "746                          [\"13 to 17 Inches\"]  \n",
       "747                          [\"13 to 17 Inches\"]  \n",
       "762                          [\"13 to 17 Inches\"]  \n",
       "831                          [\"13 to 17 Inches\"]  \n",
       "832                          [\"13 to 17 Inches\"]  \n",
       "833                          [\"13 to 17 Inches\"]  \n",
       "929                          [\"13 to 17 Inches\"]  \n",
       "1077        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "1107                         [\"13 to 17 Inches\"]  \n",
       "1108                         [\"13 to 17 Inches\"]  \n",
       "1109                         [\"13 to 17 Inches\"]  \n",
       "1110                         [\"13 to 17 Inches\"]  \n",
       "1111        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "1302                         [\"13 to 17 Inches\"]  \n",
       "1492                         [\"13 to 17 Inches\"]  \n",
       "1493                         [\"13 to 17 Inches\"]  \n",
       "1494                         [\"13 to 17 Inches\"]  \n",
       "1495        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "1496                         [\"13 to 17 Inches\"]  \n",
       "1526        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "1635        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "1664                         [\"13 to 17 Inches\"]  \n",
       "1665                         [\"13 to 17 Inches\"]  \n",
       "1666                         [\"13 to 17 Inches\"]  \n",
       "1667                         [\"13 to 17 Inches\"]  \n",
       "1668                         [\"13 to 17 Inches\"]  \n",
       "1669                         [\"13 to 17 Inches\"]  \n",
       "2155                         [\"13 to 17 Inches\"]  \n",
       "2156        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "2215                         [\"13 to 17 Inches\"]  \n",
       "2216                         [\"13 to 17 Inches\"]  \n",
       "2217        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "2218                         [\"13 to 17 Inches\"]  \n",
       "2219                         [\"13 to 17 Inches\"]  \n",
       "2220                         [\"13 to 17 Inches\"]  \n",
       "2221                         [\"13 to 17 Inches\"]  \n",
       "2222                         [\"13 to 17 Inches\"]  \n",
       "2223                         [\"13 to 17 Inches\"]  \n",
       "2224                         [\"13 to 17 Inches\"]  \n",
       "2603                         [\"13 to 17 Inches\"]  \n",
       "2606                         [\"13 to 17 Inches\"]  \n",
       "2985        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "2986                         [\"13 to 17 Inches\"]  \n",
       "2987                         [\"13 to 17 Inches\"]  \n",
       "2988                         [\"13 to 17 Inches\"]  \n",
       "2989                         [\"13 to 17 Inches\"]  \n",
       "2990                         [\"13 to 17 Inches\"]  \n",
       "2991                         [\"13 to 17 Inches\"]  \n",
       "2992                         [\"13 to 17 Inches\"]  \n",
       "2993                         [\"13 to 17 Inches\"]  \n",
       "2994                         [\"13 to 17 Inches\"]  \n",
       "2995                         [\"13 to 17 Inches\"]  \n",
       "2996  [\"18 Inches and Higher\",\"13 to 17 Inches\"]  \n",
       "3053        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "3054        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "3055                         [\"13 to 17 Inches\"]  \n",
       "3271                         [\"13 to 17 Inches\"]  \n",
       "3272                         [\"13 to 17 Inches\"]  \n",
       "3273        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "3329  [\"18 Inches and Higher\",\"13 to 17 Inches\"]  \n",
       "3331                         [\"13 to 17 Inches\"]  \n",
       "3332                         [\"13 to 17 Inches\"]  \n",
       "3333        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "3334                         [\"13 to 17 Inches\"]  \n",
       "3335                         [\"13 to 17 Inches\"]  \n",
       "3336                         [\"13 to 17 Inches\"]  \n",
       "3337                         [\"13 to 17 Inches\"]  \n",
       "3338                         [\"13 to 17 Inches\"]  \n",
       "3339                         [\"13 to 17 Inches\"]  \n",
       "3340                         [\"13 to 17 Inches\"]  \n",
       "3341        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "3720                         [\"13 to 17 Inches\"]  \n",
       "3723                         [\"13 to 17 Inches\"]  \n",
       "4311                         [\"13 to 17 Inches\"]  \n",
       "4312                         [\"13 to 17 Inches\"]  \n",
       "4313        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "4314        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "4315        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "4429  [\"18 Inches and Higher\",\"13 to 17 Inches\"]  \n",
       "4431                         [\"13 to 17 Inches\"]  \n",
       "4432                         [\"13 to 17 Inches\"]  \n",
       "4433                         [\"13 to 17 Inches\"]  \n",
       "4434                         [\"13 to 17 Inches\"]  \n",
       "4435        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "4436        [\"13 to 17 Inches\",\"3 to 12 Inches\"]  \n",
       "4437                         [\"13 to 17 Inches\"]  \n",
       "4438                         [\"13 to 17 Inches\"]  \n",
       "4439                         [\"13 to 17 Inches\"]  \n",
       "4440                         [\"13 to 17 Inches\"]  \n",
       "4441                         [\"13 to 17 Inches\"]  \n",
       "4442                         [\"13 to 17 Inches\"]  \n",
       "4443                         [\"13 to 17 Inches\"]  \n",
       "4444                         [\"13 to 17 Inches\"]  \n",
       "4445                         [\"13 to 17 Inches\"]  \n",
       "4446                         [\"13 to 17 Inches\"]  \n",
       "4447                         [\"13 to 17 Inches\"]  \n",
       "4448                         [\"13 to 17 Inches\"]  \n",
       "4449                         [\"13 to 17 Inches\"]  \n",
       "4450                         [\"13 to 17 Inches\"]  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# depth['matches']=depth['match'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(range_app).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "depth[['value','matchez']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(depth.columns)):\n",
    "#     print(depth.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth['Q:depth_sheets']=depth['matchez']\n",
    "match_depth_sheets=depth[['external_id','Q:depth_sheets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_depth_sheets{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_depth_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth_sheets\n",
    "108 in\n",
    "10 in\n",
    "12\n",
    "12 in\n",
    "13 in\n",
    "13 to 17 Inches\n",
    "14 in\n",
    "15 in\n",
    "16 in\n",
    "17 in\n",
    "18 in\n",
    "19 in\n",
    "1 in\n",
    "20 in\n",
    "21 in\n",
    "24 in\n",
    "25 in\n",
    "2 in\n",
    "30 in\n",
    "5 in\n",
    "6 in\n",
    "75 in\n",
    "8 in\n",
    "9 in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13 to 17 Inches\n",
    "18 Inches and Higher\n",
    "3 to 12 Inches\n",
    "n/a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26864\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('diameter_range')\n",
    "print(len(df))\n",
    "diameter_range=df.loc[(df['attribute'].astype(str)=='diameter_range')&((df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(diameter_range))\n",
    "pat='''(?i)(\\d )'''\n",
    "diameter=filters(df,pat)\n",
    "print(len(diameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>buckets</th>\n",
       "      <th>bucket_id</th>\n",
       "      <th>value</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>external_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>curated_date</th>\n",
       "      <th>resolution</th>\n",
       "      <th>curation_tasks.curated_by</th>\n",
       "      <th>custom_fields</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [attribute, buckets, bucket_id, value, customer_name, external_id, product_name, long_desc, curated_date, resolution, curation_tasks.curated_by, custom_fields, match]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diameter_range\n",
    "0 - 11.9\n",
    "12 - 23.9\n",
    "24 - 35.9\n",
    "36 - 47.9\n",
    "48 - 59.9\n",
    "60 - 71.9\n",
    "72 or Greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0\" - 11.9\"\n",
    "12\" - 23.9\"\n",
    "24\" - 35.9\"\n",
    "36\" - 47.9\"\n",
    "48\" - 59.9\"\n",
    "60\" - 71.9\"\n",
    "72\" or Greater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249540\n",
      "0\n",
      "567\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('fabric_weight_type')\n",
    "print(len(df))\n",
    "fabric_weight_type=df.loc[(df['attribute'].astype(str)=='fabric_weight_type')&((df['value'].astype(str)=='Lightweight (300-450 GSM)')|(df['value'].astype(str)=='Midweight (450-550 GSM)')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(fabric_weight_type))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n"
     ]
    }
   ],
   "source": [
    "pat='''(?i)(449)'''\n",
    "fab=filters(df,pat)\n",
    "print(len(fab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n/a                          248091\n",
       "Heavyweight (550+ GSM)          666\n",
       "Lightweight (300-449 GSM)       567\n",
       "Midweight (450-549 GSM)         216\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fabric_weight_type\n",
    "Lightweight (300-450 GSM)\n",
    "Midweight (450-550 GSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heavyweight (550+ GSM)\n",
    "Lightweight (300-449 GSM)\n",
    "Midweight (450-549 GSM)\n",
    "n/a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('features')\n",
    "print(len(df))\n",
    "features=df.loc[(df['attribute'].astype(str)=='features')&((df['value'].astype(str)=='Adjustable ncline')|(df['value'].astype(str)=='Adjustable Power')|(df['value'].astype(str)=='Auto Shut Off')|(df['value'].astype(str)=='Bed-making placement labels')|(df['value'].astype(str)=='Boot/Foot Muff ncluded')|(df['value'].astype(str)=='Ceiling Mountable')|(df['value'].astype(str)=='ENERGY STAR-Certified')|(df['value'].astype(str)=='Full Tang')|(df['value'].astype(str)=='Hand Break')|(df['value'].astype(str)=='Includes Filters')|(df['value'].astype(str)=='Indoor/Outdoor')|(df['value'].astype(str)=='Machine Washable')|(df['value'].astype(str)=='Microwaveable')|(df['value'].astype(str)=='No Slip Grip')|(df['value'].astype(str)=='NSF Approved')|(df['value'].astype(str)=='Removable Infant Insert ncluded')|(df['value'].astype(str)=='Set')|(df['value'].astype(str)=='Tiebacks')|(df['value'].astype(str)=='Temperature/Humidity Reading')|(df['value'].astype(str)=='Valence'))]                     \n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "Adjustable ncline\n",
    "Adjustable Power\n",
    "Auto Shut Off\n",
    "Bed-making placement labels\n",
    "Boot/Foot Muff ncluded\n",
    "Ceiling Mountable\n",
    "ENERGY STAR-Certified\n",
    "Full Tang\n",
    "Hand Break\n",
    "Includes Filters\n",
    "Indoor/Outdoor\n",
    "Machine Washable\n",
    "Microwaveable\n",
    "No Slip Grip\n",
    "NSF Approved\n",
    "Removable Infant Insert ncluded\n",
    "Set\n",
    "Temperature/Humidity Reading\n",
    "Tiebacks\n",
    "Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "way too many values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('fits_laptop')\n",
    "fits_laptop=df.loc[(df['attribute'].astype(str)=='fits_laptop')&((df['value'].astype(str)=='13')|(df['value'].astype(str)=='15')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(fits_laptop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits_laptop\n",
    "13\n",
    "15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13\"\n",
    "15\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('freezing_method')\n",
    "freezing_method=df.loc[(df['attribute'].astype(str)=='freezing_method')&((df['value'].astype(str)=='Freezable')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(freezing_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(freezing_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "freezing_method['Q:freezing_method']=''\n",
    "match_freezing_method=freezing_method[['external_id','Q:freezing_method']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_freezing_method{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_freezing_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing_method\n",
    "Freezable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compressor\n",
    "Electric\n",
    "Freezer Bowl\n",
    "Rock Salt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('height_range')\n",
    "height_range=df.loc[(df['attribute'].astype(str)=='height_range')&((df['value'].astype(str)=='Large (15 - 23)')|(df['value'].astype(str)=='Medium (8 - 14.9)')|(df['value'].astype(str)=='Oversized (Over 23)')|(df['value'].astype(str)=='Small (Under 8)')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(height_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height_range\n",
    "Large (15 - 23)\n",
    "Medium (8 - 14.9)\n",
    "Oversized (Over 23)\n",
    "Small (Under 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Large (15\" - 23\")\n",
    "Medium (8\" - 14.9\")\n",
    "Oversized (Over 23\")\n",
    "Small (Under 8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needs Upload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8111\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('indoor_outdoor')\n",
    "indoor_outdoor=df.loc[(df['attribute'].astype(str)=='indoor_outdoor')&((df['value'].astype(str)=='Indoor'))]                     \n",
    "print(len(indoor_outdoor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8111\n"
     ]
    }
   ],
   "source": [
    "print(len(indoor_outdoor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indoor    8111\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indoor_outdoor['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indoor_outdoor['Q:indoor_outdoor']='Indoor & Outdoor'\n",
    "match_indoor_outdoor=indoor_outdoor[['external_id','Q:indoor_outdoor']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_indoor_outdoor{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_indoor_outdoor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indoor_outdoor\n",
    "Indoor\n",
    "Indoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Indoor & Outdoor\n",
    "n/a\n",
    "Outdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('infant_car_seat_brand_model_compatibility')\n",
    "infant_car_seat_brand_model_compatibility=df.loc[(df['attribute'].astype(str)=='infant_car_seat_brand_model_compatibility')&((df['value'].astype(str)=='BOB')|(df['value'].astype(str)=='Britax')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='gb Idan')|(df['value'].astype(str)=='Maxi Cosi')|(df['value'].astype(str)=='Nuna Pipa')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(infant_car_seat_brand_model_compatibility))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infant_car_seat_brand_model_compatibility\n",
    "BOB\n",
    "Britax\n",
    "gb Idan\n",
    "Maxi Cosi\n",
    "Nuna Pipa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaptors sold separately\n",
    "All Major\n",
    "Ally Infant Car Seat and Base\n",
    "Baby Jogger\n",
    "Baby Trend\n",
    "Baby Trend Ally 35\n",
    "Britax, BOB\n",
    "Britax/BOB\n",
    "Britax, BOB, BOB Gear\n",
    "Bugaboo Turtle by Nuna\n",
    "Chicco\n",
    "Click Connect\n",
    "Click Connect Infant Car Seats\n",
    "Compatible with 35+ Infant Car Seats\n",
    "Cybex\n",
    "Cybex, gb Idan\n",
    "CYBEX Infant Car Seat\n",
    "Cybex, Nuna Pipa, Maxi Cosi\n",
    "Graco\n",
    "Nuna Turtle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('leg_height')\n",
    "leg_height=df.loc[(df['attribute'].astype(str)=='leg_height')&((df['value'].astype(str)=='12-18 Inches')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(leg_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leg_height\n",
    "12-18 Inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0-6 Inches\n",
    "13-18 Inches\n",
    "19-24 Inches\n",
    "7-12 Inches\n",
    "Greater than 24 Inches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15065\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('lumens')\n",
    "print(len(df))\n",
    "lumens=df.loc[(df['attribute'].astype(str)=='lumens')&((df['value'].astype(str)=='[]')|(df['value'].astype(str)=='000 - 1')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]    \n",
    "print(len(lumens))\n",
    "pat='''(?i)((?<!\\,)(?<! )(?<!\\d \\-)(?<!\\- \\d\\d)(?<!\\,\\d\\d)\\d(?! \\-)(?!\\,)(?!\\d))|((?<!\\d)(?<!\\,)0(?! \\-))'''\n",
    "lu=filters(df,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "lu=filters(df,pat)\n",
    "print(len(lu))\n",
    "lu['Q:lumens']=''\n",
    "match_lumens=lu[['external_id','Q:lumens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_lumens{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_lumens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lumens\n",
    "0\n",
    "000 - 1\n",
    "50\n",
    "72\n",
    "1\n",
    "10\n",
    "100\n",
    "1000 - 1599\n",
    "1050\n",
    "11\n",
    "1100\n",
    "12\n",
    "120\n",
    "13\n",
    "135\n",
    "14\n",
    "15\n",
    "150\n",
    "16\n",
    "1600+\n",
    "1606\n",
    "17\n",
    "170\n",
    "19\n",
    "2\n",
    "20\n",
    "200\n",
    "21\n",
    "240\n",
    "25\n",
    "250\n",
    "28\n",
    "280\n",
    "29\n",
    "290\n",
    "3\n",
    "300\n",
    "350\n",
    "360\n",
    "380\n",
    "39\n",
    "4\n",
    "40\n",
    "400\n",
    "42\n",
    "43\n",
    "430\n",
    "44\n",
    "450\n",
    "480\n",
    "5\n",
    "50\n",
    "500\n",
    "520\n",
    "538\n",
    "54\n",
    "555\n",
    "599\n",
    "6\n",
    "600\n",
    "600+\n",
    "606\n",
    "610\n",
    "640\n",
    "7\n",
    "700\n",
    "750\n",
    "760\n",
    "8\n",
    "800\n",
    "837\n",
    "85\n",
    "850\n",
    "870\n",
    "9\n",
    "900\n",
    "957\n",
    "980\n",
    "990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 - 449\n",
    "1,000 - 1,599\n",
    "1,600+\n",
    "450 - 799\n",
    "800 - 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to do this--save till last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "continuing\n",
      "customs\n"
     ]
    }
   ],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2022-01-01'\n",
    "attribut='material'\n",
    "\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print('continuing')\n",
    "# dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "# print('dfs')\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "print('customs')\n",
    "custom_field_df=pd.json_normalize(dfs['custom_fields'])\n",
    "df=pd.concat([dfs.drop('custom_fields', axis=1), custom_field_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511791\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "pat='''((?:(?<![A-z] )Blend|Cotton.?blend|Cotton\\/Cotton.?Blend|MDF|Metallic|Rayon\\/Rayon.?Blend))'''\n",
    "material=filters(dfs,pat)\n",
    "print(len(material))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=import_one_att('material')\n",
    "# material=df.loc[(df['attribute'].astype(str)=='material')&((df['value'].astype(str)=='Blend')|(df['value'].astype(str)=='Cotton blend')|(df['value'].astype(str)=='Cotton/Cotton Blend')|(df['value'].astype(str)=='MDF')|(df['value'].astype(str)=='Metallic')|(df['value'].astype(str)=='Rayon/Rayon Blend')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "# print(len(material))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.78 GiB for an array with shape (467, 511028) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-aa327add859f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'''((?:(?<![A-z] )Blend|Cotton.?blend|Cotton\\/Cotton.?Blend|MDF|Metallic|Rayon\\/Rayon.?Blend))'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmaterial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-ac6dc2dbb08d>\u001b[0m in \u001b[0;36mfilters\u001b[1;34m(df, pat)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'match'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mre_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mdf_filtered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mdf_filtered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'match'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'[]'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m    912\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[0minds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3598\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3599\u001b[0m         \"\"\"\n\u001b[1;32m-> 3600\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3601\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3582\u001b[0m         \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3584\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3586\u001b[0m         new_data = self._mgr.take(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5539\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5541\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5543\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   5527\u001b[0m         \"\"\"\n\u001b[0;32m   5528\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5529\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5530\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m   5537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5538\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5539\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5541\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[0mbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m         \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    991\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 993\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    994\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   1914\u001b[0m     \u001b[0mnew_blocks\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1915\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1916\u001b[1;33m         merged_blocks = _merge_blocks(\n\u001b[0m\u001b[0;32m   1917\u001b[0m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   1940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1941\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1942\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1943\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.78 GiB for an array with shape (467, 511028) and data type object"
     ]
    }
   ],
   "source": [
    "pat='''((?:(?<![A-z] )Blend|Cotton.?blend|Cotton\\/Cotton.?Blend|MDF|Metallic|Rayon\\/Rayon.?Blend))'''\n",
    "material=filters(df,pat)\n",
    "print(len(material))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(material))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(material))\n",
    "material['Q:material']=''\n",
    "match_material=material[['external_id','Q:material']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_material{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# material\n",
    "Blend\n",
    "Cotton blend\n",
    "Cotton/Cotton Blend\n",
    "MDF\n",
    "Metallic\n",
    "Rayon/Rayon Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('maximum_rpm')\n",
    "maximum_rpm=df.loc[(df['attribute'].astype(str)=='maximum_rpm')&((df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)(\\d(?!\\d)(?! RPM)(?!\\-))|((?<!under )(?<!\\-)\\d\\d\\d RPM(?! and))'''\n",
    "rpm=filters(df,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(rpm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum_rpm\n",
    "19\n",
    "2\n",
    "500 RPM\n",
    "600 RPM\n",
    "19\n",
    "2\n",
    "500 RPM\n",
    "600 RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100-149 RPM\n",
    "150-199 RPM\n",
    "200-249 RPM\n",
    "250-299 RPM\n",
    "300 RPM and Greater\n",
    "Under 100 RPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpm['Q:maximum_rpm']=''\n",
    "match_maximum_rpm=rpm[['external_id','Q:maximum_rpm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_maximum_rpm{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_maximum_rpm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('maximum_television_range')\n",
    "maximum_television_range=df.loc[(df['attribute'].astype(str)=='maximum_television_range')&((df['value'].astype(str)=='20-Oct')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(maximum_television_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum_television_range\n",
    "20-Oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10\" - 20\"\n",
    "21\" - 30\"\n",
    "31\" - 40\"\n",
    "41\" - 50\"\n",
    "51\" - 60\"\n",
    "61\" - 70\"\n",
    "Greater than 70\"\n",
    "n/a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to do this--Waiting on Jeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('memory')\n",
    "memory=df.loc[(df['attribute'].astype(str)=='memory')&((df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "pat='''(?i)( GB)'''\n",
    "mem=filters(memory,pat)\n",
    "print(len(mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem['Q:memory']=''\n",
    "match_memory=mem[['external_id','Q:memory']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_memory{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory\n",
    "128 GB\n",
    "256 GB\n",
    "4 GB\n",
    "512 GB\n",
    "8 GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000GB\n",
    "128GB\n",
    "16GB\n",
    "16 GB\n",
    "16TB\n",
    "1TB\n",
    "1 TB\n",
    "250GB\n",
    "256GB\n",
    "2TB\n",
    "32GB\n",
    "32 GB\n",
    "3TB\n",
    "400GB\n",
    "4GB\n",
    "4TB\n",
    "500GB\n",
    "512GB\n",
    "5TB\n",
    "600GB\n",
    "64GB\n",
    "64 GB\n",
    "6TB\n",
    "7TB\n",
    "825 GB\n",
    "8GB\n",
    "8TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('metal_finish')\n",
    "metal_finish=df.loc[(df['attribute'].astype(str)=='metal_finish')&((df['value'].astype(str)=='Matted')|(df['value'].astype(str)=='Powder Coated')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(metal_finish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metal_finish\n",
    "Matted\n",
    "Powder Coated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Antique\n",
    "Brass\n",
    "Bronze\n",
    "Brushed\n",
    "Chrome\n",
    "Copper\n",
    "Gold\n",
    "Gunmetal\n",
    "Matte\n",
    "Mirror\n",
    "n/a\n",
    "Nickel\n",
    "Nickel Chrome Plated\n",
    "Oil Rubbed\n",
    "Pewter\n",
    "Polished\n",
    "Powder Coat\n",
    "Satin\n",
    "Weathered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('minimum_recommended_age')\n",
    "print(len(df))\n",
    "minimum_recommended_age=df.loc[(df['attribute'].astype(str)=='minimum_recommended_age')&((df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(minimum_recommended_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)'''\n",
    "minimum=filters(pat,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something is wrong here--go back and look it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum_recommended_age\n",
    "0 Month\n",
    "0 Year\n",
    "10 Months\n",
    "11 Years\n",
    "13 Years\n",
    "15 Years\n",
    "16 Years\n",
    "1 Month\n",
    "2 Months\n",
    "36 Months\n",
    "4 Months\n",
    "5 Months\n",
    "5 Years\n",
    "9 Years\n",
    "0 Month\n",
    "0 Year\n",
    "10 Months\n",
    "11 Years\n",
    "13 Years\n",
    "15 Years\n",
    "16 Years\n",
    "1 Month\n",
    "2 Months\n",
    "36 Months\n",
    "4 Months\n",
    "5 Months\n",
    "5 Years\n",
    "9 Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 Months\n",
    "10 Months\n",
    "10 Years\n",
    "11 Years\n",
    "12 Months\n",
    "12 Years\n",
    "13 Years\n",
    "14 Years\n",
    "1.5 Years\n",
    "15 Years\n",
    "18 Months\n",
    "18 Years\n",
    "1 Month\n",
    "1 Year\n",
    "24 Months\n",
    "2 Months\n",
    "2 Years\n",
    "36 Months\n",
    "3 Months\n",
    "3 Years\n",
    "4 Months\n",
    "4 Years\n",
    "5 Months\n",
    "5 Years\n",
    "6 Months\n",
    "6 Years\n",
    "7 Years\n",
    "8 Years\n",
    "9 Months\n",
    "9 Years\n",
    "Newborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164683\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('mount_type')\n",
    "print(len(df))\n",
    "mount_type=df.loc[(df['attribute'].astype(str)=='mount_type')&((df['value'].astype(str)=='[]')|(df['value'].astype(str)=='Close to Ceiling')|(df['value'].astype(str)=='Downrod')|(df['value'].astype(str)=='Magnetic')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(mount_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(mount_type))\n",
    "mount_type['Q:mount_type']=''\n",
    "match_mount_type=mount_type[['external_id','Q:mount_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_mount_type{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_mount_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount_type\n",
    "Close to Ceiling\n",
    "Downrod\n",
    "Magnetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adhesive Mount\n",
    "Ceiling Mount\n",
    "Concealed Mount\n",
    "Corner Mount\n",
    "Cupboard Mount\n",
    "Deck Mount\n",
    "Door Mount\n",
    "Floor Mount\n",
    "Flush Mount\n",
    "Frame Mount\n",
    "Freestanding\n",
    "Hanging\n",
    "Hinge Mount\n",
    "Inside Mount\n",
    "Leaning\n",
    "Magnetic Mount\n",
    "n/a\n",
    "Outside Mount\n",
    "Pole Mount\n",
    "Post Mount\n",
    "Pre-Drilled Mounting Holes\n",
    "Pressure Mount\n",
    "Recessed Mount\n",
    "Roof Mount\n",
    "Screw Fittings\n",
    "Semi-Flush Mount\n",
    "Stand Mountable\n",
    "Suction Mount\n",
    "Surface Mount\n",
    "Tension Mount\n",
    "Top Mount\n",
    "Under Cabinet Mount\n",
    "Undermount\n",
    "Wall Mount\n",
    "Wall Mountable\n",
    "Window Mount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('product_form')\n",
    "product_form=df.loc[(df['attribute'].astype(str)=='product_form')&((df['value'].astype(str)=='& Caplets')|(df['value'].astype(str)=='Capsules')|(df['value'].astype(str)=='Tablets')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(product_form))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_form\n",
    "& Caplets\n",
    "Capsules\n",
    "Tablets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Balm\n",
    "Bar\n",
    "Bars\n",
    "Chewable\n",
    "Clay\n",
    "Concentrate\n",
    "Cream\n",
    "Dissolving Solids\n",
    "Exfoliator\n",
    "Foam\n",
    "Gel\n",
    "Gummy\n",
    "Liquid\n",
    "Loose Powder\n",
    "Lotion\n",
    "n/a\n",
    "Oil\n",
    "Ointment\n",
    "Pad\n",
    "Pads\n",
    "Paste\n",
    "Patch\n",
    "Pen\n",
    "Pencil\n",
    "Powder\n",
    "Pressed Powder\n",
    "Roll-On\n",
    "Scrub\n",
    "Serum\n",
    "Sheets\n",
    "Solvent\n",
    "Spray\n",
    "Stick\n",
    "Suspension\n",
    "Tablets, Capsules, & Caplets\n",
    "Wax\n",
    "Wipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('serving_cart_width')\n",
    "serving_cart_width=df.loc[(df['attribute'].astype(str)=='serving_cart_width')&((df['value'].astype(str)=='Large (Over 34)')|(df['value'].astype(str)=='Medium (25 - 34)')|(df['value'].astype(str)=='Small (Under 24)')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(serving_cart_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serving_cart_width\n",
    "Large (Over 34)\n",
    "Medium (25 - 34)\n",
    "Small (Under 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Large (Over 34\")\n",
    "Medium (25\" - 34\")\n",
    "Small (Under 24\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('set_size')\n",
    "# set_size=df.loc[(df['attribute'].astype(str)=='set_size')&((df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "pat='''(?i)(((?<!1 )piece)(?! set))|((?<!\\d)1(?!\\d)(?! piece))|(000)'''\n",
    "sets=filters(set_size,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets['Q:set_size']=''\n",
    "match_set_size=sets[['external_id','Q:set_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_set_size{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_size\n",
    "000 Piece Set\n",
    "1\n",
    "100-Piece\n",
    "101-Piece\n",
    "10-Piece\n",
    "12-Piece\n",
    "13-Piece\n",
    "15-Piece\n",
    "16-Piece\n",
    "17-Piece\n",
    "18-Piece\n",
    "1-piece\n",
    "1-Piece\n",
    "1- Piece\n",
    "20-Piece\n",
    "22-Piece\n",
    "23-Piece\n",
    "24-Piece\n",
    "25-Piece\n",
    "280-Piece\n",
    "2-Piece\n",
    "30-Piece\n",
    "32-Piece\n",
    "360-Piece\n",
    "36-Piece\n",
    "38-Piece\n",
    "3-Piece\n",
    "400-Piece\n",
    "40-Piece\n",
    "42-Piece\n",
    "44-Piece\n",
    "45-Piece\n",
    "46-Piece\n",
    "48-Piece\n",
    "4-Piece\n",
    "500-Piece\n",
    "50-Piece\n",
    "51-Piece\n",
    "53-Piece\n",
    "54-Piece\n",
    "55-Piece\n",
    "58-Piece\n",
    "5-Piece\n",
    "600-Piece\n",
    "60-Piece\n",
    "61-Piece\n",
    "62-Piece\n",
    "63-Piece\n",
    "64-Piece\n",
    "65-Piece\n",
    "6-Piece\n",
    "72-Piece\n",
    "75-Piece\n",
    "77-Piece\n",
    "7-Piece\n",
    "800-Piece\n",
    "80-Piece\n",
    "84-Piece\n",
    "86-Piece\n",
    "89-Piece\n",
    "8-Piece\n",
    "90-Piece\n",
    "9-Piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10 Piece Set\n",
    "11 Piece Set\n",
    "12 Piece Set\n",
    "13 Piece Set\n",
    "14 Piece Set\n",
    "15 Piece Set\n",
    "16 Piece Set\n",
    "17 Piece Set\n",
    "18 Piece Set\n",
    "19 Piece Set\n",
    "1 Piece\n",
    "20+ Piece Set\n",
    "2 Piece Set\n",
    "3 Piece Set\n",
    "4 Piece Set\n",
    "5 Piece Set\n",
    "6 Piece Set\n",
    "7 Piece Set\n",
    "8 Piece Set\n",
    "9 Piece Set\n",
    "n/a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "df=import_one_att('shape')\n",
    "shape=df.loc[(df['attribute'].astype(str)=='shape')&((df['value'].astype(str)=='Oblong')|(df['value'].astype(str)=='Rectangle')|(df['value'].astype(str)=='Traditional')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                    \n",
    "print(len(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape['Q:shape']=''\n",
    "match_shape=shape[['external_id','Q:shape']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_shape{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "Oblong\n",
    "Rectangle\n",
    "Traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Backrest\n",
    "Bolster\n",
    "Novelty\n",
    "Oval\n",
    "Rectangular\n",
    "Round\n",
    "Square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('shelf_weight_capacity')\n",
    "# shelf_weight_capacity=df.loc[(df['attribute'].astype(str)=='shelf_weight_capacity')&((df['value'].astype(str)=='11 lb')|(df['value'].astype(str)=='26.5 lb')|(df['value'].astype(str)=='44 lb')|(df['value'].astype(str)=='5 lb')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)(lb(?!s))'''\n",
    "shelf=filters(df,pat)\n",
    "print(len(shelf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf['Q:shelf_weight_capacity']=shelf['value'].apply(lambda x: re.sub(r'((?:\\d+\\,?)?\\d\\d\\d+(?:\\.\\d+)?\\s?lbs?)','100 lbs and Greater',str(x)))\n",
    "shelf['Q:shelf_weight_capacity']=shelf['Q:shelf_weight_capacity'].apply(lambda x: re.sub(r'((?<!\\d)(?<!\\,)(?<!\\.)(?:1[0-9]|[0-9]|2[0-4])(?:\\.\\d+)?\\s?lbs?)','1 - 24 lbs',str(x)))\n",
    "shelf['Q:shelf_weight_capacity']=shelf['Q:shelf_weight_capacity'].apply(lambda x: re.sub(r'((?<!\\d)(?<!\\,)(?<!\\.)(?:2[5-9]|3[0-9]|4[0-9])(?:\\.\\d+)?\\s?lbs?)','25 - 49 lbs',str(x)))\n",
    "shelf['Q:shelf_weight_capacity']=shelf['Q:shelf_weight_capacity'].apply(lambda x: re.sub(r'((?<!\\d)(?<!\\,)(?<!\\.)(?:5[0-9]|6[0-9]|7[0-4])(?:\\.\\d+)?\\s?lbs?)','50 - 74 lbs',str(x)))\n",
    "shelf['Q:shelf_weight_capacity']=shelf['Q:shelf_weight_capacity'].apply(lambda x: re.sub(r'((?<!\\d)(?<!\\,)(?<!\\.)(?:7[5-9]|8[0-9]|9[0-9])(?:\\.\\d+)?\\s?lbs?)','75 - 99 lbs',str(x)))\n",
    "shelf['Q:shelf_weight_capacity']=shelf['Q:shelf_weight_capacity'].apply(lambda x: re.sub(r'\\[\"25 \\- 49 lbs\",\"25 - 49 lbs\"\\]','25 - 49 lbs',str(x)))\n",
    "\n",
    "\n",
    "# ((?:\\d+\\,?)?\\d\\d\\d+(?:\\.\\d+)?\\s?lbs?)|\n",
    "# ((?<!\\d)(?<!\\,)(?<!\\.)(?:1[0-9]|[0-9]|2[0-4])(?:\\.\\d+)?\\s?lbs?)|\n",
    "# ((?<!\\d)(?<!\\,)(?<!\\.)(?:2[5-9]|3[0-9]|4[0-9])(?:\\.\\d+)?\\s?lbs?)|\n",
    "# ((?<!\\d)(?<!\\,)(?<!\\.)(?:5[0-9]|6[0-9]|7[0-4])(?:\\.\\d+)?\\s?lbs?)|\n",
    "# ((?<!\\d)(?<!\\,)(?<!\\.)(?:7[5-9]|8[0-9]|9[0-9])(?:\\.\\d+)?\\s?lbs?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf['Q:shelf_weight_capacity']=''\n",
    "match_shelf_weight_capacity=shelf[['external_id','Q:shelf_weight_capacity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_shelf_weight_capacity{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_shelf_weight_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shelf_weight_capacity\n",
    "11 lb\n",
    "26.5 lb\n",
    "44 lb\n",
    "5 lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100 lbs and Greater\n",
    "1 - 24 lbs\n",
    "25 - 49 lbs\n",
    "50 - 74 lbs\n",
    "75 - 99 lbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done wiped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=import_one_att('size')\n",
    "size=df.loc[(df['attribute'].astype(str)=='[]')&((df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]')|(df['value'].astype(str)=='[]'))]                     \n",
    "pat='''(?i)((?:year|16 to 20|one(?! size)|over 25))'''\n",
    "size_df=filters(df,pat)\n",
    "print(len(size_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size\n",
    "10 Years\n",
    "12 Years\n",
    "14 Years\n",
    "16 to 20\n",
    "1 to 2 Years\n",
    "2 Years\n",
    "3 Years\n",
    "4 Years\n",
    "5 Years\n",
    "6 Years\n",
    "7 Years\n",
    "8 Years\n",
    "9 to 10 Years\n",
    "One\n",
    "Over 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0-3 Months\n",
    "0-6 Months\n",
    "12-18 Months\n",
    "12-24 Months\n",
    "18-24 Months\n",
    "2T\n",
    "2X-Large\n",
    "3-6 Months\n",
    "3T\n",
    "3X-Large\n",
    "4T\n",
    "5T\n",
    "6-12 Months\n",
    "6-9 Months\n",
    "6T\n",
    "9-12 Months\n",
    "Infant\n",
    "Large\n",
    "Large (10-12)\n",
    "Medium\n",
    "Medium (8)\n",
    "Newborn\n",
    "One Size\n",
    "Preemie\n",
    "Size 1\n",
    "Size 10\n",
    "Size 11\n",
    "Size 12\n",
    "Size 13\n",
    "Size 2\n",
    "Size 3\n",
    "Size 4\n",
    "Size 5\n",
    "Size 6\n",
    "Size 7\n",
    "Size 8\n",
    "Size 9\n",
    "Small\n",
    "Small\n",
    "Small (6/7)\n",
    "Toddler\n",
    "X-Large\n",
    "X-Large (14-16)\n",
    "X-Small\n",
    "X-Small (4/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.DataFrame()\n",
    "y=pd.DataFrame()\n",
    "tripz='''((?:California.King|European|Full|Futon|King|Queen|Single|Sofa|Split|Standard|Twin|n\\/a))|()''' \n",
    "def att(df,attribute,trip):\n",
    "    x=df[df['attribute'].astype(str)==attribute]\n",
    "    trips=trip          \n",
    "    x['match']=x['value'].apply(lambda x: re_extract(trips,str(x))) \n",
    "    y=x[x['match'].astype(str)=='[]']\n",
    "    return x,y\n",
    "\n",
    "x,air=att(dfs,attribut,tripz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Q:bed_bedding_size, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air[f'Q:{attribut}']=air['value'].apply(lambda x: re.sub(r'','',str(x)))\n",
    "air[f'Q:{attribut}'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n/a                                                            883\n",
       "King                                                           421\n",
       "Queen                                                          303\n",
       "Twin                                                           291\n",
       "Full                                                           171\n",
       "[\"Full\",\"Queen\"]                                               151\n",
       "[\"Full\",\"King\",\"Queen\",\"Twin\"]                                 132\n",
       "Standard                                                        79\n",
       "California King                                                 24\n",
       "[\"California King\",\"King\"]                                      21\n",
       "Twin XL                                                         17\n",
       "[\"Twin\",\"Twin XL\"]                                              14\n",
       "[\"Full\",\"King\",\"Queen\"]                                         12\n",
       "Sofa                                                             6\n",
       "[\"King\",\"Queen\"]                                                 6\n",
       "[\"Standard\",\"Twin\"]                                              4\n",
       "[\"King\",\"Split\"]                                                 4\n",
       "[\"King\",\"Queen\",\"Standard\",\"Twin\"]                               3\n",
       "[\"King\",\"Standard\"]                                              3\n",
       "[\"King\",\"Queen\",\"Twin\"]                                          3\n",
       "[\"Full\",\"King\",\"Queen\",\"Standard\",\"Twin\"]                        3\n",
       "[\"Full\",\"Queen\",\"Standard\"]                                      3\n",
       "[\"Full\",\"Twin\"]                                                  3\n",
       "[\"California King\",\"Full\",\"King\",\"Queen\",\"Twin\"]                 2\n",
       "Futon                                                            2\n",
       "[\"Full\",\"King\",\"Queen\",\"Twin\",\"Twin XL\"]                         2\n",
       "[\"Full\",\"Queen\",\"Twin\"]                                          2\n",
       "European                                                         2\n",
       "[\"King\",\"Twin\"]                                                  2\n",
       "[\"California King\",\"Full\",\"King\",\"Queen\",\"Standard\",\"Twin\"]      1\n",
       "[\"Full\",\"Queen\",\"Standard\",\"Twin\"]                               1\n",
       "[\"King\",\"Queen\",\"Standard\"]                                      1\n",
       "[\"Full\",\"King\",\"Queen\",\"Standard\"]                               1\n",
       "[\"Queen\",\"Twin\"]                                                 1\n",
       "[\"Futon\",\"Split\"]                                                1\n",
       "[\"Full\",\"Twin\",\"Twin XL\"]                                        1\n",
       "[\"European\",\"King\",\"Queen\",\"Twin\"]                               1\n",
       "[\"California King\",\"Full\",\"King\",\"Queen\",\"Twin XL\"]              1\n",
       "Full XL                                                          1\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>value</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200743482</td>\n",
       "      <td>Sofa</td>\n",
       "      <td>You deserve a cozy floor sofa for relaxation in this busy era! Our floor sofa features foldable design, which makes it unique and modern compared with the traditional one. What's more, with a premium metal frame inside the sofa, the backrest can be adjust at 6 positions within 90° to 180°, which allows you to find the most comfortable posture of your own, and also makes it possible to transform from sofa into bed. Features Adjustable backrest allows you to find a perfect tilt angle Comfortable sofa cushion with skin-friendly surface Premium metal frame makes it strong enough to support your body Foldable design makes it easy to move and store Wide application to serve as sofa and bed Specification Color Grey Material Steel + Corduroy + Sponge Flat Dimension 70.5'' x 42.5'' x 7'' (L x Wx H) Sofa Dimension 42.5'' x 22.5'' x 21'' (L x Wx H) Bearing Capacity 330 lbs Net Weight 29 lbs Package includes 1 x Adjustable Floor Sofa</td>\n",
       "      <td>[Sofa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200829434</td>\n",
       "      <td>Sofa</td>\n",
       "      <td>Our convertible sleeper chair is a perfect addition to any household . The unique folding design makes this chair easy to transform. It has multiple positions, such as a chair with armrests, chaise lounge or a bed. Featuring steel construction, this chair can retains its value over the long term. A pillow comes as a gift, which you can use as a pillow or cushion. You can put it in the living room, the bedroom, or even the office. Feature Constructed of high quality polyester, sponge and steel, provides lasting durability The outer cover can be removed for easy clean Folds up to an armrest chair, bed or chaise lounge seat Equipped with two casters for easier mobility Five adjustable position of backrest Filled with thick sponge for superior comfort Includes soft pillow for added comfort Specification Material Polyester + Steel + Sponge Overall dimension 26.5''Wx39''Dx31''H Seat size 25.5''Wx 23''Deep Height from seat to ground 15.5'';Back size 25.5'' x 16'' Weight capacity 330 Lbs Package includes 1 x Sofa Bed</td>\n",
       "      <td>[Sofa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>200903759</td>\n",
       "      <td>Futon</td>\n",
       "      <td>Slickblue Black Mid-Century Modern Linen Upholstered Sofa Bed with Classic Wood Legs Designed to handle your lifestyle, classic Sofa bed Futon is a Mid-Century-inspired classic design that looks great in any living-room. Easily converts from sofa to to a comfortable sleeping surface, and makes a great guest bed. Refined tapered wooden solid wood legs and diagonal stitching. Backrest offers multiple recline positions Wooden frame with tapered dowel legs Fabric upholstery in your choice of color Diagonal stitching Stylish Mid-Century feel Dimensions 78.5L x 32W x 33.5H in. Weight 86 lbs WARNING This product contains a chemical known to the State of California to cause cancer or birth defects or other reproductive harm.</td>\n",
       "      <td>[Futon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>200903870</td>\n",
       "      <td>Futon</td>\n",
       "      <td>Slickblue White Faux Leather Click Clack Adjustable Futon Sleeper Sofa This White Faux Leather Click Clack Adjustable Futon Sleeper Sofa provides functional and aesthetic furniture for any limited space. Crafted from a plywood frame, faux leather covering, foam fill, and strong metal spring, this convertible sofa bed features a flexible folding contraption to lock the back at 2 tilt angles for reading and lounging or lay it down as a comfy platform bed. With the solid construction, it can easily hold up to 770lb. The tufted faux leather upholstery presents an understated yet luxurious touch. Assembly Required Dimensions 31.5 inches D x 65.6 inches W x 30 inches H Max Weight 770 lbs. Weight 51 lbs. WARNING This product contains a chemical known to the State of California to cause cancer or birth defects or other reproductive harm</td>\n",
       "      <td>[Futon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>200903770</td>\n",
       "      <td>[\"Futon\",\"Split\"]</td>\n",
       "      <td>Slickblue Modern Grey Linen Split-Back Futon Sofa Bed Couch This Modern Grey Linen Split-Back Futon Sofa Bed Couch is made with a versatile split-back design, and is perfect for placement in a bedroom, bonus room, apartment, and more! The furniture provides guaranteed comfort as the result of its tufted plush linen fabric upholstery and hypoallergenic filling. Lounging with a friend has never been this convenient! Its split-back feature can accommodate two lounge preferences at once, as one half can recline into a flat position for a quick nap while the other remains up. This inviting piece of lounge furniture is available in a variety of colors, allowing you to select it in a shade that perfectly complements your living space's setup. Switch up your position of relaxation with the Modern Grey Linen Split-Back Futon Sofa Bed Couch! SPECIFICATIONS Couch Dimensions 75.5\\\"(L) x 28.25\\\"(W) x 33\\\"(H); Bed Dimensions 75.5\\\"(L) x 43\\\"(W) x 23\\\"(H); Floor-to-Seat Dimensions 13\\\"(H); Backrest Dimensions 69\\\"(L) x 6.5\\\"(W) x 20\\\"(H); Armrest Dimensions 23.5\\\"(L) x 4\\\"(W) x 16\\\"(H); Pillow Dimensions (2) 14\\\"(L) x 14\\\"(W) x 4\\\"(H); Weight Capacity 550 lbs.; Weight 97 lbs.; Color Light Sea Foam Gray; Material Linen Fabric; Assembly required (with instructions). Modern Grey Linen Split-Back Futon Sofa Bed Couch Plush futon made with versatile split-back design, perfect for placement in a bedroom, bonus room, apartment, and more Easily converts into a bed for overnight guests, made with comfortable upholstery and hypoallergenic filling Split-back feature can accommodate two lounge preferences at once one half can recline into a flat position while the other remains up Inviting appeal to perfectly complement your living space's setup Couch Dimensions 75.5\\\"(L) x 28.25\\\"(W) x 33\\\"(H) Bed Dimensions 75.5\\\"(L) x 43\\\"(W) x 23\\\"(H) Weight Capacity 550 lbs. Dimensions 42.5 x 35.4 x 15.2 inches Weight 97lbs. WARNING This product contains a chemical known to the State of California to cause cancer or birth defects or other reproductive harm</td>\n",
       "      <td>[Split, Futon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62786</th>\n",
       "      <td>200745715</td>\n",
       "      <td>[\"Full\",\"Queen\"]</td>\n",
       "      <td>Dress your bed in the whimsical paisley of the Veda quilt set. Sunny hues of orange, pink, yellow, and green create an allover paisley design that appeals to both modern and traditional styles. Reverse to a geometric tile print for an alternate look. Made of 100% cotton and machine washable for easy care. Complete your bedroom with coordinating accent pillows, euro shams and bed skirt available separately. UNIQUE DESIGN Refined floral arabesques evolve from paisley. Amaranth and orange pop with a hint of turquoise. Reverse follows a mosaic pattern in maize and turquoise. Luxury oversized, prewashed, cotton filled quilt HIGH QUALITY MATERIAL Cover is crafted of 100% cotton and provides long-lasting softness and durability. Bedspread is lightweight for comfortable all season year round use. Prewashed and Preshrunk. WHAT YOU GET This 3 piece full queen quilt set includes 1 quilt (90\\\" x 92\\\") and 2 standard shams (20\\\" x 26\\\"). Luxury oversized for today's larger mattresses. Coordinating accent pillows and bed skirt are available separately. EASY CARE Machine washable so it is great for families with kids or pets. Use it in your master bedroom, kid's room, guest room or vacation home. or cabin. Makes a great gift for birthday, anniversary or wedding. Pre-washed and pre-shrunk. Coordinating accent pillows, euro shams and bed skirt available separately</td>\n",
       "      <td>[Queen, Full]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62790</th>\n",
       "      <td>200751563</td>\n",
       "      <td>[\"Full\",\"Queen\"]</td>\n",
       "      <td>Create your own seaside escape with the Key Biscayne Mini Set. Displaying a colorful coastal pattern of crabs, shells, coral, fish, and sea urchins layered in a sketch-style allover print, this set borrows color from an on-trend palette of Aegean, Rust, Gold, and Crimson with a reversible Aegean-on-white seaside print. Machine washable for easy care. Enjoy the serenity of the sea, wherever you are with this beautiful coastal bedding set from C&amp;F Home. Crafted of cotton, this reversible quilt set includes a quilt and coordinating sham(s). Machine washable for easy care. Twin sets include 1 standard sham and 1 quilt. Queen sets include 2 standard shams and 1 quilt. King sets include 2 king shams and 1 quilt. Additional accessories sold separately.</td>\n",
       "      <td>[Queen, Full]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62799</th>\n",
       "      <td>200751553</td>\n",
       "      <td>[\"Full\",\"Queen\"]</td>\n",
       "      <td>Beautiful handcrafted quilt set crafted in soft cotton. Flip to the reverse for an alternate look. These quilted cotton quilts are conveniently machine washable. Crafted of 100% cotton and machine washable for easy care. UNIQUE DESIGN Bring the joys of the Christmas season to life with the Holiday Ribbon quilt set. This classic festive design of evergreen sprigs, holly berries, and crimson ribbons transforms your bedroom with joy. Holiday Ribbon is perfect to coordinate with festive red, green, and white accents and to pair with your favorite flavor of hot chocolate. HIGH QUALITY MATERIAL Cover is crafted of 100% cotton and provides long-lasting softness and durability. Bedspread is lightweight for comfortable all season year round use. Prewashed and Preshrunk. WHAT YOU GET This 3 piece full queen quilt set includes 1 quilt (90\\\" x 92\\\") and 2 standard shams (20\\\" x 26\\\"). Luxury oversized for today's larger mattresses. Coordinating accent pillows and bed skirt are available separately. EASY CARE Machine washable so it is great for families with kids or pets. Use it in your bedroom, kid's room, guest room or vacation home. or cabin. Makes a great gift for birthday, anniversary or wedding. PERFECT FOR Use it in your bedroom, kid's room, guest room, vacation home, or condo. Makes a great gift for weddings, house warmings, birthdays, holidays and more. Coordinating euro shams, accent pillows and bed skirt are available separately</td>\n",
       "      <td>[Queen, Full]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62801</th>\n",
       "      <td>200745718</td>\n",
       "      <td>[\"Full\",\"Queen\"]</td>\n",
       "      <td>Escape to your cabin in the woods or lakefront property with the Bryson Retreat quilt set. This luxury oversized quilt features a plaid pattern overlaid with critters you may find visiting the lake. This quilt reverses to a coordinating plaid pattern and the entire set is machine washable for easy care. DIMENSIONS These quilt sets measure 90\\\" x 92\\\"; 20\\\" x 26\\\" and are the perfect size for your Full and Queen size beds. DESIGN DETAILS Cover is crafted of 100% cotton and features a poly-cotton fill material that provides long lasting softness, lightweight, high breathability, and durability UNIQUE DESIGN Create a rustic, cabin bedroom retreat with the Bryson Retreat collection. Features an all-over patchwork of evergreen trees and forest animals. A coordinating beige plaid pattern on the reverse gives you an additional layering option. EASY CARE All pieces were designed to be machine washable for ease of use. Machine wash cold and air-dry or tumble at a low speed. USES Use it in your bedroom, kid's room, guest room, vacation home, and condos. Makes a great gift for weddings, housewarmings and more. Coordinating euro shams, accent pillows and bed skirt are available separately.</td>\n",
       "      <td>[Queen, Full]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62803</th>\n",
       "      <td>200745717</td>\n",
       "      <td>[\"Full\",\"Queen\"]</td>\n",
       "      <td>Madison Aqua Bedding Parent Machine Washable. Pre-washed and Pre-shrunk. Handcrafted of Cotton. Reversible to a coordinating medallion lattice pattern Twin Set includes 1 Quilt + 1 Standard Sham- Full/Queen Set includes 1 Quilt + 2 Standard Shams- King Set includes 1 Quilt + 2 King Shams Luxury Oversized - Twin Dimensions 64\\\" x 86\\\"- Full/Queen Dimensions 90\\\" x 92\\\"- King Dimensions 108\\\" x 92\\\"</td>\n",
       "      <td>[Queen, Full]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2579 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      external_id              value  \\\n",
       "2       200743482               Sofa   \n",
       "15      200829434               Sofa   \n",
       "55      200903759              Futon   \n",
       "56      200903870              Futon   \n",
       "124     200903770  [\"Futon\",\"Split\"]   \n",
       "...           ...                ...   \n",
       "62786   200745715   [\"Full\",\"Queen\"]   \n",
       "62790   200751563   [\"Full\",\"Queen\"]   \n",
       "62799   200751553   [\"Full\",\"Queen\"]   \n",
       "62801   200745718   [\"Full\",\"Queen\"]   \n",
       "62803   200745717   [\"Full\",\"Queen\"]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   long_desc  \\\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    You deserve a cozy floor sofa for relaxation in this busy era! Our floor sofa features foldable design, which makes it unique and modern compared with the traditional one. What's more, with a premium metal frame inside the sofa, the backrest can be adjust at 6 positions within 90° to 180°, which allows you to find the most comfortable posture of your own, and also makes it possible to transform from sofa into bed. Features Adjustable backrest allows you to find a perfect tilt angle Comfortable sofa cushion with skin-friendly surface Premium metal frame makes it strong enough to support your body Foldable design makes it easy to move and store Wide application to serve as sofa and bed Specification Color Grey Material Steel + Corduroy + Sponge Flat Dimension 70.5'' x 42.5'' x 7'' (L x Wx H) Sofa Dimension 42.5'' x 22.5'' x 21'' (L x Wx H) Bearing Capacity 330 lbs Net Weight 29 lbs Package includes 1 x Adjustable Floor Sofa   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Our convertible sleeper chair is a perfect addition to any household . The unique folding design makes this chair easy to transform. It has multiple positions, such as a chair with armrests, chaise lounge or a bed. Featuring steel construction, this chair can retains its value over the long term. A pillow comes as a gift, which you can use as a pillow or cushion. You can put it in the living room, the bedroom, or even the office. Feature Constructed of high quality polyester, sponge and steel, provides lasting durability The outer cover can be removed for easy clean Folds up to an armrest chair, bed or chaise lounge seat Equipped with two casters for easier mobility Five adjustable position of backrest Filled with thick sponge for superior comfort Includes soft pillow for added comfort Specification Material Polyester + Steel + Sponge Overall dimension 26.5''Wx39''Dx31''H Seat size 25.5''Wx 23''Deep Height from seat to ground 15.5'';Back size 25.5'' x 16'' Weight capacity 330 Lbs Package includes 1 x Sofa Bed   \n",
       "55                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Slickblue Black Mid-Century Modern Linen Upholstered Sofa Bed with Classic Wood Legs Designed to handle your lifestyle, classic Sofa bed Futon is a Mid-Century-inspired classic design that looks great in any living-room. Easily converts from sofa to to a comfortable sleeping surface, and makes a great guest bed. Refined tapered wooden solid wood legs and diagonal stitching. Backrest offers multiple recline positions Wooden frame with tapered dowel legs Fabric upholstery in your choice of color Diagonal stitching Stylish Mid-Century feel Dimensions 78.5L x 32W x 33.5H in. Weight 86 lbs WARNING This product contains a chemical known to the State of California to cause cancer or birth defects or other reproductive harm.   \n",
       "56                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Slickblue White Faux Leather Click Clack Adjustable Futon Sleeper Sofa This White Faux Leather Click Clack Adjustable Futon Sleeper Sofa provides functional and aesthetic furniture for any limited space. Crafted from a plywood frame, faux leather covering, foam fill, and strong metal spring, this convertible sofa bed features a flexible folding contraption to lock the back at 2 tilt angles for reading and lounging or lay it down as a comfy platform bed. With the solid construction, it can easily hold up to 770lb. The tufted faux leather upholstery presents an understated yet luxurious touch. Assembly Required Dimensions 31.5 inches D x 65.6 inches W x 30 inches H Max Weight 770 lbs. Weight 51 lbs. WARNING This product contains a chemical known to the State of California to cause cancer or birth defects or other reproductive harm   \n",
       "124    Slickblue Modern Grey Linen Split-Back Futon Sofa Bed Couch This Modern Grey Linen Split-Back Futon Sofa Bed Couch is made with a versatile split-back design, and is perfect for placement in a bedroom, bonus room, apartment, and more! The furniture provides guaranteed comfort as the result of its tufted plush linen fabric upholstery and hypoallergenic filling. Lounging with a friend has never been this convenient! Its split-back feature can accommodate two lounge preferences at once, as one half can recline into a flat position for a quick nap while the other remains up. This inviting piece of lounge furniture is available in a variety of colors, allowing you to select it in a shade that perfectly complements your living space's setup. Switch up your position of relaxation with the Modern Grey Linen Split-Back Futon Sofa Bed Couch! SPECIFICATIONS Couch Dimensions 75.5\\\"(L) x 28.25\\\"(W) x 33\\\"(H); Bed Dimensions 75.5\\\"(L) x 43\\\"(W) x 23\\\"(H); Floor-to-Seat Dimensions 13\\\"(H); Backrest Dimensions 69\\\"(L) x 6.5\\\"(W) x 20\\\"(H); Armrest Dimensions 23.5\\\"(L) x 4\\\"(W) x 16\\\"(H); Pillow Dimensions (2) 14\\\"(L) x 14\\\"(W) x 4\\\"(H); Weight Capacity 550 lbs.; Weight 97 lbs.; Color Light Sea Foam Gray; Material Linen Fabric; Assembly required (with instructions). Modern Grey Linen Split-Back Futon Sofa Bed Couch Plush futon made with versatile split-back design, perfect for placement in a bedroom, bonus room, apartment, and more Easily converts into a bed for overnight guests, made with comfortable upholstery and hypoallergenic filling Split-back feature can accommodate two lounge preferences at once one half can recline into a flat position while the other remains up Inviting appeal to perfectly complement your living space's setup Couch Dimensions 75.5\\\"(L) x 28.25\\\"(W) x 33\\\"(H) Bed Dimensions 75.5\\\"(L) x 43\\\"(W) x 23\\\"(H) Weight Capacity 550 lbs. Dimensions 42.5 x 35.4 x 15.2 inches Weight 97lbs. WARNING This product contains a chemical known to the State of California to cause cancer or birth defects or other reproductive harm   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
       "62786                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Dress your bed in the whimsical paisley of the Veda quilt set. Sunny hues of orange, pink, yellow, and green create an allover paisley design that appeals to both modern and traditional styles. Reverse to a geometric tile print for an alternate look. Made of 100% cotton and machine washable for easy care. Complete your bedroom with coordinating accent pillows, euro shams and bed skirt available separately. UNIQUE DESIGN Refined floral arabesques evolve from paisley. Amaranth and orange pop with a hint of turquoise. Reverse follows a mosaic pattern in maize and turquoise. Luxury oversized, prewashed, cotton filled quilt HIGH QUALITY MATERIAL Cover is crafted of 100% cotton and provides long-lasting softness and durability. Bedspread is lightweight for comfortable all season year round use. Prewashed and Preshrunk. WHAT YOU GET This 3 piece full queen quilt set includes 1 quilt (90\\\" x 92\\\") and 2 standard shams (20\\\" x 26\\\"). Luxury oversized for today's larger mattresses. Coordinating accent pillows and bed skirt are available separately. EASY CARE Machine washable so it is great for families with kids or pets. Use it in your master bedroom, kid's room, guest room or vacation home. or cabin. Makes a great gift for birthday, anniversary or wedding. Pre-washed and pre-shrunk. Coordinating accent pillows, euro shams and bed skirt available separately   \n",
       "62790                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Create your own seaside escape with the Key Biscayne Mini Set. Displaying a colorful coastal pattern of crabs, shells, coral, fish, and sea urchins layered in a sketch-style allover print, this set borrows color from an on-trend palette of Aegean, Rust, Gold, and Crimson with a reversible Aegean-on-white seaside print. Machine washable for easy care. Enjoy the serenity of the sea, wherever you are with this beautiful coastal bedding set from C&F Home. Crafted of cotton, this reversible quilt set includes a quilt and coordinating sham(s). Machine washable for easy care. Twin sets include 1 standard sham and 1 quilt. Queen sets include 2 standard shams and 1 quilt. King sets include 2 king shams and 1 quilt. Additional accessories sold separately.   \n",
       "62799                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Beautiful handcrafted quilt set crafted in soft cotton. Flip to the reverse for an alternate look. These quilted cotton quilts are conveniently machine washable. Crafted of 100% cotton and machine washable for easy care. UNIQUE DESIGN Bring the joys of the Christmas season to life with the Holiday Ribbon quilt set. This classic festive design of evergreen sprigs, holly berries, and crimson ribbons transforms your bedroom with joy. Holiday Ribbon is perfect to coordinate with festive red, green, and white accents and to pair with your favorite flavor of hot chocolate. HIGH QUALITY MATERIAL Cover is crafted of 100% cotton and provides long-lasting softness and durability. Bedspread is lightweight for comfortable all season year round use. Prewashed and Preshrunk. WHAT YOU GET This 3 piece full queen quilt set includes 1 quilt (90\\\" x 92\\\") and 2 standard shams (20\\\" x 26\\\"). Luxury oversized for today's larger mattresses. Coordinating accent pillows and bed skirt are available separately. EASY CARE Machine washable so it is great for families with kids or pets. Use it in your bedroom, kid's room, guest room or vacation home. or cabin. Makes a great gift for birthday, anniversary or wedding. PERFECT FOR Use it in your bedroom, kid's room, guest room, vacation home, or condo. Makes a great gift for weddings, house warmings, birthdays, holidays and more. Coordinating euro shams, accent pillows and bed skirt are available separately   \n",
       "62801                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Escape to your cabin in the woods or lakefront property with the Bryson Retreat quilt set. This luxury oversized quilt features a plaid pattern overlaid with critters you may find visiting the lake. This quilt reverses to a coordinating plaid pattern and the entire set is machine washable for easy care. DIMENSIONS These quilt sets measure 90\\\" x 92\\\"; 20\\\" x 26\\\" and are the perfect size for your Full and Queen size beds. DESIGN DETAILS Cover is crafted of 100% cotton and features a poly-cotton fill material that provides long lasting softness, lightweight, high breathability, and durability UNIQUE DESIGN Create a rustic, cabin bedroom retreat with the Bryson Retreat collection. Features an all-over patchwork of evergreen trees and forest animals. A coordinating beige plaid pattern on the reverse gives you an additional layering option. EASY CARE All pieces were designed to be machine washable for ease of use. Machine wash cold and air-dry or tumble at a low speed. USES Use it in your bedroom, kid's room, guest room, vacation home, and condos. Makes a great gift for weddings, housewarmings and more. Coordinating euro shams, accent pillows and bed skirt are available separately.   \n",
       "62803                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Madison Aqua Bedding Parent Machine Washable. Pre-washed and Pre-shrunk. Handcrafted of Cotton. Reversible to a coordinating medallion lattice pattern Twin Set includes 1 Quilt + 1 Standard Sham- Full/Queen Set includes 1 Quilt + 2 Standard Shams- King Set includes 1 Quilt + 2 King Shams Luxury Oversized - Twin Dimensions 64\\\" x 86\\\"- Full/Queen Dimensions 90\\\" x 92\\\"- King Dimensions 108\\\" x 92\\\"   \n",
       "\n",
       "                match  \n",
       "2              [Sofa]  \n",
       "15             [Sofa]  \n",
       "55            [Futon]  \n",
       "56            [Futon]  \n",
       "124    [Split, Futon]  \n",
       "...               ...  \n",
       "62786   [Queen, Full]  \n",
       "62790   [Queen, Full]  \n",
       "62799   [Queen, Full]  \n",
       "62801   [Queen, Full]  \n",
       "62803   [Queen, Full]  \n",
       "\n",
       "[2579 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[['external_id','value','long_desc','match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight_capacity            259\n",
       "shelf_weight_capacity      102\n",
       "lumens                      54\n",
       "size_width_cookware         23\n",
       "size_length_cookware        23\n",
       "drapery_length              21\n",
       "size_diameter_cookware      20\n",
       "minimum_recommended_age     10\n",
       "table_size                  10\n",
       "diameter_range               7\n",
       "table_height                 7\n",
       "step_count                   7\n",
       "btu_range                    4\n",
       "bulb_type                    4\n",
       "serving_cart_width           3\n",
       "fabric_weight_type           2\n",
       "service_size                 1\n",
       "leg_height                   1\n",
       "seat_depth                   1\n",
       "volume                       1\n",
       "seat_height                  1\n",
       "Name: Attribute, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g=pd.read_csv('Strategy Vs Curation Conflict Project - BedBath.csv')\n",
    "x=g[g['curation\\n(In curation but NOT in strategy)'].astype(str)!='nan']\n",
    "x['Attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "continuing\n",
      "dfs\n",
      "customs\n",
      "17094\n"
     ]
    }
   ],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2001-08-11'\n",
    "attribut='seat_depth'\n",
    "\n",
    "\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print('continuing')\n",
    "dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "print('dfs')\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "print('customs')\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "df=pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-18 Inches    1\n",
       "Name: Value, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc=x[x['Attribute'].astype(str)=='seat_depth']\n",
    "# rounding(wc, 'Value','ac-km-z')\n",
    "# wc_round=wc[wc['rounding'].astype(str)!='[]']\n",
    "# wc_round\n",
    "wc['Value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-6 Inches\n",
    "# 13-18 Inches\n",
    "# 19-24 Inches\n",
    "# 7-12 Inches\n",
    "# Greater than 24 Inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n/a                       13701\n",
       "19-24 Inches               2153\n",
       "13-18 Inches                826\n",
       "Greater than 24 Inches      374\n",
       "7-12 Inches                  26\n",
       "0-6 Inches                   14\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seat_depth=df[df['value'].astype(str)=='12-18 Inches']#['external_id']\n",
    "seat_depth['Q:seat_depth']='13-18 Inches'\n",
    "match_seat_depth=seat_depth[['external_id','Q:seat_depth']]\n",
    "# match_seat_depth\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_seat_depth{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_seat_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seat=df[df['value'].astype(str)=='12-18 Inches']\n",
    "seat['Q:seat_height']='13-18 Inches'\n",
    "match_seat_height=seat[['external_id','Q:seat_height']]\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_seat_height{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_seat_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>buckets</th>\n",
       "      <th>bucket_id</th>\n",
       "      <th>value</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>external_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>curated_date</th>\n",
       "      <th>resolution</th>\n",
       "      <th>curation_tasks.curated_by</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>COLOR</th>\n",
       "      <th>COLOR_s</th>\n",
       "      <th>SKU_SIZE</th>\n",
       "      <th>SKU_TYPE</th>\n",
       "      <th>Set_Size</th>\n",
       "      <th>RecordType</th>\n",
       "      <th>SKU_SIZE_s</th>\n",
       "      <th>COLOR_GROUP</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>s_f_binSize</th>\n",
       "      <th>COLORGROUP_s</th>\n",
       "      <th>VDC_SKU_TYPE</th>\n",
       "      <th>gbi_syn_size</th>\n",
       "      <th>Fill_Material</th>\n",
       "      <th>f_Product_Type</th>\n",
       "      <th>SKU_DESCRIPTION</th>\n",
       "      <th>s_f_binMaterial</th>\n",
       "      <th>Fabric_FiberType</th>\n",
       "      <th>LONG_DESCRIPTION</th>\n",
       "      <th>ROLLUP_TYPE_CODE</th>\n",
       "      <th>s_f_Product_Type</th>\n",
       "      <th>f_binProduct_Type</th>\n",
       "      <th>s_f_Fill_Material</th>\n",
       "      <th>s_f_Lifestyle_multi</th>\n",
       "      <th>s_f_Seat_Back_Style</th>\n",
       "      <th>s_f_binProduct_Type</th>\n",
       "      <th>PERSONALIZATION_TYPE</th>\n",
       "      <th>gbi_exp_product_type</th>\n",
       "      <th>gbi_syn_product_type</th>\n",
       "      <th>s_f_Fabric_FiberType</th>\n",
       "      <th>s_f_binFill_Material</th>\n",
       "      <th>MARKETPLACE_ITEM_FLAG</th>\n",
       "      <th>ASSEMBLEDPRODUCTWIDTHIN</th>\n",
       "      <th>ASSEMBLEDPRODUCTHEIGHTIN</th>\n",
       "      <th>ASSEMBLEDPRODUCTLENGTHIN</th>\n",
       "      <th>gbi_product_type_affinity</th>\n",
       "      <th>ASSEMBLEDPRODUCTDIAMETERIN</th>\n",
       "      <th>s_f_binHoliday_Tree_Height</th>\n",
       "      <th>s_f_binUpholstered_Material</th>\n",
       "      <th>s_f_binConstruction_Material</th>\n",
       "      <th>s_f_binSet_Size</th>\n",
       "      <th>s_f_binSeat_Depth</th>\n",
       "      <th>s_f_binSeat_Height</th>\n",
       "      <th>s_f_Chair_Type</th>\n",
       "      <th>MAX_ASSEMBLEDPRODUCTWIDTHIN</th>\n",
       "      <th>MIN_ASSEMBLEDPRODUCTWIDTHIN</th>\n",
       "      <th>MAX_ASSEMBLEDPRODUCTHEIGHTIN</th>\n",
       "      <th>MAX_ASSEMBLEDPRODUCTLENGTHIN</th>\n",
       "      <th>MIN_ASSEMBLEDPRODUCTHEIGHTIN</th>\n",
       "      <th>MIN_ASSEMBLEDPRODUCTLENGTHIN</th>\n",
       "      <th>s_f_Made_In</th>\n",
       "      <th>s_f_Arm_Style</th>\n",
       "      <th>s_f_Adjustable</th>\n",
       "      <th>s_f_Construction</th>\n",
       "      <th>s_f_Arm_Height_in</th>\n",
       "      <th>s_f_Pattern_Design</th>\n",
       "      <th>s_f_Exterior_Finish</th>\n",
       "      <th>s_f_Frame_Construction</th>\n",
       "      <th>s_f_Assembly_Instructions</th>\n",
       "      <th>s_f_Does_this_item_have_Wheels</th>\n",
       "      <th>s_f_Maximum_Weight_Capacity_lb</th>\n",
       "      <th>s_f_Soft_Textiles_Use_and_Care_Instructions</th>\n",
       "      <th>s_f_Cushioned</th>\n",
       "      <th>s_f_Additional_Treatment_Types</th>\n",
       "      <th>s_f_Chair_Style</th>\n",
       "      <th>s_f_Seat_Firmness</th>\n",
       "      <th>s_f_Chair_Width_in</th>\n",
       "      <th>s_f_Number_of_Batteries</th>\n",
       "      <th>s_f_Chair_Weight_Capacity_lbs</th>\n",
       "      <th>s_f_Number_of_Recline_Positions</th>\n",
       "      <th>HARMON_DESCRIPTION</th>\n",
       "      <th>s_f_Theme</th>\n",
       "      <th>s_f_Fold_Portability_multi</th>\n",
       "      <th>s_f_Detailed_Care_Instructions</th>\n",
       "      <th>s_f_Product_Durability_Features_multi</th>\n",
       "      <th>SERVICE_TYPE_CD</th>\n",
       "      <th>s_f_Cover_Fabric_Fiber</th>\n",
       "      <th>s_f_Arm_Length_in</th>\n",
       "      <th>s_f_Chair_Depth_in</th>\n",
       "      <th>s_f_Chair_Height_in</th>\n",
       "      <th>s_f_External_Finish</th>\n",
       "      <th>s_f_Ottoman_Depth_in</th>\n",
       "      <th>s_f_Ottoman_Width_in</th>\n",
       "      <th>s_f_Wood_Color_multi</th>\n",
       "      <th>s_f_Ottoman_Height_in</th>\n",
       "      <th>s_f_Embellishment_multi</th>\n",
       "      <th>s_f_Ottoman_Weight_Capacity_lbs</th>\n",
       "      <th>s_f_Water_Resistance_Repellant</th>\n",
       "      <th>s_f_Closure_Type</th>\n",
       "      <th>s_f_binOversized</th>\n",
       "      <th>Reversible_Fabric_Fiber</th>\n",
       "      <th>s_f_Indoor_Outdoor_Use</th>\n",
       "      <th>s_f_Team_Sports</th>\n",
       "      <th>s_f_College</th>\n",
       "      <th>s_f_Control_Type</th>\n",
       "      <th>s_f_binCord_Length</th>\n",
       "      <th>s_f_Stain_Resistance</th>\n",
       "      <th>s_f_L4_BBBY_Baby_Category</th>\n",
       "      <th>s_f_Recline</th>\n",
       "      <th>s_f_Harness_Type</th>\n",
       "      <th>s_f_High_Chair_Features_multi</th>\n",
       "      <th>s_f_Number_of_Height_Positions</th>\n",
       "      <th>Age_Requirements_Appropriateness</th>\n",
       "      <th>s_f_Lockable_Swivel_Wheels_multi</th>\n",
       "      <th>s_f_High_Chair_Items_Included_multi</th>\n",
       "      <th>s_f_binHealth_Therapy_Type</th>\n",
       "      <th>s_f_Hardware_Finish</th>\n",
       "      <th>WARRANTY_TYPE_s</th>\n",
       "      <th>s_f_Is_this_Item_Expandable</th>\n",
       "      <th>s_f_Frame_Color</th>\n",
       "      <th>s_f_binFloral_Type</th>\n",
       "      <th>s_f_binType_of_Art</th>\n",
       "      <th>s_f_binType_of_Wall_D_cor</th>\n",
       "      <th>s_f_binType_of_Beds</th>\n",
       "      <th>s_f_binCustomization_Type</th>\n",
       "      <th>s_f_Finish</th>\n",
       "      <th>s_f_License_multi</th>\n",
       "      <th>s_f_Baby_Kids_Theme_multi</th>\n",
       "      <th>s_f_Mattress_Construction</th>\n",
       "      <th>s_f_Frame_Finish</th>\n",
       "      <th>s_f_Converts_to_multi</th>\n",
       "      <th>s_f_Mattress_Thickness</th>\n",
       "      <th>s_f_Battery_Size</th>\n",
       "      <th>s_f_Battery_Type</th>\n",
       "      <th>s_f_Sound_Details</th>\n",
       "      <th>s_f_Number_of_Sounds</th>\n",
       "      <th>s_f_Number_of_Speed_Settings</th>\n",
       "      <th>s_f_Hardlines_Use_and_Care_multi</th>\n",
       "      <th>s_f_Number_of_Mattress_Support_Heights</th>\n",
       "      <th>s_f_Mattress_Foam_Construction_multi</th>\n",
       "      <th>s_f_Anti_Tip_Kit</th>\n",
       "      <th>s_f_Life_Stage_multi</th>\n",
       "      <th>s_f_Chair_Reclined_Depth_in</th>\n",
       "      <th>s_f_Ottoman_Features_multi</th>\n",
       "      <th>s_f_Seating_Features_multi</th>\n",
       "      <th>s_f_Pillow_Included</th>\n",
       "      <th>s_f_Ottoman_Included</th>\n",
       "      <th>s_f_Power_Source_multi</th>\n",
       "      <th>MAX_ASSEMBLEDPRODUCTDIAMETERIN</th>\n",
       "      <th>MIN_ASSEMBLEDPRODUCTDIAMETERIN</th>\n",
       "      <th>s_f_Number_of_Doors</th>\n",
       "      <th>s_f_Number_of_Hooks</th>\n",
       "      <th>s_f_Desk_Style_multi</th>\n",
       "      <th>s_f_Gender</th>\n",
       "      <th>Frame_Color</th>\n",
       "      <th>s_f_Fixture_Mounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [attribute, buckets, bucket_id, value, customer_name, external_id, product_name, long_desc, curated_date, resolution, curation_tasks.curated_by, TYPE, COLOR, COLOR_s, SKU_SIZE, SKU_TYPE, Set_Size, RecordType, SKU_SIZE_s, COLOR_GROUP, DESCRIPTION, s_f_binSize, COLORGROUP_s, VDC_SKU_TYPE, gbi_syn_size, Fill_Material, f_Product_Type, SKU_DESCRIPTION, s_f_binMaterial, Fabric_FiberType, LONG_DESCRIPTION, ROLLUP_TYPE_CODE, s_f_Product_Type, f_binProduct_Type, s_f_Fill_Material, s_f_Lifestyle_multi, s_f_Seat_Back_Style, s_f_binProduct_Type, PERSONALIZATION_TYPE, gbi_exp_product_type, gbi_syn_product_type, s_f_Fabric_FiberType, s_f_binFill_Material, MARKETPLACE_ITEM_FLAG, ASSEMBLEDPRODUCTWIDTHIN, ASSEMBLEDPRODUCTHEIGHTIN, ASSEMBLEDPRODUCTLENGTHIN, gbi_product_type_affinity, ASSEMBLEDPRODUCTDIAMETERIN, s_f_binHoliday_Tree_Height, s_f_binUpholstered_Material, s_f_binConstruction_Material, s_f_binSet_Size, s_f_binSeat_Depth, s_f_binSeat_Height, s_f_Chair_Type, MAX_ASSEMBLEDPRODUCTWIDTHIN, MIN_ASSEMBLEDPRODUCTWIDTHIN, MAX_ASSEMBLEDPRODUCTHEIGHTIN, MAX_ASSEMBLEDPRODUCTLENGTHIN, MIN_ASSEMBLEDPRODUCTHEIGHTIN, MIN_ASSEMBLEDPRODUCTLENGTHIN, s_f_Made_In, s_f_Arm_Style, s_f_Adjustable, s_f_Construction, s_f_Arm_Height_in, s_f_Pattern_Design, s_f_Exterior_Finish, s_f_Frame_Construction, s_f_Assembly_Instructions, s_f_Does_this_item_have_Wheels, s_f_Maximum_Weight_Capacity_lb, s_f_Soft_Textiles_Use_and_Care_Instructions, s_f_Cushioned, s_f_Additional_Treatment_Types, s_f_Chair_Style, s_f_Seat_Firmness, s_f_Chair_Width_in, s_f_Number_of_Batteries, s_f_Chair_Weight_Capacity_lbs, s_f_Number_of_Recline_Positions, HARMON_DESCRIPTION, s_f_Theme, s_f_Fold_Portability_multi, s_f_Detailed_Care_Instructions, s_f_Product_Durability_Features_multi, SERVICE_TYPE_CD, s_f_Cover_Fabric_Fiber, s_f_Arm_Length_in, s_f_Chair_Depth_in, s_f_Chair_Height_in, s_f_External_Finish, s_f_Ottoman_Depth_in, s_f_Ottoman_Width_in, s_f_Wood_Color_multi, s_f_Ottoman_Height_in, s_f_Embellishment_multi, s_f_Ottoman_Weight_Capacity_lbs, s_f_Water_Resistance_Repellant, ...]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['value'].astype(str)=='Midweight (450-550 GSM)')|(df['value'].astype(str)=='Lightweight (300-450 GSM)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKUs not in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: external_id, dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['value'].value_counts()\n",
    "\n",
    "bulb=df[(df['value'].astype(str)=='Standard Bulb')|(df['value'].astype(str)=='LED Bulb')|(df['value'].astype(str)=='Fluorescent Bulb')|(df['value'].astype(str)=='Specialty Bulb')]\n",
    "bulb['value'].explode().value_counts()\n",
    "bulb['external_id'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17094\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: value, dtype: int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips='''(?i)(\\d\\d\\-Step)|([6-9]\\-Step)|(5-Step)|()'''           \n",
    "df['match']=df['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "print(len(df))\n",
    "drap=df[(df['match'].astype(str)!='[]')]\n",
    "print(len(drap))\n",
    "drap['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "drap['Q:step_count']=drap['value'].apply(lambda x: re.sub(r'(?i)(\\d\\d\\-Step)|([6-9]\\-Step)|(5-Step)','5+ Step',str(x)))\n",
    "drap[['external_id','value','Q:step_count']]\n",
    "match_step=drap[['external_id','Q:step_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_step{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17094\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "trips='''(?i)((?<=\\d) (?!in)(?!\\d))|()'''           \n",
    "df['match']=df['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "print(len(df))\n",
    "drap=df[(df['match'].astype(str)!='[]')]\n",
    "print(len(drap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: Q:drapery_length, dtype: int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drap[['attribute','external_id','value','match']][0:500]\n",
    "drap['Q:drapery_length']=drap['value'].apply(lambda x:re.sub(r'(?i)((?<=\\d) (?!in)(?!\\d))',' in',str(x)))\n",
    "drap['Q:drapery_length'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_drape=drap[['external_id','Q:drapery_length']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_drape{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_drape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3393\n",
      "3393\n"
     ]
    }
   ],
   "source": [
    "trips='''(?i)(\\d+\\\\?\\s?-\\s?\\d+(?:\\.9)?\\s?(?:\\s?Inches)?)|(inches)|()'''           \n",
    "df['match']=df['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "a=df[(df['value'].astype(str)!='nan')&(df['value'].astype(str)!='n/a')]\n",
    "print(len(a))\n",
    "length=a[(a['match'].astype(str)!='[]')]\n",
    "print(len(length))\n",
    "\n",
    "length['Q:size_diameter_cookware']=length['value'].apply(lambda x: re.sub(r'(21\\\\ or Greater)','21 or Greater',str(x))).apply(lambda x: re.sub(r'(9(?:\\\\)?\\s?-\\s?11\\.9(?:\\\\)?(?:\\s?Inches)?)','9\" - 11.9\"',str(x))).apply(lambda x: re.sub(r'(6(?:\\\\)?\\s?-\\s?8\\.9(?:\\\\)?(?:\\s?Inches)?)','6\" - 8.9\"',str(x))).apply(lambda x: re.sub(r'(3(?:\\\\)?\\s?-\\s?5\\.9(?:\\\\)?(?:\\s?Inches)?)','3\" - 5.9\"',str(x))).apply(lambda x: re.sub(r'(18(?:\\\\)?\\s?-\\s?20\\.9(?:\\\\)?(?:\\s?Inches)?)','18\" - 20.9\"',str(x))).apply(lambda x: re.sub(r'(15(?:\\\\)?\\s?-\\s?17\\.9(?:\\\\)?(?:\\s?Inches)?)','15\" - 17.9\"',str(x))).apply(lambda x: re.sub(r'(0(?:\\\\)?\\s?-\\s?2\\.9(?:\\\\)?(?:\\s?Inches)?)','0\" - 2.9\"',str(x))).apply(lambda x: re.sub(r'(12(?:\\\\)? - 14\\.9(?:\\\\)?(?:\\s?Inches)?)','12\" - 14.9\"',str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "length[['external_id','value','Q:size_diameter_cookware']][0:500]\n",
    "length['Q:size_diameter_cookware'].explode().value_counts()\n",
    "match_diameter=length[['external_id','Q:size_diameter_cookware']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_diameter{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_diameter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(heights,col, texto):\n",
    "    regex_pattern_rounding=rf'''(?i)((?<!\\d)(?<!\\.)0(?!\\.))|(\\.0(?!\\d))|(\\.\\d0(?<!\\d))|(xa)|(\\\\)|([{texto}])|(\\')|(\\d\\d\\d\\d\\d(?!\\sin))|((?<![A-z])\"\\])|(\\d(?<![A-z])\")|(\"(?<!\\d).{0,3}[A-z]\")|((?<=[A-z])\\s\")|((?<=[A-z])\\.)|((?<!\\d)000)|((?<!\\d\\s)in)|((?<!\\w)(?<!\\.)(?<!\")0(?!\\.))|((?<!\")\\,)|(\\,(?!\"))|((?<!\")\\])|((?<!\\w)(?<!\\.)(?<!\")\\d(?!.\\w)(?!\\d)(?!\\.))|(\\-|ï|¿|½)|(ft.{0,4}in)|(\\(|\\))|(\"\\]\"\\])|(\\[\"\\[\")|(in\\d+)|(?<=\\[)\"(?=\\])|((?i)inft)|((?i)ftin)|((?<=\")(?:ft|in))|(\\d+\\..{3,4}\\/)|()'''         \n",
    "    heights['rounding'] = heights[col].apply(lambda x: re_extract(regex_pattern_rounding, x))\n",
    "    print('Number of SKUs that need Rounding: '+ str(len(heights[heights['rounding'].astype(str)!='[]'])))\n",
    "    return heights[heights['rounding'].astype(str)!='[]'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>value</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68836245</td>\n",
       "      <td>13-18 Inches</td>\n",
       "      <td>[18 In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69507193</td>\n",
       "      <td>13-18 Inches</td>\n",
       "      <td>[18 In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60475053</td>\n",
       "      <td>13-18 Inches</td>\n",
       "      <td>[18 In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66689768</td>\n",
       "      <td>13-18 Inches</td>\n",
       "      <td>[18 In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60474995</td>\n",
       "      <td>13-18 Inches</td>\n",
       "      <td>[18 In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17060</th>\n",
       "      <td>67204175</td>\n",
       "      <td>19-24 Inches</td>\n",
       "      <td>[24 In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17063</th>\n",
       "      <td>67203833</td>\n",
       "      <td>19-24 Inches</td>\n",
       "      <td>[24 In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17070</th>\n",
       "      <td>67203994</td>\n",
       "      <td>19-24 Inches</td>\n",
       "      <td>[24 In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17072</th>\n",
       "      <td>67203741</td>\n",
       "      <td>19-24 Inches</td>\n",
       "      <td>[24 In]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17088</th>\n",
       "      <td>69745268</td>\n",
       "      <td>19-24 Inches</td>\n",
       "      <td>[24 In]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3393 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      external_id         value  matches\n",
       "0        68836245  13-18 Inches  [18 In]\n",
       "1        69507193  13-18 Inches  [18 In]\n",
       "2        60475053  13-18 Inches  [18 In]\n",
       "3        66689768  13-18 Inches  [18 In]\n",
       "4        60474995  13-18 Inches  [18 In]\n",
       "...           ...           ...      ...\n",
       "17060    67204175  19-24 Inches  [24 In]\n",
       "17063    67203833  19-24 Inches  [24 In]\n",
       "17070    67203994  19-24 Inches  [24 In]\n",
       "17072    67203741  19-24 Inches  [24 In]\n",
       "17088    69745268  19-24 Inches  [24 In]\n",
       "\n",
       "[3393 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips='''(?i)(\\d (?!\\w)(?!-))|(\\d\\d\\d\\d)|((?<!\\.)(?<!\\d)\\d+ (?:L(?!b)|gal|in))|()'''           \n",
    "df['matches']=df['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "weight=df[df['matches'].astype(str)!='[]']\n",
    "# # rounding(df, 'value','ac-km-z')\n",
    "# df[df['value'].astype(str)=='42']\n",
    "# # df['value'].explode().value_counts()\n",
    "weight[['external_id','value','matches']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight['Q:shelf_weight_capacity']=''\n",
    "match_shelf_weight=weight[['external_id','Q:shelf_weight_capacity']]\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_shelf_weight{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_shelf_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d6bc79a58909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# cs=pd.read_csv('Strategy Vs Curation Conflict Project - .csv',header=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'curation\\n(In curation but NOT in strategy)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'nan'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Attribute'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cs' is not defined"
     ]
    }
   ],
   "source": [
    "# cs=pd.read_csv('Strategy Vs Curation Conflict Project - .csv',header=1)\n",
    "x=cs[cs['curation\\n(In curation but NOT in strategy)'].astype(str)!='nan']\n",
    "x['Attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x['Attribute'].astype(str)=='hanger_type']['Value'].explode().value_counts()\n",
    "# x[x['Value'].astype(str)=='features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia=df[df['attribute'].astype(str)=='features']#['value'].explode().value_counts()\n",
    "print(len(dia))\n",
    "dia[dia['value'].astype(str)=='[]']\n",
    "# lst=dia['value'].explode().value_counts().reset_index()['index'].to_list()\n",
    "# lst.sort()\n",
    "# lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs[cs['Attribute'].astype(str)=='material']#['Value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '144'\n",
    "customer_name='%motionapac%'\n",
    "dateszs='2021-01-01'\n",
    "attribut='inside_diameter'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print('continuing')\n",
    "dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "print('dfs')\n",
    "print(len(dfs))\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "print('customs')\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips='''(?i)(zinc)|()'''           \n",
    "dfz['matches']=dfz['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "dfz['match']=dfz['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "zinc=dfz[(dfz['matches'].astype(str)!='[]')&(dfz['match'].astype(str)=='[]')]\n",
    "print(len(zinc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '144'\n",
    "customer_name='%motionapac%'\n",
    "dateszs='2021-11-01'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "motion = query_from_file(file_name='../query/curated_all_attributes_date_family.sql', params=params)\n",
    "print(len(motion))\n",
    "# df['time']=df['time'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=motion[motion['attribute'].astype(str)=='material']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips='''(?i)(zinc)|()'''           \n",
    "dfz['matches']=dfz['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "dfz['match']=dfz['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "zinc=dfz[(dfz['matches'].astype(str)!='[]')&(dfz['match'].astype(str)=='[]')]\n",
    "print(len(zinc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zinc[zinc['external_id'].astype(str)=='10116993']\n",
    "zinc['value'].explode().value_counts()\n",
    "match=zinc[(zinc['value'].astype(str)=='Zinc')|(zinc['value'].astype(str)=='Zinc plated')]#[0:500]\n",
    "match['Q:material']='n/a'\n",
    "matches=match[['external_id','Q:material']]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match=zinc[(zinc['value'].astype(str)!='Zinc')&(zinc['value'].astype(str)!='Zinc plated')&(zinc['value'].astype(str)!='Zinc flake')]#[0:500]\n",
    "match['Q:material']=match['value'].apply(lambda x: re.sub(r'(?i)(\\,?\"Zinc\")','',str(x)))\n",
    "matches_material_not_zinc=match[['external_id','Q:material']]\n",
    "# match['Q:material'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}matches_material_not_zinc-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', matches_material_not_zinc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inside_diameter=motion[(motion['attribute'].astype(str)=='inside_diameter')&((motion['buckets'].astype(str)=='Fixings & Fasteners')|(motion['buckets'].astype(str)=='Fixings & Fasteners B')|(motion['buckets'].astype(str)=='Fixings & Fasteners C'))]\n",
    "\n",
    "inside_diameter=dfz[(dfz['attribute'].astype(str)=='inside_diameter')&(dfz['value'].astype(str)=='n/a')]\n",
    "print(len(inside_diameter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips='''(?i)(.{0,20}(?<!\\w)(?<!\\d)\\d+(?:[\\-]\\d+\\/\\d+|\\/\\d+|\\.\\d+)?[^\\d]{0,2}(?:inc?h?e?s?|mm|\"|''|')?.{0,2}x.{0,3}(?<!\\d)\\d+(?:.\\d+\\/\\d+|\\/\\d+|\\.\\d+)?.{0,3}.{0,20})|()'''           \n",
    "inside_diameter['matches']=inside_diameter['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)((?<!\\w)(?<!\\d)(?<!\\-)\\d{1,5}(?:[\\-]\\d+\\/\\d+|\\/\\d+|\\.\\d+)?(?!\\d)[^\\d]{0,2}(?:inc?h?e?s?|mm|\"|''|')?.{0,2}(?<!\\-)(?<!4)x(?!\\-).{0,3}(?<!\\d)\\d{1,5}(?:.\\d+\\/\\d+|\\/\\d+|\\.\\d+)?(?!\\d)[^\\d]{0,3})|()'''           \n",
    "inside_diameter['match']=inside_diameter['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "# x[['buckets','value','external_id','name','long_desc','match']]\n",
    "# x[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips='''(?i)(\\d+.{0,3}mm)|()'''           \n",
    "inside_diameter['mm']=inside_diameter['matches'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(\\d+.{0,3}(?:\"|in))|()'''           \n",
    "inside_diameter['in']=inside_diameter['matches'].apply(lambda x: re_extract(trips,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=inside_diameter[(inside_diameter['matches'].astype(str)!='[]')|(inside_diameter['match'].astype(str)!='[]')]\n",
    "print('total length: '+str(len(x)))\n",
    "\n",
    "fixing_b=x[x['buckets'].astype(str)=='Fixings & Fasteners B']\n",
    "print('fixing_b: '+str(len(fixing_b)))\n",
    "\n",
    "Sealants=x[x['buckets'].astype(str)=='Sealants']\n",
    "print('Sealants: '+str(len(Sealants)))\n",
    "\n",
    "Bearings=x[x['buckets'].astype(str)=='Bearings']\n",
    "print('Bearings: '+str(len(Bearings)))\n",
    "\n",
    "fixing=x[x['buckets'].astype(str)=='Fixings & Fasteners']\n",
    "print('fixing: '+str(len(fixing)))\n",
    "\n",
    "plastic=x[x['buckets'].astype(str)=='Plastic Raw Materials']\n",
    "print('plastic: '+str(len(plastic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del fixing_b['bucket_id']\n",
    "# del fixing_b['customer_name']\n",
    "# # del fixing_b['time']\n",
    "# del fixing_b['family_friendly']\n",
    "del fixing_b['resolution']\n",
    "del fixing_b['curation_tasks.curated_by']\n",
    "del fixing_b['buckets']\n",
    "del fixing_b['attribute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixing_b['Q:inside_diameter']=''\n",
    "match_fixing_b=fixing_b[['external_id','Q:inside_diameter']]\n",
    "\n",
    "Sealants['Q:inside_diameter']=''\n",
    "match_Sealants=Sealants[['external_id','Q:inside_diameter']]\n",
    "\n",
    "Bearings['Q:inside_diameter']=''\n",
    "match_Bearings=Bearings[['external_id','Q:inside_diameter']]\n",
    "\n",
    "fixing['Q:inside_diameter']=''\n",
    "match_fixing=fixing[['external_id','Q:inside_diameter']]\n",
    "\n",
    "plastic['Q:inside_diameter']=''\n",
    "match_plastic=plastic[['external_id','Q:inside_diameter']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_fixing_b-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_fixing_b) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_Sealants-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_Sealants) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_Bearings-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_Bearings) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_fixing-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_fixing) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_plastic-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_plastic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardware=x[x['buckets'].astype(str)=='General Hardware']\n",
    "print('hardware: '+str(len(hardware)))\n",
    "\n",
    "transmission=x[x['buckets'].astype(str)=='Transmission System & Driveline']\n",
    "print('transmission: '+str(len(transmission)))\n",
    "\n",
    "fixing_c=x[x['buckets'].astype(str)=='Fixings & Fasteners C']\n",
    "print('fixing_c: '+str(len(fixing_c)))\n",
    "\n",
    "hose_attatch=x[x['buckets'].astype(str)=='Hose Tools & Attachments']\n",
    "print('hose_attatch: '+str(len(hose_attatch)))\n",
    "\n",
    "Hoses=x[x['buckets'].astype(str)=='Hoses']\n",
    "print('Hoses: '+str(len(Hoses)))\n",
    "\n",
    "fuel=x[x['buckets'].astype(str)=='Fuel System']\n",
    "print('fuel: '+str(len(fuel)))\n",
    "\n",
    "\n",
    "hardware['Q:inside_diameter']=''\n",
    "match_hardware=hardware[['external_id','Q:inside_diameter']]\n",
    "\n",
    "transmission['Q:inside_diameter']=''\n",
    "match_transmission=transmission[['external_id','Q:inside_diameter']]\n",
    "\n",
    "fixing_c['Q:inside_diameter']=''\n",
    "match_fixing_c=fixing_c[['external_id','Q:inside_diameter']]\n",
    "\n",
    "hose_attatch['Q:inside_diameter']=''\n",
    "match_hose_attatch=hose_attatch[['external_id','Q:inside_diameter']]\n",
    "\n",
    "Hoses['Q:inside_diameter']=''\n",
    "match_Hoses=Hoses[['external_id','Q:inside_diameter']]\n",
    "\n",
    "fuel['Q:inside_diameter']=''\n",
    "match_fuel=fuel[['external_id','Q:inside_diameter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_hardware-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_hardware) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_transmission-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_transmission) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_fixing_c-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_fixing_c) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_hose_attatch-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_hose_attatch) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_Hoses-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_Hoses) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_fuel-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_fuel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machienery_brakes=x[x['buckets'].astype(str)=='Machinery Brakes & Clutches']\n",
    "print('machienery_brakes: '+str(len(machienery_brakes)))\n",
    "\n",
    "cooling=x[x['buckets'].astype(str)=='Cooling System']\n",
    "print('cooling: '+str(len(cooling)))\n",
    "\n",
    "conduit=x[x['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "print('conduit: '+str(len(conduit)))\n",
    "\n",
    "machienery_sprocket=x[x['buckets'].astype(str)=='Machinery Sprockets']\n",
    "print('machienery_sprocket: '+str(len(machienery_sprocket)))\n",
    "\n",
    "valves=x[x['buckets'].astype(str)=='Valves']\n",
    "print('valves: '+str(len(valves)))\n",
    "\n",
    "\n",
    "machienery_brakes['Q:inside_diameter']=''\n",
    "match_machienery_brakes=machienery_brakes[['external_id','Q:inside_diameter']]\n",
    "\n",
    "cooling['Q:inside_diameter']=''\n",
    "match_cooling=cooling[['external_id','Q:inside_diameter']]\n",
    "\n",
    "conduit['Q:inside_diameter']=''\n",
    "match_conduit=conduit[['external_id','Q:inside_diameter']]\n",
    "\n",
    "machienery_sprocket['Q:inside_diameter']=''\n",
    "match_machienery_sprocket=machienery_sprocket[['external_id','Q:inside_diameter']]\n",
    "\n",
    "valves['Q:inside_diameter']=''\n",
    "match_valves=valves[['external_id','Q:inside_diameter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_machienery_brakes-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_machienery_brakes) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_cooling-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_cooling) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_conduit-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_conduit) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_machienery_sprocket-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_machienery_sprocket) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_valves-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_valves) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bearings_in=Bearings[(Bearings['in'].astype(str)=='[]')&(Bearings['mm'].astype(str)!='[]')]\n",
    "print(len(Bearings_in))\n",
    "Bearings_in['Q:inside_diameter']=Bearings_in['match']#.apply(lambda x: re.sub(r'''(?i)(x.{0,10}(?='\\,))|(x.{0,10}(?='\\]))''','',str(x))).apply(lambda x: re.sub(r\"(')\",'\"',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\d)(?=\"\\]))|(\\s?mm\\s?)|((?<=\\d)\\s?(?=\"))',' mm',str(x))).apply(lambda x: re.sub(r'(\"\\s?,\\s?\")','\",\"',str(x))).apply(lambda x: re.sub(r'(\\.0(?!\\d))','',str(x)))                                     \n",
    "# rounding(Sealants_in, 'Q:inside_diameter','a-hj-mo-z')\n",
    "Bearings_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixing_b_in=fixing_b[(fixing_b['in'].astype(str)!='[]')&(fixing_b['mm'].astype(str)=='[]')]\n",
    "\n",
    "fixing_b_in['Q:inside_diameter']=fixing_b_in['match'].apply(lambda x: re.sub(r'''(?i)(x.{0,10}(?='\\,))|(x.{0,10}(?='\\]))''','',str(x))).apply(lambda x: re.sub(r'''(?i)((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|((?<=\\,)\\s?')|(\\s?'\\s?(?=\\,))''','\"',str(x))).apply(lambda x: re.sub(r'''(?i)((?<=\\d)(?:\\-|\\s?)(?:\"|inc?h?)(?!\\])(?!\\,)\\s?)|((?<=\\d)\\s?(?=\"))''',' in',str(x))).apply(lambda x: re.sub(r\"(')\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\s?,\\s?\")','\",\"',str(x))).apply(lambda x: re.sub(r'(\\.0(?!\\d))','',str(x)))                                     \n",
    "rounding(fixing_b_in, 'Q:inside_diameter','a-hj-mo-z')\n",
    "fixing_b_in_in=fixing_b_in[fixing_b_in['rounding'].astype(str)=='[]']\n",
    "print(len(fixing_b_in_in))\n",
    "\n",
    "fixing_b_in_in['Q:inside_diameter']=fixing_b_in_in['Q:inside_diameter'].apply(lambda x: re.sub(r'(\\s?(?<!\")(?=\\]))|(\"\")','\"',str(x))).apply(lambda x: re.sub(r'(\"\")','\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|(\\s?'\\s?(?=\\,))|((?<=\\,)\\s?'\\s?)''','\"',str(x))).apply(lambda x: re.sub(r'(\\s?(?<!\")(?=\\]))|(\"\")','\"',str(x))).apply(lambda x: re.sub(r'(\"\")','\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|(\\s?'\\s?(?=\\,))|((?<=\\,)\\s?'\\s?)''','\"',str(x)))                       \n",
    "fixing_b_in_in['Q:inside_diameter'].explode().value_counts()\n",
    "match_fixing_in=fixing_b_in_in[['external_id','Q:inside_diameter']]\n",
    "\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_fixing_in-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_fixing_in) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixing_b_mm=fixing_b[(fixing_b['mm'].astype(str)!='[]')&(fixing_b['in'].astype(str)=='[]')]\n",
    "print(len(fixing_b_mm))\n",
    "fixing_b_mm['Q:inside_diameter']=fixing_b_mm['match'].apply(lambda x: re.sub(r'''(?i)(x.{0,10}(?='\\,))|(x.{0,10}(?='\\]))''','',str(x))).apply(lambda x: re.sub(r\"(')\",'\"',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\d)(?=\"\\]))|(\\s?mm\\s?)|((?<=\\d)\\s?(?=\"))',' mm',str(x))).apply(lambda x: re.sub(r'(\"\\s?,\\s?\")','\",\"',str(x))).apply(lambda x: re.sub(r'(\\.0(?!\\d))','',str(x)))                                     \n",
    "fixing_b_mm#['Q:inside_diameter']\n",
    "rounding(fixing_b_mm, 'Q:inside_diameter','a-ln-z')\n",
    "\n",
    "fixing_b_mm_mm=fixing_b_mm[fixing_b_mm['rounding'].astype(str)=='[]']\n",
    "print(len(fixing_b_mm_mm))\n",
    "fixing_b_mm_mm['Q:inside_diameter']=fixing_b_mm_mm['Q:inside_diameter'].apply(lambda x: re.sub(r'(\\s?(?<!\")(?=\\]))|(\"\")','\"',str(x))).apply(lambda x: re.sub(r'(\"\")','\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|(\\s?'\\s?(?=\\,))|((?<=\\,)\\s?'\\s?)''','\"',str(x))).apply(lambda x: re.sub(r'(\\s?(?<!\")(?=\\]))|(\"\")','\"',str(x))).apply(lambda x: re.sub(r'(\"\")','\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|(\\s?'\\s?(?=\\,))|((?<=\\,)\\s?'\\s?)''','\"',str(x)))                       \n",
    "fixing_b_mm_mm['Q:inside_diameter'].explode().value_counts()\n",
    "fix=fixing_b_mm_mm[fixing_b_mm_mm['Q:inside_diameter'].astype(str)!='[\"5 M27 mm\",\"22 mm\",\"23.9 mm\"]']\n",
    "print(len(fix))\n",
    "match_fixing_mm=fix[['external_id','Q:inside_diameter']]\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_fixing_mm-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_fixing_mm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=\"(?i)(x(?!\\-).{0,3}(?<!\\d)\\d{1,5}(?:.\\d+\\/\\d+|\\/\\d+|\\.\\d+)?(?!\\d)[^\\d^\\,]{0,4}\\,)\"\n",
    "x=inside_diameter[inside_diameter['match'].astype(str)!='[]']\n",
    "x['comma']=x['match'].apply(lambda x: re_extract(trips,str(x)))\n",
    "com=x[x['comma'].astype(str)=='[]']\n",
    "# print(len(com))\n",
    "com[['external_id','value','name','long_desc','match']][0:500]\n",
    "\n",
    "\n",
    "trips='''(?i)((?<!\\w)(?<!\\d)(?<!M)\\d{1,5}(?:[\\-]\\d+\\/\\d+|\\/\\d+|\\.\\d+)?(?![a-hj-lo-z])(?!\\d)[^\\d]{0,2}(?:inc?h?e?s?|mm|\"|''|')?[^\\d]{0,2}(?<!\\-)(?<!4)(?<![A-z])x(?![A-z])(?!\\-)[^m]{0,3}(?<!\\d)(?<!M)\\d{1,5}(?:.\\d+\\/\\d+|\\/\\d+|\\.\\d+)?(?![a-hj-lo-z])(?!\\d)[^\\d\\/]{0,3}(?!\\/)(?!\\,))|()'''           \n",
    "com['mat']=com['match'].apply(lambda x: re_extract(trips,str(x)))\n",
    "inside=com[com['mat'].astype(str)!='[]']\n",
    "print(len(inside))\n",
    "inside[['external_id','value','name','long_desc','mat']][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips='(?i)([^\\,\\;]{0,30}inside.{0,10}dia[^\\,\\;]{0,50})|()'\n",
    "inside_diameter['matches']=inside_diameter['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "x=inside_diameter[inside_diameter['matches'].astype(str)!='[]']\n",
    "\n",
    "trips='''(?i)((?<!x)(?<!\\d)\\d+(?:.\\d+\\/\\d+|\\/\\d+|\\.\\d+)?(?!x)(?!\\d)[^\\,\\;\\d]{0,10}inside.{0,10}diameter(?!\\s\\d))|(inside.{0,10}diameter[^\\,\\;\\d]{0,10}\\d+(?:.\\d+\\/\\d+|\\/\\d+|\\.\\d+)?(?:.?in|.?millimeter|.?inc?h?|\\s?\"|\\s?''|.?mm|.?m|.?cm)?)|()'''           \n",
    "x['match']=x['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "y=x[x['match'].astype(str)!='[]']\n",
    "\n",
    "print(len(y))\n",
    "z=y[['value','buckets','external_id','matches','match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z['Q:inside_diameter']=''\n",
    "match_wipe_inside_diam=z[['external_id','Q:inside_diameter']]\n",
    "match_wipe_inside_diam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_wipe_inside_diam-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_wipe_inside_diam) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z['Q:inside_diameter']=z['match'].apply(lambda x: re.sub(r'(?i)(\\s?(?:Minimum|Maximum))|()','',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?Inc?h?\\.?)|(\")',' in',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?inside.{0,20}dia(?:meter)?\\:?\\s?)|(\\\\n)|(\\s?(?:hose|head)\\s?)|(\\((?:C|ID|[A-z]{0,3})\\))|(\\s?\\:\\s?)','',str(x))).apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'\"\\, \"','\",\"',str(x))).apply(lambda x: re.sub(r'(\\))|(\\()|((?:\\+\\/\\-))|((?<=\\.\\d)0+\\s)|((?<=\\.\\d\\d)0+\\s)|((?<=\\.\\d\\d\\d)0+\\s)','',str(x))).apply(lambda x: re.sub(r'((?<!\\d)\\.)','0.',str(x))).apply(lambda x: re.sub(r'''(?i)(\"0.3125 in\",\"5\\/16 in\")''','5\\/16 in',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?(?:mm|millimeter))',' mm',str(x)))                                          \n",
    "z[0:500]['Q:inside_diameter']\n",
    "z[0:500]['match']\n",
    "z[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(heights,col, texto):\n",
    "    regex_pattern_rounding=rf'''(?i)((?<!\\d)(?<!\\.)0(?!\\.))|(\\.0(?!\\d))|(\\.\\d0(?<!\\d))|(xa)|(\\\\)|([{texto}])|(\\')|(\\d\\d\\d\\d\\d(?!\\sin))|((?<![A-z])\"\\])|(\\d(?<![A-z])\")|(\"(?<!\\d).{0,3}[A-z]\")|((?<=[A-z])\\s\")|((?<=[A-z])\\.)|((?<!\\d)000)|((?<!\\d\\s)in)|((?<!\\w)(?<!\\.)(?<!\")0(?!\\.))|((?<!\")\\,)|(\\,(?!\"))|((?<!\")\\])|((?<!\\w)(?<!\\.)(?<!\")\\d(?!.\\w)(?!\\d)(?!\\.))|(\\-|ï|¿|½)|(ft.{0,4}in)|(\\(|\\))|(\"\\]\"\\])|(\\[\"\\[\")|(in\\d+)|(?<=\\[)\"(?=\\])|((?i)inft)|((?i)ftin)|((?<=\")(?:ft|in))|(\\d+\\..{3,4}\\/)|()'''         \n",
    "    heights['rounding'] = heights[col].apply(lambda x: re_extract(regex_pattern_rounding, x))\n",
    "    print('Number of SKUs that need Rounding: '+ str(len(heights[heights['rounding'].astype(str)!='[]'])))\n",
    "    return heights[heights['rounding'].astype(str)!='[]'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(heights,col, texto):\n",
    "    regex_pattern_rounding=rf'''(?i)((?<!\\d)(?<!\\.)0(?!\\.))|(\\.0(?!\\d))|(\\.\\d0(?<!\\d))|(xa)|(\\\\)|([{texto}])|(\\')|(\\d\\d\\d\\d\\d(?!\\sin))|((?<![A-z])\"\\])|(\\d(?<![A-z])\")|(\"(?<!\\d).{0,3}[A-z]\")|((?<=[A-z])\\s\")|((?<=[A-z])\\.)|((?<!\\d)000)|((?<!\\d\\s)in)|((?<!\\w)(?<!\\.)(?<!\")0(?!\\.))|((?<!\")\\,)|(\\,(?!\"))|((?<!\")\\])|((?<!\\w)(?<!\\.)(?<!\")\\d(?!.\\w)(?!\\d)(?!\\.))|(\\-|ï|¿|½)|(ft.{0,4}in)|(\\(|\\))|(\"\\]\"\\])|(\\[\"\\[\")|(in\\d+)|(?<=\\[)\"(?=\\])|((?i)inft)|((?i)ftin)|((?<=\")(?:ft|in))|(\\d+\\..{3,4}\\/)|()'''         \n",
    "    heights['rounding'] = heights[col].apply(lambda x: re_extract(regex_pattern_rounding, x))\n",
    "    print('Number of SKUs that need Rounding: '+ str(len(heights[heights['rounding'].astype(str)!='[]'])))\n",
    "    return heights[heights['rounding'].astype(str)!='[]'] \n",
    "\n",
    "rounding(z, 'Q:inside_diameter','a-eghj-lo-su-z*')\n",
    "inside=z[z['rounding'].astype(str)=='[]']\n",
    "print(len(inside))\n",
    "inside['Q:inside_diameter']=inside['Q:inside_diameter'].apply(lambda x: re.sub(r'(\\s?(?<!\")(?=\\]))|(\"\")','\"',str(x))).apply(lambda x: re.sub(r'(\"\")','\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|(\\s?'\\s?(?=\\,))|((?<=\\,)\\s?'\\s?)''','\"',str(x))).apply(lambda x: re.sub(r'0.3125 in\",\"5/16','5/16',str(x))).apply(lambda x: re.sub(r'  ',' ',str(x))).apply(lambda x: re.sub(r'((?<=\\d)mm)',' mm',str(x))).apply(lambda x: re.sub(r'((?<=\\.\\d)0+\\s)|((?<=\\.\\d\\d)0+\\s)|((?<=\\.\\d\\d\\d)0+\\s)','',str(x))).apply(lambda x: re.sub(r'\\.0mm',' mm',str(x)))                    \n",
    "inside['Q:inside_diameter'].explode().value_counts()\n",
    "rounding(inside, 'Q:inside_diameter','a-eghj-lo-su-z*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_insdie_diam=inside[['external_id','Q:inside_diameter']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_insdie_diam-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_insdie_diam) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins=z[z['rounding'].astype(str)!='[]']\n",
    "print(len(ins))\n",
    "ins['Q:inside_diameter']=''\n",
    "match_blank_ins=ins[['external_id','Q:inside_diameter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_blank_ins-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_blank_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_type=motion[(motion['attribute'].astype(str)=='thread_type')]\n",
    "# print(len(thread_type))\n",
    "\n",
    "trips='(?i)(mpt)|()'\n",
    "thread_type['mpt']=thread_type['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='(?i)(\\bmpt\\b)|()'\n",
    "thread_type['long_mpt']=thread_type['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "\n",
    "\n",
    "threads=thread_type[thread_type['mpt'].astype(str)!='[]']\n",
    "print(len(threads))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread=thread_type[(thread_type['mpt'].astype(str)!='[]')&(thread_type['long_mpt'].astype(str)=='[]')]\n",
    "print(len(thread))\n",
    "\n",
    "thread['Q:thread_type']=thread['value'].apply(lambda x: re.sub(r'(?i)(\\s?\\,?\\s?\"mpt\"\\,?\\s?)|()','',str(x))).apply(lambda x: re.sub(r'(?i)((?<!\")mpt(?!\"))','n/a',str(x)))\n",
    "thread['Q:thread_type'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_thread_type_MPT=thread[['external_id','Q:thread_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_thread_type_MPT-{today}.csv',index=False) \n",
    "looks_good('Motion APAC', match_thread_type_MPT) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_type=motion[(motion['attribute'].astype(str)=='product_type')&(motion['resolution'].astype(str)=='rules')]#&((motion['buckets'].astype(str)=='Fixings and Fasteners C')|(motion['buckets'].astype(str)=='Fixings and Fasteners B'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('start')\n",
    "fixing_fasteners=product_type[product_type['buckets'].astype(str)=='Fixings & Fasteners']\n",
    "Bearings=product_type[product_type['buckets'].astype(str)=='Bearings']\n",
    "fixing_fasteners=product_type[product_type['buckets'].astype(str)=='Fixings & Fasteners B']\n",
    "Machinery_Belts=product_type[product_type['buckets'].astype(str)=='Machinery Belts']\n",
    "fixing_fasteners=product_type[product_type['buckets'].astype(str)=='Fixings & Fasteners C']\n",
    "Sealants=product_type[product_type['buckets'].astype(str)=='Sealants']\n",
    "transmission=product_type[product_type['buckets'].astype(str)=='Transmission System & Driveline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips='(?i)(differentials)|()'\n",
    "transmission['differential']=transmission['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "trips='(?i)(torque.?converter)|()'\n",
    "transmission['torque_converter']=transmission['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "trips='(?i)(transfer.?case)|()'\n",
    "transmission['transfer_case']=transmission['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "trips='(?i)(transmission.?valve)|()'\n",
    "transmission['trans_value']=transmission['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "trips='(?i)(gears)|()'\n",
    "transmission['gears']=transmission['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "trips='(?i)(joint.{0,5}yokes?)|(yoke)|(CV.?joint)|(constant.?velocity.?joint)|(constant.?velocity.?yoke)|(u.?joints)|(universal.?joint)|(u.?yokes)|(QR.?yokes)|(quick.?release)|()'\n",
    "transmission['joints_yokes']=transmission['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "trips='(?i)(drive.?shaft)|(transmission.?shaft)|(constant.?velocity.?shaft)|(axle.?shaft)|(stub.?shaft)|(shafts)|()'\n",
    "transmission['shaft']=transmission['long_desc'].apply(lambda x: re_extract(trips,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(transmission))\n",
    "x=transmission[(transmission['differential'].astype(str)!='[]')|(transmission['torque_converter'].astype(str)=='[]')|(transmission['transfer_case'].astype(str)=='[]')|(transmission['trans_value'].astype(str)=='[]')|(transmission['gears'].astype(str)=='[]')|(transmission['joints_yokes'].astype(str)=='[]')|(transmission['shaft'].astype(str)=='[]')]                \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sealants\n",
    "# trips='''(?i)(Sealants?)|()'''\n",
    "# Sealants['sealant']=Sealants['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "\n",
    "# trips='''(?i)(Machinery.?Belts?)|()'''\n",
    "# Machinery_Belts['machine']=Machinery_Belts['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing and Fasteners\n",
    "trips='(?i)(.{0,10}(?:ball.?bearings?|mounted.?bearings?|Housings?|plain.?bearings?|roller.?bearings?).{0,10})|()'\n",
    "fixing_fasteners['matches']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='(?i)(ball.?bearings?)|(Mounted.?bearings?(?:.?\\&.?housings?))|(plain.?bearings?)|(roller.?bearings?)|()'\n",
    "fixing_fasteners['match']=fixing_fasteners['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "\n",
    "trips='''(?i)(\\banchors?)|(hex.?nut.?sleeve)|(through.?bolt)|(screw.?bolt)|(masonry.?screw)|()'''\n",
    "fixing_fasteners['anchors']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(bearing.?sleeve)|(adaptor.?sleeve)|(withdrawal.?sleeve)|()'''\n",
    "fixing_fasteners['bearing_sleeve']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)((?<!through)(?<!through.)(?<!screw)(?<!screw.)\\bBolts)|()'''\n",
    "fixing_fasteners['bolts']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(\\bClamps?\\b)|()'''\n",
    "fixing_fasteners['clamps']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)((?:r.)?(?<!e)(?<!e.)(?:\\bClips?\\b))|(r.?pin)|()'''\n",
    "fixing_fasteners['clips']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(Fastener.?Assortments)|(\\bfasteners?\\b)|()'''\n",
    "fixing_fasteners['fasteners']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "print('one')\n",
    "\n",
    "trips='''(?i)(Gaskets.{0,4}Seals)|(\\bgaskets?\\b)|(\\bseals?\\b)|(mechanical.?seal)|(shaft.?seal)|(shaft.?collar)|(kammprofile)|(wiper.?seal)|()'''\n",
    "fixing_fasteners['gaskets']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(\\bGrommets?\\b)|()'''\n",
    "fixing_fasteners['grommet']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)((?<!masonry)(?<!masonry.)Nails(?!anchor)(?!.anchor))|()'''\n",
    "fixing_fasteners['nails']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(\\bNuts?\\b)|()'''\n",
    "fixing_fasteners['nuts']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(\\bPins?\\b)|()'''\n",
    "fixing_fasteners['pins']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(\\b(?:e.?clip.?|o.?|spiral.?|crescent.?)?Rings?)|(circlips?)|(c.?clips?)|(ferrules?)|()'''\n",
    "fixing_fasteners['ring']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(\\bRivets?)|()'''\n",
    "fixing_fasteners['rivets']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(Rods.{0,4}Studs)|(\\brods?\\b)|(\\bstuds?\\b)|(threaded.?rod)|(all.?thread.?rods?)|()'''\n",
    "fixing_fasteners['rods_studs']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "print('two')\n",
    "\n",
    "trips='''(?i)(\\b(?!<masonry)(?<!masonry.)Screws?(?!anchor)(?!.anchor)\\b)|(socket.?screw)|(button.?head.?screw)|(SHCS)|(head.?cap.?screw)|()'''\n",
    "fixing_fasteners['screws']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(\\bspacers?\\b)|()'''\n",
    "fixing_fasteners['clamps']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(Staple.?Gun.?Staples)|()'''\n",
    "fixing_fasteners['staples']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(Suction.?Cups?)|()'''\n",
    "fixing_fasteners['suction_cups']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(Threaded.?Inserts?)|(nut.?inserts?)|(hex.?couplers?)|()'''\n",
    "fixing_fasteners['threaded_inserts']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    " \n",
    "trips='''(?i)(\\bTies?\\b)|()'''\n",
    "fixing_fasteners['ties']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "trips='''(?i)(\\bWashers?\\b)|()'''\n",
    "fixing_fasteners['washers']=fixing_fasteners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # bearings\n",
    "# trips='(?i)(Mounted.?bearings?(?:.?\\&.?housings?))|(bearing.?blocks?)|(bearing.?units?)|(pillow.?blocks?)|(flange.?mount.?bearings?)|(bearing.?hubs?)|(wheel.?bearing.?kits?)|(hub.?assemblys?)|()'\n",
    "# Bearings['mounted_bearings']=Bearings['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "# trips='(?i)(ball.?bearings?)|(insert.?bearings?)|(thrust.?bearings?)|(thrust.?washers?)|(deep.?groove)|(self.?aligning.?ball.?bearing)|(angular.?contact)|(ball.?transfer.?unit)|(radial.?bearing)|(tensioner.?bearing)|(idler.?bearing)|()'\n",
    "# Bearings['ball_bearing']=Bearings['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "# trips='(?i)(plain.?bearings?)|(bush(?:ing|ed).?bearing)|(rod.?end.?bearing)|(jewel.?bearing)|()'\n",
    "# Bearings['plain_bearing']=Bearings['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "# trips='(?i)(roller.?bearing)|()'\n",
    "# Bearings['roller_bearing']=Bearings['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "\n",
    "# print(len(Bearings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixing_fastenerz=fixing_fasteners[(fixing_fasteners['anchors'].astype(str)!='[]')|(fixing_fasteners['bearing_sleeve'].astype(str)!='[]')|(fixing_fasteners['bolts'].astype(str)!='[]')|(fixing_fasteners['clamps'].astype(str)!='[]')|(fixing_fasteners['clips'].astype(str)!='[]')|(fixing_fasteners['fasteners'].astype(str)!='[]')|(fixing_fasteners['gaskets'].astype(str)!='[]')|(fixing_fasteners['grommet'].astype(str)!='[]')|(fixing_fasteners['nails'].astype(str)!='[]')|(fixing_fasteners['nuts'].astype(str)!='[]')|(fixing_fasteners['pins'].astype(str)!='[]')|(fixing_fasteners['ring'].astype(str)!='[]')|(fixing_fasteners['rivets'].astype(str)!='[]')|(fixing_fasteners['rods_studs'].astype(str)!='[]')|(fixing_fasteners['clamps'].astype(str)!='[]')&(fixing_fasteners['staples'].astype(str)!='[]')|(fixing_fasteners['suction_cups'].astype(str)!='[]')|(fixing_fasteners['threaded_inserts'].astype(str)!='[]')|(fixing_fasteners['ties'].astype(str)!='[]')|(fixing_fasteners['washers'].astype(str)!='[]')]\n",
    "print(len(fixing_fastenerz))\n",
    "# fixing_fastenerz['value'].explode().value_counts()\n",
    "# fixing_fastenerz=fixing_fasteners[['external_id','anchors', 'bearing_sleeve', 'bolts', 'clamps', 'clips', 'fasteners', 'gaskets', 'grommet', 'nails', 'nuts', 'pins','ring', 'rivets' ,'rods_studs', 'screws', 'staples','suction_cups' ,'threaded_inserts','ties','washers']]\n",
    "# fixing_fastenerz[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix=fixing_fastenerz[(fixing_fastenerz['anchors'].astype(str)!='[]')|(fixing_fastenerz['bearing_sleeve'].astype(str)!='[]')|(fixing_fastenerz['bolts'].astype(str)!='[]')|(fixing_fastenerz['clamps'].astype(str)!='[]')|(fixing_fastenerz['clips'].astype(str)!='[]')|(fixing_fastenerz['fasteners'].astype(str)!='[]')|(fixing_fastenerz['gaskets'].astype(str)!='[]')|(fixing_fastenerz['grommet'].astype(str)!='[]')|(fixing_fastenerz['nails'].astype(str)!='[]')|(fixing_fastenerz['nuts'].astype(str)!='[]')|(fixing_fastenerz['pins'].astype(str)!='[]')|(fixing_fastenerz['ring'].astype(str)!='[]')|(fixing_fastenerz['rivets'].astype(str)!='[]')|(fixing_fastenerz['rods_studs'].astype(str)!='[]')|(fixing_fastenerz['clamps'].astype(str)!='[]')|(fixing_fastenerz['staples'].astype(str)!='[]')|(fixing_fastenerz['suction_cups'].astype(str)!='[]')|(fixing_fastenerz['threaded_inserts'].astype(str)!='[]')|(fixing_fastenerz['ties'].astype(str)!='[]')|(fixing_fastenerz['washers'].astype(str)!='[]')|(fixing_fastenerz['screws'].astype(str)!='[]')]\n",
    "fixing=fix[['value','resolution','external_id','anchors', 'bearing_sleeve', 'bolts', 'clamps', 'clips', 'fasteners', 'gaskets', 'grommet', 'nails', 'nuts', 'pins','ring', 'rivets' ,'rods_studs', 'screws', 'staples','suction_cups' ,'threaded_inserts','ties','washers']]\n",
    "x=fixing[(fixing['anchors'].astype(str)=='[]')&(fixing['bearing_sleeve'].astype(str)=='[]')&(fixing['bolts'].astype(str)=='[]')&(fixing['clamps'].astype(str)=='[]')&(fixing['clips'].astype(str)=='[]')&(fixing['fasteners'].astype(str)=='[]')&(fixing['gaskets'].astype(str)=='[]')&(fixing['grommet'].astype(str)=='[]')&(fixing['nails'].astype(str)=='[]')&(fixing['nuts'].astype(str)=='[]')&(fixing['pins'].astype(str)=='[]')&(fixing['ring'].astype(str)=='[]')&(fixing['rivets'].astype(str)=='[]')&(fixing['rods_studs'].astype(str)=='[]')&(fixing['clamps'].astype(str)=='[]')&(fixing['screws'].astype(str)=='[]')&(fixing['staples'].astype(str)=='[]')&(fixing['suction_cups'].astype(str)=='[]')&(fixing['threaded_inserts'].astype(str)=='[]')&(fixing['ties'].astype(str)=='[]')&(fixing['washers'].astype(str)=='[]')]\n",
    "print(len(x))\n",
    "x[0:500]\n",
    "\n",
    "\n",
    "x['Q:product_type']='Threaded Inserts'\n",
    "match_threaded_insert=x[['external_id','Q:product_type']]\n",
    "match_threaded_insert\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}-{today}match_threaded_insert-C.csv',index=False) \n",
    "looks_good('Motion APAC', match_threaded_insert) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power=product_type[(product_type['buckets'].astype(str)=='Power & Impact Drills/Drivers/Presses Accessories & Replacement Parts')]           \n",
    "print(len(power))\n",
    "\n",
    "trips=\"(?i)(\\bBatter(?:ies|y)?)|(battery.?charger)|(buffer)|(drill.?bit)|(rebar.?breaker)|(hole.?saw)|(extractor.?bit)|(eramer.?bit)|(nut.?setter)|(nose.?piece)|(nose.?assembl)|(nose.?top)|(piston)|(n\\/a)\"\n",
    "power['power']=power['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "power['match']=power['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "x=power[power['power'].astype(str)!='[]']\n",
    "print(len(x))\n",
    "x[['power','match']][0:500]\n",
    "\n",
    "\n",
    "# .apply(lambda x: re.sub(r'(?i)(nut.?setter)|(nose.?piece)|(nose.?assembl)|(nose.?top)|(piston)','',str(x)))\n",
    "\n",
    "\n",
    "\n",
    "# rebar breakers; hole saw bits; extractor bits; reamer bits\n",
    "x['Q:product_type']=x['power'].apply(lambda x: re.sub(r'(?i)(nut.?setter)|(nose.?piece)|(nose.?assembl)|(nose.?top)|(piston)','Nut Setters',str(x))).apply(lambda x: re.sub(r'(?i)(buffers?)','Buffers',str(x))).apply(lambda x: re.sub(r'(?i)(piston)','Piston',str(x))).apply(lambda x: re.sub(r'(?i)(Battery.?chargers?)','Battery Chargers',str(x))).apply(lambda x: re.sub(r'(?i)(?:hole.?saw|drill.?bit|extractor.?bit|reamer(?:.?bits?.?)?)','Drill Bits',str(x))).apply(lambda x: re.sub(r\"((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|(\\s?'\\s?(?=\\,))|((?<=\\,)\\s?'\\s?)\",'\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|(\\s?'\\s?(?=\\,))|((?<=\\,)\\s?'\\s?)''','\"',str(x)))                            \n",
    "x['Q:product_type'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0:500]\n",
    "not_drill=x[x['value'].astype(str)!='Drill Bits']\n",
    "print(len(x))\n",
    "match_power_product_type=x[['external_id','Q:product_type']]\n",
    "match_power_product_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}-{today}match_power_product_type-C.csv',index=False) \n",
    "looks_good('Motion APAC', match_power_product_type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensioners=product_type[(product_type['buckets'].astype(str)=='Tensioners')]  \n",
    "trips='(?i)(tensioner)|(winch.?bar)|()'\n",
    "Tensioners['Tensioners']=Tensioners['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "Tensioners['match']=Tensioners['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "x=Tensioners[Tensioners['Tensioners'].astype(str)!='[]']\n",
    "\n",
    "print(len(x))\n",
    "# x[['Tensioners','match']][0:500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vises=product_type[(product_type['buckets'].astype(str)=='Vises & Clamps')]  \n",
    "trips='(?i)(clamp)|(vises)|()'\n",
    "vises['vises']=vises['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "vises['match']=vises['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "x=vises[vises['vises'].astype(str)!='[]']\n",
    "\n",
    "print(len(x))\n",
    "x[['vises','value']][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_type=motion[(motion['attribute'].astype(str)=='product_type')&(motion['resolution'].astype(str)=='rules')]#&((motion['buckets'].astype(str)=='Fixings and Fasteners C')|(motion['buckets'].astype(str)=='Fixings and Fasteners B'))]\n",
    "product_type['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaft=motion[(motion['attribute'].astype(str)=='shaft_diameter')&(motion['value'].astype(str)=='n/a')]\n",
    "\n",
    "trips='(?i)(.{0,10}(?:shaft.?(?:dia|size)).{0,10})|()'\n",
    "shaft['matches']=shaft['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "shaft_diameter=shaft[(shaft['matches'].astype(str)!='[]')&((shaft['buckets'].astype(str)=='Fixings & Fasteners')|(shaft['buckets'].astype(str)=='Fixings & Fasteners B')|(shaft['buckets'].astype(str)=='Fixings & Fasteners C'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=motion[(motion['attribute'].astype(str)=='thread_size')&(motion['value'].astype(str)=='n/a')]\n",
    "print(len(size))\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips='(?i)(.{0,5}(?:M\\d+.?X))|()'\n",
    "size['matches']=size['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "trips='(?i)(.{0,5}(?:M\\d+.?X))|()'\n",
    "size['match']=size['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "thread_size=size[(size['matches'].astype(str)!='[]')|(size['match'].astype(str)!='[]')]\n",
    "print(len(thread_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread_size['value'].explode().value_counts()\n",
    "# print(len(thread_size))\n",
    "# thread_size[['external_id','matches','value']][0:500]\n",
    "# thread_size['Q:thread_size']=thread_size['matches'].apply(lambda x: re.sub(r'''(?i)((?<=').{0,6}(?=M\\d))|(x.{0,2}(?='))''','',str(x))).apply(lambda x: re.sub(r\"(\\s?'\\s?)\",'\"',str(x)))\n",
    "# thread_size['Q:thread_size']=thread_size['Q:thread_size']#.apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x)))      \n",
    "\n",
    "# thread_size['Q:thread_size'].explode().value_counts()[0:500]\n",
    "# thread_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread=motion[motion['attribute'].astype(str)=='thread_type']\n",
    "\n",
    "trips='(?i)(.{0,10}(?:316.?stainless).{0,10})|()'\n",
    "thread['matches']=thread['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "thread_type=thread[(thread['matches'].astype(str)!='[]')&(thread['value'].astype(str)!='Metric')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads=thread_type[thread_type['value'].astype(str)!='n/a']\n",
    "threads['value'].explode().value_counts()\n",
    "thread_type['value'].explode().value_counts()\n",
    "# threads\n",
    "# threads['Q:thread_type']=threads['value'].apply(lambda x: re.sub(r'(?i)(UNC\",\"UNF)','Metric',str(x))).apply(lambda x: re.sub(r'(?i)(metric\",\"UNC)|((?<=NPT\",\")UNC)|((?<=Internal\",\")UNC)|((?<=External\",\")UNC)|((?<=MPT\",\")UNC)|(UNC)|(Metric\",\"Metric)','Metric',str(x))) \n",
    "# threads['Q:thread_type']=threads['Q:thread_type'].apply(lambda x: re.sub(r'((?<=Internal\",\")Metric)|(((?<=NPT\"),\"Metric\"))|(((?<=NPTF\"),\"Metric\"))','',str(x)))\n",
    "# threads['Q:thread_type'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_thread_metric=threads[['external_id','Q:thread_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_thread_metric.csv',index=False) \n",
    "looks_good('Motion APAC', match_thread_metric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_bearing=product_type[(product_type['resolution'].astype(str)=='rules')&(product_type['buckets'].astype(str)=='Bearings')&(product_type['match'].astype(str)!=\"['Roller Bearings']\")&(product_type['match'].astype(str)!=\"['Ball Bearings']\")&(product_type['matches'].astype(str)==\"[]\")]                                           \n",
    "print(len(rule_bearing))\n",
    "rule_bearing[['external_id','buckets','matches','match']][500:1000]\n",
    "rule_bearing[500:1000]\n",
    "\n",
    "rule_bearing['Q:product_type']='n/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_bearing_na=rule_bearing[['external_id','Q:product_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_bearing_na.csv',index=False) \n",
    "looks_good('Motion APAC', match_bearing_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixings=product_type[(product_type['resolution'].astype(str)=='rules')&(product_type['buckets'].astype(str)=='Fixings & Fasteners')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips='(?i)(.{0,3}(?:\\banchors?\\b|\\bbearing.?sleeve|\\bbolts?\\b|\\bclamps?\\b|\\bclip|\\bfastener|\\bgaskets?|\\bseal|\\bgrommets|\\bnails?\\b|\\bnuts?\\b|\\bpins?\\b|\\brings?\\b|\\brivets\\b|\\brods?\\b|\\bscrews?\\b|\\bspacer|\\bstaple.?gun|\\bstaple|\\bsuction.?cup|\\bthreaded.?insert|tie|washer|stud).{0,3})|(bolt\\b)|()'\n",
    "fixings['matches']=fixings['long_desc'].apply(lambda x: re_extract(trips,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc='(?i)(.{0,3}(?:\\banchors?\\b|\\bbearing.?sleeve|\\bbolts?\\b|\\bclamps?\\b|\\bclip|\\bfastener|\\bgaskets?|\\bseal|\\bgrommets|\\bnails?\\b|\\bnuts?\\b|\\bpins?\\b|\\brings?\\b|\\brivets\\b|\\brods?\\b|\\bscrews?\\b|\\bspacer|\\bstaple.?gun|\\bstaple|\\bsuction.?cup|\\bthreaded.?insert|tie|washer|stud).{0,3})|(bolt\\b)|()'                 \n",
    "fixings['match']=fixings['value'].apply(lambda x: re_extract(abc,str(x)))\n",
    "x=fixings[(fixings['match'].astype(str)=='[]')&(fixings['matches'].astype(str)=='[]')]\n",
    "print(len(x))\n",
    "x[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixing_fasteners=product_type[(product_type['matches'].astype(str)!='[]')&(product_type['buckets'].astype(str)=='Fixings & Fasteners')&(product_type['resolution'].astype(str)=='rules')&(product_type['match'].astype(str)=='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fixing_fasteners))\n",
    "fixing_fasteners[['external_id','buckets','matches','match']][0:500]\n",
    "fixing_fasteners[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastener=product_type[product_type['value'].astype(str)=='Fastener Assortments']\n",
    "\n",
    "print('Start')\n",
    "trip='(?i)(.{0,7}pack)|()'\n",
    "fastener['matches']=fastener['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "fastener_assortment=fastener[fastener['matches'].astype(str)!='[]']\n",
    "\n",
    "fastener_assortment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread=motion[(motion['attribute'].astype(str)=='thread_size')]#&((motion['buckets'].astype(str)=='Fixings and Fasteners C')|(motion['buckets'].astype(str)=='Fixings and Fasteners B'))]\n",
    "\n",
    "print('Start')\n",
    "trip='(?i)(\\d.?mm)|()'\n",
    "thread['matches']=thread['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "thread_size=thread[thread['matches'].astype(str)!='[]']\n",
    "\n",
    "trip='(M\\d+.?(?:x|X).?\\d+.?mm)|()'\n",
    "thread_size['match']=thread_size['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "size=thread_size[thread_size['match'].astype(str)!='[]']\n",
    "size['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size['Q:thread_size']=size['match'].apply(lambda x: re.sub(r'''(?i)(\\s?x.+(?=\\']))|()''','',str(x))).apply(lambda x: re.sub(r\"'\",'\"',str(x)))\n",
    "size['Q:thread_size'].explode().value_counts()\n",
    "match_thread_size_M=size[['external_id','Q:thread_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_thread_size_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_thread_size_M.csv',index=False) \n",
    "looks_good('Motion APAC', match_thread_size_M) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt_length=motion[(motion['attribute'].astype(str)=='bolt_length')]#&((motion['buckets'].astype(str)=='Fixings and Fasteners C')|(motion['buckets'].astype(str)=='Fixings and Fasteners B'))]\n",
    "\n",
    "print('Start')\n",
    "trip='(?i)(bs[46]m)|()'\n",
    "bolt_length['matches']=bolt_length['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bolt_length['match']=bolt_length['name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "trip='(?i)(bolt)|()'\n",
    "bolt_length['boltes']=bolt_length['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bolt_length['bolt']=bolt_length['name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "\n",
    "\n",
    "bolt=bolt_length[(bolt_length['matches'].astype(str)=='[]')&(bolt_length['match'].astype(str)=='[]')&((bolt_length['boltes'].astype(str)!='[]')|(bolt_length['bolt'].astype(str)!='[]'))]\n",
    "print(len(bolt))\n",
    "bolts=bolt[bolt['value'].astype(str)!='n/a']\n",
    "print(len(bolts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolts['Q:bolt_length']='n/a'\n",
    "match_bolt_na=bolts[['external_id','Q:bolt_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_bolt_na.csv',index=False) \n",
    "looks_good('Motion APAC', match_bolt_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt_lengths=motion[(motion['attribute'].astype(str)=='bolt_length')]\n",
    "bolt_lengths['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_type=motion[motion['attribute'].astype(str)=='product_type']\n",
    "product_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_type['buckets'].explode().value_counts()\n",
    "fixings=product_type[product_type['buckets'].astype(str)=='Fixings & Fasteners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip='(?i)(anchors)|(bearing.?sleeve)|(\\bbolt)|(\\bclamps)|(\\bclips)|(fastener.?assortment)|(gasket.{0,5}seal)|(\\bgrommet)|(]bnails)|(\\bnuts)|(\\bpins)|(\\brings)|(rivet)|(rod.{0,5}stud)|(screws)|(spacers)|(staple.?gun.?staple)|(suction.?cup)|(threaded.?insert)|(\\bties)|(washers)|(ball.?bearing)|(mounted.?bearings)|(housing)|(nails)|(plain.?bearing)|(roller.?bearing)|(tensioner)'\n",
    "print('Start')\n",
    "fixings['matches']=fixings['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "types=fixings[fixings['matches'].astype(str)!='[]']\n",
    "# prod_type=types[types['value'].astype(str)!='n/a']\n",
    "print(len(types))\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "# threads=motion[motion['attribute'].astype(str)=='thread_type']\n",
    "\n",
    "trip=r'''(?i)([^\\w]ring)|()'''\n",
    "product_type['matches']=product_type['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "types=product_type[product_type['matches'].astype(str)!='[]']\n",
    "\n",
    "trip=r'''(?i)([^\\w]ring)|()'''\n",
    "product_type['matches']=product_type['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "types=product_type[product_type['matches'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)([\\w]ring)|()'''\n",
    "types['not_ring']=types['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "trip=r'''(?i)([^\\w]ring)|()'''\n",
    "types['ring']=types['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "ring=types[(types['ring'].astype(str)=='[]')&(types['not_ring'].astype(str)!='[]')]\n",
    "print(len(ring))\n",
    "ring['value'].explode().value_counts()\n",
    "ring['Q:product_type']=ring['value'].apply(lambda x: re.sub(r'(\\,?\"Rings\"\\,?)','',str(x)))\n",
    "ring['Q:product_type'].explode().value_counts()\n",
    "match_ring=ring[['external_id','Q:product_type']]\n",
    "match_ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_ring.csv',index=False) \n",
    "looks_good('Motion APAC', match_ring) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaft_diameter=motion[motion['attribute'].astype(str)=='shaft_diameter']\n",
    "# shaft_diameter['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "# threads=motion[motion['attribute'].astype(str)=='thread_type']\n",
    "\n",
    "trip=r'''(?i)(shaft.diameter(?!\\;)(?! \\;)(?! size)(?! from)(?! limit)(?!\\,)(?! \\,).{0,10}\\d+(?:\\.\\d+|\\s?\\d\\/\\d+|\\/\\d+)?\\s?(?:in|mm)?)|()'''\n",
    "shaft_diameter['matches']=shaft_diameter['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "shaft=shaft_diameter[shaft_diameter['matches'].astype(str)!='[]']\n",
    "print(len(shaft))\n",
    "# shaft['matches'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A\n",
    "# df['ones']=df['ones'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)]))\n",
    "# df['ones']=df['ones'].apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaft['Q:shaft_diameter']=shaft['matches'].apply(lambda x: re.sub(r'(?i)(shaft.?diameters?(?:\\s?\\=|\\:\\-|\\:\\s?| from| )?\\s?)|(\\\\n)|(\\(IN\\.?\\)\\:?\\s?)|(\\|.+(?=\\]))|(has\\s?)|()','',str(x)))\n",
    "shaft['Q:shaft_diameter']=shaft['Q:shaft_diameter'].apply(lambda x: re.sub(r\"(?i)(\\s?inc?h?)\",' in',str(x))).apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)')|(\\s?'(?=\\,))|((?<=\\,)\\s?')|(\\s?'\\s?(?=\\]))''','\"',str(x)))\n",
    "shaft['Q:shaft_diameter']=shaft['Q:shaft_diameter'].apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r'(\\.0+(?!\\d))|((?<=\\.\\d)0+(?!\\d))|((?<=\\.\\d\\d)0+(?!\\d))|((?<=\\.\\d\\d\\d)0+(?!\\d))','',str(x)))\n",
    "shaft['Q:shaft_diameter']=shaft['Q:shaft_diameter'].apply(lambda x: re.sub(r'((?<=\\d)(?=\"))',' in',str(x))).apply(lambda x: re.sub(r\"((?<=\\d)\\,\\s?(?=\\d))\",'\",\"',str(x)))\n",
    "shaft['Q:shaft_diameter']=shaft['Q:shaft_diameter'].apply(lambda x: re.sub(r'(\\s?(?<!\")(?=\\]))|(\"\")','\"',str(x))).apply(lambda x: re.sub(r'(\"\")','\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x)))\n",
    "shaft['Q:shaft_diameter']=shaft['Q:shaft_diameter'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\\s?(?<=\\d)(?=\"\\]))',' in',str(x)))\n",
    "\n",
    "\n",
    "shafts=shaft[(shaft['Q:shaft_diameter'].astype(str)!='[\"43556 in\"]')&(shaft['Q:shaft_diameter'].astype(str)!='[\"10416196 in\"]')&(shaft['Q:shaft_diameter'].astype(str)!='[\"Series H31 in\"]')&(shaft['Q:shaft_diameter'].astype(str)!='[\"10410640 in\"]')&(shaft['Q:shaft_diameter'].astype(str)!='[\"10421122 in\"]')&(shaft['Q:shaft_diameter'].astype(str)!='[\"10429840 in\"]')]\n",
    "# shafts['Q:shaft_diameter'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(\\d\\d\\d\\d\\d\\d)|(series)|()'''\n",
    "shaft['matches']=shaft['Q:shaft_diameter'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "trip=r'''(?i)(mm)|()'''\n",
    "shaft['mm']=shaft['Q:shaft_diameter'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "trip=r'''(?i)(in)|()'''\n",
    "shaft['in']=shaft['Q:shaft_diameter'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "shafts=shaft[(shaft['matches'].astype(str)=='[]')&((shafts['mm'].astype(str)=='[]')|(shafts['in'].astype(str)=='[]'))]\n",
    "match_shafts=shafts[['external_id','Q:shaft_diameter']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_shafts.csv',index=False) \n",
    "looks_good('Motion APAC', match_shafts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mounting_type=motion[motion['attribute'].astype(str)=='mounting_type']\n",
    "mounting_type['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "trip=r'''(?i)(316.?Stainless.{0,20})|()'''\n",
    "threads=motion[motion['attribute'].astype(str)=='thread_type']\n",
    "\n",
    "trips=r'''(?i)(bolt)|()'''\n",
    "\n",
    "threads['matches']=threads['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "threads['match']=threads['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "\n",
    "thread_type=threads[(threads['matches'].astype(str)!='[]')&(threads['match'].astype(str)!='[]')]\n",
    "print(len(thread_type))\n",
    "thread_type['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(thread_type))\n",
    "thread_type['value'].explode().value_counts()\n",
    "# thread_type[0:500]\n",
    "thread=thread_type[(thread_type['value'].astype(str)=='UNC')|(thread_type['value'].astype(str)=='UNF')]\n",
    "print(len(thread))\n",
    "thread['Q:thread_type']='Metric'\n",
    "match_thread=thread[['external_id','Q:thread_type']]\n",
    "match_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_thread.csv',index=False) \n",
    "looks_good('Motion APAC', match_thread) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion[motion['attribute'].astype(str)=='thread_type']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "moutning_type=motion[(motion['attribute'].astype(str)=='mounting_type')]\n",
    "print('continuing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moutning_type['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaft=motion[(motion['attribute'].astype(str)=='shaft_diameter')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start')\n",
    "trip=r'''(?i)(\\d+(?:.?\\d+\\/\\d+|\\.\\d+)\\s?in\\s?shaft.?diameter)|((?:\\d+\\.)?\\d+^[\\,\\w]{0,10}shaft diameter(?!\\:))|(shaft.?diameter\\:?\\s?\\d+(?:\\.\\d+|\\/\\d+)?(?:in|ft|\"|mm|\\s?inch)?)|()'''\n",
    "shaft['matches']=shaft['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print('continuing')\n",
    "# thread_types=thread_type[(thread_type['matches'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shaft_diameter=shaft[shaft['matches'].astype(str)!='[]']\n",
    "shaft_diameter['Q:shaft_diameter']=shaft_diameter['matches'].apply(lambda x: re.sub(r'(?i)(\\s?inch\\s?)',' in',str(x))).apply(lambda x: re.sub(r'(\\s?\\:\\s?)|(\\\\n)','',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?\"\\s?)|(\\s?in\\.?)|(\\s?inch\\s?)',' in',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?MM)',' mm',str(x))).apply(lambda x: re.sub(r'(?i)((?:\\s?\\-)?\\s?shaft.?diameter\\s?)','',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|((?<=,)\\s?'\\s?)|(\\s?'\\s?(?=\\,))''','\"',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?(?=\"))',' in',str(x))).apply(lambda x: re.sub(r'(?i)(\\.0\\s?in)',' in',str(x)))                                                                               \n",
    "shaft_diameter['Q:shaft_diameter'].explode().value_counts()\n",
    "print(len(shaft_diameter))\n",
    "rounding_kimball(shaft_diameter,'Q:shaft_diameter','a-eghj-lo-su-z')\n",
    "# shaft_diameter[shaft_diameter['value'].astype(str)!='n/a']['value'].explode().value_counts()\n",
    "\n",
    "# shaft_diameter['Q:shaft_diameter'].explode().value_counts()\n",
    "# shaft_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_shaft_diameter=shaft_diameter[['external_id','Q:shaft_diameter']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_shaft_diameter.csv',index=False) \n",
    "# looks_good('Motion APAC', match_shaft_diameter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Here is an example of an item code: BS6M1000401\n",
    "The 1st 4 characters indicate some sort of product informatin such as product type. \n",
    "The 5th & 6th character is the metric size. For example, if we have 'BS4M56****' the metric thread size is 56. \n",
    "The 7th-10th characters show the bolt length. For example, if we have 'BS4M**78**' the bolt length is 78\n",
    "The last character (11th) will have the values 1,2 or 3. If it is 1, then the product is a Bolt only, with NO nut. If it is 2, the product is a Bolt and Nut. if it is 3, it is a full threaded bolt (set screw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=motion[motion['matches'].astype(str)!='[]']\n",
    "bs['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(bs[46]M\\d*)|()'''\n",
    "bs['matches']=bs['name'].apply(lambda x: re_extract(trip,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs['matches'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt_types['Q:bolt_type'].explode().value_counts()\n",
    "full_threaded=bolt_typez[bolt_typez['Q:bolt_type'].astype(str)=='3']\n",
    "full_threaded['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt_type=bs[bs['attribute'].astype(str)=='bolt_type']\n",
    "bolt_type['Q:bolt_type']=bolt_type['matches'].apply(lambda x: x[-1][-1])\n",
    "bolt_types=bolt_type[bolt_type['matches'].astype(str)!='[]']\n",
    "bolt_types['Q:bolt_type'].explode().value_counts()\n",
    "bolt_typez=bolt_types[(bolt_types['Q:bolt_type'].astype(str)=='1')|(bolt_types['Q:bolt_type'].astype(str)=='3')|(bolt_types['Q:bolt_type'].astype(str)=='2')]\n",
    "bolt_only=bolt_typez[bolt_typez['Q:bolt_type'].astype(str)=='1']\n",
    "bolt_and_nut=bolt_typez[bolt_typez['Q:bolt_type'].astype(str)=='2']\n",
    "full_threaded=bolt_typez[bolt_typez['Q:bolt_type'].astype(str)=='3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt_only['Q:bolt_type']='Bolt Only'\n",
    "match_bolt_only=bolt_only[['external_id','Q:bolt_type']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_bolt_only.csv',index=False) \n",
    "looks_good('Motion APAC', match_bolt_only) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt_and_nut['Q:bolt_type']='Fully Threaded Bolt'\n",
    "match_bolt_and_nut=bolt_and_nut[['external_id','Q:bolt_type']]\n",
    "match_bolt_and_nut\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_bolt_and_nut.csv',index=False) \n",
    "looks_good('Motion APAC', match_bolt_and_nut) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_threaded['Q:bolt_type']='Bolt and Nut'\n",
    "match_full_threaded=full_threaded[['external_id','Q:bolt_type']]\n",
    "match_full_threaded\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_full_threaded.csv',index=False) \n",
    "looks_good('Motion APAC', match_full_threaded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_length=bs[bs['attribute'].astype(str)=='overall_length']\n",
    "print(len(overall_length))\n",
    "overall_length=overall_length[overall_length['matches'].astype(str)!='[]']\n",
    "overall_length['Q:overall_length']=overall_length['matches'].apply(lambda x: x[-1][6:10])\n",
    "print(len(overall_length))\n",
    "overall_length['Q:overall_length']=overall_length['Q:overall_length'].apply(lambda x: re.sub(r'((?<!\\d)0+(?=[1-9]))|()','',str(x))).apply(lambda x: re.sub(r'((?<=\\d)(?!\\d))',' mm',str(x)))\n",
    "overall_length['Q:overall_length'].explode().value_counts()\n",
    "\n",
    "match_overall_length=overall_length[['external_id','Q:overall_length']]\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_overall_length.csv',index=False) \n",
    "looks_good('Motion APAC', match_overall_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_size=bs[bs['attribute'].astype(str)=='thread_size']\n",
    "thread_size['Q:thread_size']=thread_size['matches'].apply(lambda x: x[-1][5:7])\n",
    "\n",
    "\n",
    "match_thread_size=thread_size[['external_id','Q:thread_size']]\n",
    "match_thread_size\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_thread_size.csv',index=False) \n",
    "looks_good('Motion APAC', match_thread_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs[bs['attribute'].astype(str)=='product_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_type['value'].explode().value_counts()\n",
    "thread_types['Q:thread_type']='Metric'\n",
    "thread_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_thread=thread_types[['external_id','Q:thread_type']]\n",
    "match_thread\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_thread.csv',index=False) \n",
    "# looks_good('Motion APAC', match_thread) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread_type=motion[(motion['attribute'].astype(str)=='thread_type')]\n",
    "# trip=r'''(?i)(bs[46]M)|()'''\n",
    "# thread_type['matches']=thread_type['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# thread_types=thread_type[(thread_type['matches'].astype(str)!='[]')]\n",
    "# thread_types['matches'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(Assembly)|(Bolt)|(Nut)|(Bolt Only)|(fully.?threaded.?bolt)|()'''\n",
    "bolt_type=motion[motion['attribute'].astype(str)=='bolt_type']\n",
    "bolt_type['matches']=bolt_type['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bolt_types=bolt_type[(bolt_type['matches'].astype(str)!='[]')]\n",
    "bolt_types['matches'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(bs[46]M.{7})|()'''\n",
    "bolt_types['matches']=bolt_types['name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bolt_typez=bolt_types[(bolt_types['matches'].astype(str)!='[]')]\n",
    "bolt_typez['matches'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt_typez['last_item']=bolt_typez['matches'].apply(lambda x: x[-1][-1])\n",
    "bolt_typez['last_item'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=bolt_typez[(bolt_typez['last_item'].astype(str)=='4')&(bolt_typez['value'].astype(str)=='Assembly')]\n",
    "# print(len(x))\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=bolt_typez['matches']\n",
    "# y=[]\n",
    "# # for i in range(len(x)):\n",
    "# #     print(x[i])\n",
    "# #     y.append(bolt_typez['matches'].iloc[x[i]][-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thread=motions[motions['attribute'].astype(str)=='thread_type']\n",
    "# print(len(thread))\n",
    "# thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kimball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '137'\n",
    "customer_name='%kimballmidwest%'\n",
    "dateszs='2001-06-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "print('Starting')\n",
    "kimb = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "# dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "print(len(kimb))\n",
    "\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['CanSize']\n",
    "# print('creating DataFrame')\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_tension=dfs[(dfs['attribute'].astype(str)=='maximum_tension')&(dfs['value'].astype(str)=='n/a')]\n",
    "\n",
    "trip='(?i)(.{0,20}\\btension\\b.{0,20})|()'                       \n",
    "maximum_tension['matches']=maximum_tension['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "maximum_tension['match'] = maximum_tension['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "maximum_tension['matchez'] = maximum_tension['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "tension=maximum_tension[(maximum_tension['matches'].astype(str)!='[]')|(maximum_tension['match'].astype(str)!='[]')|(maximum_tension['matchez'].astype(str)!='[]')]#['matchez'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside_diameter=dfs[(dfs['attribute'].astype(str)=='inside_diameter')&(dfs['value'].astype(str)=='n/a')]\n",
    "\n",
    "trip='(?i)(inside.?diameter.?\\:.{0,20})|()'                       \n",
    "inside_diameter['matches']=inside_diameter['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "inside_diameter['match'] = inside_diameter['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "inside_diameter['matchez'] = inside_diameter['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "inside=inside_diameter[(inside_diameter['matches'].astype(str)!='[]')|(inside_diameter['match'].astype(str)!='[]')|(inside_diameter['matchez'].astype(str)!='[]')]#['matchez'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside['Q:inside_diameter']=inside['matchez'].apply(lambda x: re.sub(r'''(?i)(Inside.?diameter.{0,10}\\:\\s?)|(Inside.?diameter\\s?\\'?\\s?\\:?\\s?)|(\\,..+(?=\\]))''','',str(x))).apply(lambda x: re.sub(r'''(\\\\)|(')''','',str(x)))\n",
    "inside['Q:inside_diameter']=inside['Q:inside_diameter'].apply(lambda x: re.sub(r'((?<=\\[)(?!\"))|((?=\\]))','\"',str(x))).apply(lambda x: re.sub(r'(?<=\\[\").+\\s\\-\\s','',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\d))\\s?mm',' mm',str(x)))                           \n",
    "inside['Q:inside_diameter'].explode().value_counts()\n",
    "match_id=inside[['external_id','Q:inside_diameter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_hd=hd[['external_id','Q:hole_diameter']]\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_id.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin=dfs[dfs['attribute'].astype(str)=='finish']\n",
    "finish=fin[fin['value'].astype(str)=='n/a']\n",
    "\n",
    "trip='(?i)(.{0,20}(?i)(?:alloy.?steel|altin.?coat|galling|armor.?coat|black.?e\\-|black.?oxid|black.?powder|oil.?dipped|blue.?extreme|brass|bright|cadmium|chrome|clear.?anodi|clear.?triva|clima|color|copper|dark|dichromate|dual.?process|dura.?kote|egg.?shell|electro|enamel|epoxy|ferro.?gold|galvaniz|galv.?krom|gloss|gold|graphite|gray.?lacqu|gray.?surfac|k.?cor|kim.?kote|kote|lead.?plate|matte|metallic|natural.?nylon|nickel|nitride|orange.?finish|phosphate|pink|plain|plated|polish|polymer|poly|powder.?coated|satin|semi\\-|silver|stainless|stal.?gard|steel|tin.?plate|titanium|tru.?guard|vinyl|wax|yellow.?dich|yellow.?trivalent|yellow.?zinc|zinc).{0,20})|()'                       \n",
    "finish['matches']=finish['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "trip='(?i)((?:alloy.?steel|altin.?coat|galling|armor.?coat|black.?e\\-|black.?oxid|black.?powder|oil.?dipped|blue.?extreme|brass|bright|cadmium|chrome|clear.?anodi|clear.?triva|clima|color|copper|dark|dichromate|dual.?process|dura.?kote|egg.?shell|electro|enamel|epoxy|ferro.?gold|galvaniz|galv.?krom|gloss|gold|graphite|gray.?lacqu|gray.?surfac|k.?cor|kim.?kote|kote|lead.?plate|matte|metallic|natural.?nylon|nickel|nitride|orange.?finish|phosphate|pink|plain|plated|polish|polymer|poly|powder.?coated|satin|semi\\-|silver|stainless|stal.?gard|steel|tin.?plate|titanium|tru.?guard|vinyl|wax|yellow.?dich|yellow.?trivalent|yellow.?zinc|zinc))|()'                       \n",
    "finish['match']=finish['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "finishs=finish[(finish['matches'].astype(str)!='[]')]\n",
    "print(len(finishs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finishs['match'].explode().value_counts()[0:500]\n",
    "Copper=finishs[(finishs['match'].astype(str)=='''['Copper']''')&(finishs['buckets'].astype(str)!='''None''')]\n",
    "print(len(Copper))\n",
    "Copper['buckets'].explode().value_counts()\n",
    "Copper[Copper['buckets'].astype(str)=='Fixings & Fasteners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dfz[dfz['attribute'].astype(str)=='shank_size']['buckets'].explode().value_counts().reset_index()['index'].to_list()\n",
    "print(len(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['CanSize']\n",
    "print('creating DataFrame')\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['attribute'].astype(str)=='closure']['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish=df[(df['IndustryNumber'].astype(str)!='nan')&(df['attribute'].astype(str)=='industry_number')][['attribute','buckets','value','external_id','product_name','long_desc','IndustryNumber']]\n",
    "finish[finish['value'].astype(str)=='n/a']\n",
    "finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['custom_fields'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish=dfs[dfs['attribute'].astype(str)=='finish']\n",
    "# print(len(finish))\n",
    "# finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(\\d+(?:(?:.?\\d+)?\\/\\d|\\/\\d+)?\"?\\s?(?:\\s?double\\s?)?Weld.?On.?Clamp)|()'''\n",
    "dfs['matches']=dfs['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "stems=dfs[(dfs['matches'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems['Q:hole_diameter']=stems['matches'].apply(lambda x: re.sub(r'(?i)(\\s?(?:\\s?double\\s?)?Weld.?On.?Clamp)','',str(x))).apply(lambda x: re.sub(r'''(((?<=\\[)')|('(?=\\])))''','\"',str(x)))\n",
    "hd=stems[stems['attribute'].astype(str)=='hole_diameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems['attribute'].explode().value_counts()\n",
    "welds=stems[(stems['attribute'].astype(str)=='hole_diameter')&(stems['matches'].astype(str)!='[]')]#['product_name'].explode().value_counts()\n",
    "welds['Q:hole_diameter']=welds['Q:hole_diameter'].apply(lambda x: re.sub(r'(?i)((?<=\\d)(?=\"\\]))','\"',str(x)))\n",
    "print(len(welds))\n",
    "welds['Q:hole_diameter'].explode().value_counts()\n",
    "\n",
    "match_welds=welds[['external_id','Q:hole_diameter']]\n",
    "match_welds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_hd=hd[['external_id','Q:hole_diameter']]\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_welds.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_welds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd['Q:hole_diameter']=hd['Q:hole_diameter'].apply(lambda x: re.sub(r'((?<=\\d)(?=\"(?!\")))','\"',str(x)))\n",
    "hd['Q:hole_diameter'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_hd=hd[['external_id','Q:hole_diameter']]\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_hd.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['CanSize']\n",
    "print('creating DataFrame')\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs['custom_fields'].explode().value_counts()\n",
    "# dfs\n",
    "# \n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['OverallLength']\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['StemLength']\n",
    "print('creating DataFrame')\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outside_diameter_sae\n",
    "stem_length=df[(df['attribute'].astype(str)=='stem_length')&(df['value'].astype(str)=='n/a')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','StemLength']]\n",
    "print(len(stem_length))\n",
    "# installation['HoleSize'].explode().value_counts()\n",
    "\n",
    "# trip=r'''(?i)(mm)|()'''\n",
    "# installation['matches']=installation['OutsideDiameter'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# depths=installation[(installation['matches'].astype(str)=='[]')]\n",
    "# depths['OutsideDiameter'].explode().value_counts()\n",
    "\n",
    "\n",
    "# depths['Q:outside_diameter_sae']=depths['OutsideDiameter'].apply(lambda x: re.sub(r'(.+\\-\\s?(?!\\d\\/)(?!\\d\\d\\/))|((?<!\\.)0(?!\\d)(?!\\.))','',str(x)))\n",
    "# # # installations=installation[(installation['Q:installation'].astype(str)!='Asst')&(installation['Q:installation'].astype(str)!='Flat')&(installation['Q:installation'].astype(str)!='#4')&(installation['Q:installation'].astype(str)!='#6')&(installation['Q:installation'].astype(str)!='6')]\n",
    "# depths['Q:outside_diameter_sae'].explode().value_counts()\n",
    "\n",
    "# match_outside_diameter_sae=depths[['external_id','Q:outside_diameter_sae']]\n",
    "# match_outside_diameter_sae['Q:outside_diameter_sae'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(\\bstem(?!.diameter)(?!diameter)\\s?[A-z\\s0-9\\:]{0,13}\\s?\\d+(?:\\/\\d+|\\.\\d+)?(?:\"|”|\\s?MM)?)|(\\d+(?:\\/\\d+|\\.\\d+)?(?:\"|”|\\s?MM)?\\s?stem(?!\\s\\d)(?<!\\slength..\\d)(?<!.length.\\d)(?!.length))|(\\bstem\\b)|()'''\n",
    "stem_length['matches']=stem_length['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "stem=stem_length[(stem_length['matches'].astype(str)!='[]')]\n",
    "print(len(stem))\n",
    "stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(0)\n",
    "# dfs['custom_fields'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem=df[(df['attribute'].astype(str)=='stem_length')&(df['value'].astype(str)=='n/a')][['attribute','buckets','value','external_id','product_name','long_desc','shortdescription','curated_date','StemLength']]#['StemLength'].explode().value_counts()\n",
    "\n",
    "trip=r'''(?i)(\\bstem(?!.diameter)(?!diameter)\\s?[A-z\\s0-9\\:]{0,13}\\s?\\d+(?:\\/\\d+|\\.\\d+)?(?:\"|”|\\s?MM)?)|(\\d+(?:\\/\\d+|\\.\\d+)?(?:\"|”|\\s?MM)?\\s?stem(?!\\s\\d)(?<!\\slength..\\d)(?<!.length.\\d)(?!.length))|()'''\n",
    "stem['matches']=stem['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "stems=stem[(stem['matches'].astype(str)!='[]')]\n",
    "stems['matches'].explode().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['external_id'].astype(str)=='131420']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems['Q:stem_length']=stems['matches'].apply(lambda x: re.sub(r'(?i)(stem\\s?(?:length)?\\s)|(\\s?Stem\\s?)|(\\s?(?:length|Lgth)\\s?\\:?)|(\\s?:\\s?)','',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?mm\\s?)',' mm',str(x))).apply(lambda x: re.sub(r'(\")|(”)',' in',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)')|('(?=\\]))''','\"',str(x))).apply(lambda x: re.sub(r'''((?<=\\d)\\s?(?=\"\\]))''',' in',str(x))).apply(lambda x: re.sub(r'''((?<=\\[\")\\s?)''','',str(x)))                                 \n",
    "stems['Q:stem_length'].explode().value_counts()\n",
    "# stems\n",
    "match_stem=stems[['external_id','Q:stem_length']]\n",
    "match_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem=df[(df['attribute'].astype(str)=='stem_length')&(df['value'].astype(str)!='n/a')][['attribute','buckets','value','external_id','product_name','long_desc','shortdescription','curated_date','StemLength']]#['StemLength'].explode().value_counts()\n",
    "# stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_stem.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['CanSize']\n",
    "print('creating DataFrame')\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outside Diameter\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['OutsideDiameter'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outside_diameter_sae\n",
    "\n",
    "installation=df[(df['attribute'].astype(str)=='outside_diameter')&(df['value'].astype(str)=='n/a')&(df['OutsideDiameter'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','OutsideDiameter']]\n",
    "print(len(installation))\n",
    "# installation['HoleSize'].explode().value_counts()\n",
    "\n",
    "# trip=r'''(?i)(mm)|()'''\n",
    "# installation['matches']=installation['OutsideDiameter'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# depths=installation[(installation['matches'].astype(str)=='[]')]\n",
    "# depths['OutsideDiameter'].explode().value_counts()\n",
    "\n",
    "\n",
    "# depths['Q:outside_diameter_sae']=depths['OutsideDiameter'].apply(lambda x: re.sub(r'(.+\\-\\s?(?!\\d\\/)(?!\\d\\d\\/))|((?<!\\.)0(?!\\d)(?!\\.))','',str(x)))\n",
    "# # # installations=installation[(installation['Q:installation'].astype(str)!='Asst')&(installation['Q:installation'].astype(str)!='Flat')&(installation['Q:installation'].astype(str)!='#4')&(installation['Q:installation'].astype(str)!='#6')&(installation['Q:installation'].astype(str)!='6')]\n",
    "# depths['Q:outside_diameter_sae'].explode().value_counts()\n",
    "\n",
    "# match_outside_diameter_sae=depths[['external_id','Q:outside_diameter_sae']]\n",
    "# match_outside_diameter_sae['Q:outside_diameter_sae'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_outside_diameter_sae.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_outside_diameter_sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Finish\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['Finish'] # TemperatureRange\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish=df[(df['attribute'].astype(str)=='finish')&(df['value'].astype(str)=='n/a')&(df['Finish'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','Finish']]\n",
    "print(len(finish))\n",
    "finish['Finish'].explode().value_counts()\n",
    "finish['Q:finish']=finish['Finish'].apply(lambda x: re.sub(r'(?i)(Standard&)|((?<=length)s)','',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "finishs=finish[(finish['Q:finish'].astype(str)!='Asst')&(finish['Q:finish'].astype(str)!='Flat')&(finish['Q:finish'].astype(str)!='#4')&(finish['Q:finish'].astype(str)!='#6')&(finish['Q:finish'].astype(str)!='6')]\n",
    "# gauges['Q:gauge'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "match_finish=finishs[['external_id','Q:finish']]\n",
    "match_finish['Q:finish'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_finish.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gauge\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['Gauge'] # TemperatureRange\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge=df[(df['attribute'].astype(str)=='gauge')&(df['value'].astype(str)=='n/a')&(df['Gauge'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','Gauge']]\n",
    "print(len(gauge))\n",
    "gauge['Gauge'].explode().value_counts()\n",
    "gauge['Q:gauge']=gauge['Gauge'].apply(lambda x: re.sub(r'(?i)(Standard&)|((?<=length)s)','',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "gauges=gauge[(gauge['Q:gauge'].astype(str)!='Assortment')&(gauge['Q:gauge'].astype(str)!='Up to 12')&(gauge['Q:gauge'].astype(str)!='#4')&(gauge['Q:gauge'].astype(str)!='#6')&(gauge['Q:gauge'].astype(str)!='6')]\n",
    "# gauges['Q:gauge'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "match_gauge=gauges[['external_id','Q:gauge']]\n",
    "match_gauge['Q:gauge'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_gauge.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_gauge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Air Consumption\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['Weight'] # TemperatureRange\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbs=df[(df['attribute'].astype(str)=='weight')]#['value'].explode().value_counts()\n",
    "\n",
    "trip=r'''(?i)(lb)|()'''\n",
    "lbs['matches']=lbs['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "depths=lbs[(lbs['matches'].astype(str)!='[]')]\n",
    "depths['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depths[depths['Weight'].astype(str)=='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=df[(df['attribute'].astype(str)=='weight')&(df['value'].astype(str)=='n/a')&(df['Weight'].astype(str)!='nan')]\n",
    "print(len(depth))\n",
    "depth['Weight'].explode().value_counts()\n",
    "\n",
    "\n",
    "trip=r'''(?i)(oz)|()'''\n",
    "depth['matches']=depth['Weight'].apply(lambda x: re_extract(trip,str(x)))\n",
    "depths=depth[(depth['matches'].astype(str)!='[]')]\n",
    "depths['Weight'].explode().value_counts()\n",
    "\n",
    "depths['Q:weight']=depths['Weight'].apply(lambda x: re.sub(r'(?i)(oz\\.)',' oz',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "# depths=depth[(depth['Q:weight'].astype(str)!='Assortment')&(depth['Q:weight'].astype(str)!='[]')]\n",
    "depths['Q:weight'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "match_weight=depths[['external_id','Q:weight']]\n",
    "# match_weight['Q:weight'].explode().value_counts()\n",
    "match_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_weight.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Style\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['Style'] # TemperatureRange\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=df[(df['attribute'].astype(str)=='socket_style')&(df['value'].astype(str)=='n/a')&(df['Style'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','Style']]\n",
    "print(len(depth))\n",
    "depth['Style'].explode().value_counts()\n",
    "depth['Q:socket_style']=depth['Style'].apply(lambda x: re.sub(r'(?i)(Standard&)|((?<=length)s)','',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "depths=depth[(depth['Q:socket_style'].astype(str)!='Assortment')&(depth['Q:socket_style'].astype(str)!='[]')]\n",
    "depths['Q:socket_style'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "match_socket_style=depths[['external_id','Q:socket_style']]\n",
    "# match_socket_style['Q:socket_style'].explode().value_counts()\n",
    "match_socket_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_socket_style.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_socket_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Air Consumption\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['IndustryNumber'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=df[(df['attribute'].astype(str)=='axle_diameter')&(df['value'].astype(str)=='n/a')&(df['IndustryNumber'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','IndustryNumber']]\n",
    "print(len(depth))\n",
    "depth['IndustryNumber'].explode().value_counts()\n",
    "depth['Q:industry_number']=depth['IndustryNumber'].apply(lambda x: re.sub(r'(?i)((?<=\\d)\")',' in',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "depths=depth[(depth['Q:industry_number'].astype(str)!='Assortment')&(depth['Q:industry_number'].astype(str)!='[]')]\n",
    "depths['Q:industry_number'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "match_industry_number=depths[['external_id','Q:industry_number']]\n",
    "match_industry_number['Q:industry_number'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_industry_number.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_industry_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axle Diameter\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['AxleDiameter'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=df[(df['attribute'].astype(str)=='axle_diameter')&(df['value'].astype(str)=='n/a')&(df['AxleDiameter'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','AxleDiameter']]\n",
    "print(len(depth))\n",
    "depth['AxleDiameter'].explode().value_counts()\n",
    "depth['Q:axle_diameter']=depth['AxleDiameter'].apply(lambda x: re.sub(r'(?i)((?<=\\d)\")',' in',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "depths=depth[(depth['Q:axle_diameter'].astype(str)!='Assortment')&(depth['Q:axle_diameter'].astype(str)!='[]')]\n",
    "depths['Q:axle_diameter'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "match_axle_diameter=depths[['external_id','Q:axle_diameter']]\n",
    "match_axle_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_axle_diameter.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_axle_diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drive Size\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['DriveSize'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=df[(df['attribute'].astype(str)=='drive_size')&(df['value'].astype(str)=='n/a')&(df['DriveSize'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','DriveSize']]\n",
    "print(len(depth))\n",
    "depth['DriveSize'].explode().value_counts()\n",
    "depth['Q:drive_size']=depth['DriveSize'].apply(lambda x: re.sub(r'(?i)((?<=\\d)\")',' in',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "depths=depth[(depth['Q:drive_size'].astype(str)!='Assortment')&(depth['Q:drive_size'].astype(str)!='[]')]\n",
    "depths['Q:drive_size'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "match_drive_size=depths[['external_id','Q:drive_size']]\n",
    "match_drive_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_drive_size.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_drive_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Air Consumption\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['AirConsumption_CFM_'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=df[(df['attribute'].astype(str)=='air_consumption_cfm')&(df['value'].astype(str)=='n/a')&(df['AirConsumption_CFM_'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','AirConsumption_CFM_']]\n",
    "print(len(depth))\n",
    "depth['AirConsumption_CFM_'].explode().value_counts()\n",
    "depth['Q:air_consumption_cfm']=depth['AirConsumption_CFM_'].apply(lambda x: re.sub(r'(?i)((?<=\\d))',' CMF',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "depths=depth[(depth['Q:air_consumption_cfm'].astype(str)!='Various')&(depth['Q:air_consumption_cfm'].astype(str)!='[]')]\n",
    "depths['Q:air_consumption_cfm'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "match_air_consumption=depths[['external_id','Q:air_consumption_cfm']]\n",
    "match_air_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_air_consumption.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_air_consumption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tube Size\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['VibrationRating'] # TemperatureRange\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vibration=df[(df['attribute'].astype(str)=='vibration_rating')&(df['value'].astype(str)=='n/a')&(df['VibrationRating'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','VibrationRating']]\n",
    "print(len(vibration))\n",
    "vibration['VibrationRating'].explode().value_counts()\n",
    "\n",
    "# trip=r'''(?i)(\")|(SAE)|()'''\n",
    "# op_pressure['matches']=op_pressure['OperatingPressure'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# op_pressures=op_pressure[(op_pressure['matches'].astype(str)!='[]')]\n",
    "# op_pressures['OperatingPressure'].explode().value_counts()\n",
    "\n",
    "\n",
    "\n",
    "vibration['Q:vibration_rating']=vibration['VibrationRating']#.apply(lambda x: re.sub(r'(?i)(P\\.?\\s?S\\.?\\s?I\\.?\\s?)','PSI',str(x)))#.apply(lambda x: re.sub(r'(\\,.+Metric)','',str(x))).apply(lambda x: re.sub(r'((?<=\\d)\\-(?!\\d\\/)(?!\\d\\d\\/)\\s?)','\" - ',str(x)))\n",
    "vibration['Q:vibration_rating'].explode().value_counts()\n",
    "match_vibration=vibration[['external_id','Q:vibration_rating']]\n",
    "match_vibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_vibration.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_vibration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tube Size\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['StampSize'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp=df[(df['attribute'].astype(str)=='size_sae')&(df['value'].astype(str)=='n/a')&(df['StampSize'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','StampSize']]\n",
    "print(len(stamp))\n",
    "stamp['StampSize'].explode().value_counts()\n",
    "\n",
    "# trip=r'''(?i)(\")|(SAE)|()'''\n",
    "# op_pressure['matches']=op_pressure['OperatingPressure'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# op_pressures=op_pressure[(op_pressure['matches'].astype(str)!='[]')]\n",
    "# op_pressures['OperatingPressure'].explode().value_counts()\n",
    "\n",
    "\n",
    "\n",
    "stamp['Q:size_sae']=stamp['StampSize']#.apply(lambda x: re.sub(r'(?i)(P\\.?\\s?S\\.?\\s?I\\.?\\s?)','PSI',str(x)))#.apply(lambda x: re.sub(r'(\\,.+Metric)','',str(x))).apply(lambda x: re.sub(r'((?<=\\d)\\-(?!\\d\\/)(?!\\d\\d\\/)\\s?)','\" - ',str(x)))\n",
    "stamp['Q:size_sae'].explode().value_counts()\n",
    "match_stamp_size=stamp[['external_id','Q:size_sae']]\n",
    "match_stamp_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_stamp_size.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_stamp_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tube Size\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['OperatingPressure'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_pressure=df[(df['attribute'].astype(str)=='operating_pressure')&(df['value'].astype(str)=='n/a')&(df['OperatingPressure'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','OperatingPressure']]\n",
    "print(len(op_pressure))\n",
    "op_pressure['OperatingPressure'].explode().value_counts()\n",
    "\n",
    "# trip=r'''(?i)(\")|(SAE)|()'''\n",
    "# op_pressure['matches']=op_pressure['OperatingPressure'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# op_pressures=op_pressure[(op_pressure['matches'].astype(str)!='[]')]\n",
    "# op_pressures['OperatingPressure'].explode().value_counts()\n",
    "\n",
    "\n",
    "\n",
    "op_pressure['Q:operating_pressure']=op_pressure['OperatingPressure'].apply(lambda x: re.sub(r'(?i)(P\\.?\\s?S\\.?\\s?I\\.?\\s?)','PSI',str(x)))#.apply(lambda x: re.sub(r'(\\,.+Metric)','',str(x))).apply(lambda x: re.sub(r'((?<=\\d)\\-(?!\\d\\/)(?!\\d\\d\\/)\\s?)','\" - ',str(x)))\n",
    "op_pressure['Q:operating_pressure'].explode().value_counts()\n",
    "match_op_pressure=op_pressure[['external_id','Q:operating_pressure']]\n",
    "match_op_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_op_pressure.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_op_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tube Size\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['Capacity'] # TemperatureRange\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Capacity'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity=df[(df['attribute'].astype(str)=='capacity_sae')&(df['value'].astype(str)=='n/a')&(df['Capacity'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','Capacity']]\n",
    "print(len(capacity))\n",
    "capacity['Capacity'].explode().value_counts()\n",
    "# capacity\n",
    "trip=r'''(?i)(\")|(SAE)|()'''\n",
    "capacity['matches']=capacity['Capacity'].apply(lambda x: re_extract(trip,str(x)))\n",
    "capacity_s=capacity[(capacity['matches'].astype(str)!='[]')]\n",
    "capacity_s['Capacity'].explode().value_counts()\n",
    "\n",
    "\n",
    "\n",
    "capacity_s['Q:capacity_sae']=capacity_s['Capacity'].apply(lambda x: re.sub(r'(?i)(\\s?SAE\\s?)','\"',str(x))).apply(lambda x: re.sub(r'(\\,.+Metric)','',str(x))).apply(lambda x: re.sub(r'((?<=\\d)\\-(?!\\d\\/)(?!\\d\\d\\/)\\s?)','\" - ',str(x)))\n",
    "capacity_s['Q:capacity_sae'].explode().value_counts()\n",
    "match_capacity_SAE=capacity_s[['external_id','Q:capacity_sae']]\n",
    "match_capacity_SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_capacity_SAE.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_capacity_SAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity=df[(df['attribute'].astype(str)=='capacity')&(df['value'].astype(str)=='n/a')&(df['Capacity'].astype(str)!='nan')]\n",
    "print(len(capacity))\n",
    "capacity['Capacity'].explode().value_counts()\n",
    "# capacity\n",
    "trip=r'''(?i)((M(?![A-z])))|()'''\n",
    "capacity['matches']=capacity['Capacity'].apply(lambda x: re_extract(trip,str(x)))\n",
    "capacity_s=capacity[(capacity['matches'].astype(str)!='[]')]\n",
    "capacity_s['Capacity'].explode().value_counts()\n",
    "\n",
    "\n",
    "\n",
    "capacity_s['Q:capacity']=capacity_s['Capacity'].apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?oz\\.)',' oz',str(x)))\n",
    "capacity_s['Q:capacity'].explode().value_counts()\n",
    "match_capacity=capacity_s[['external_id','Q:capacity']]\n",
    "match_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_capacity.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity=df[(df['attribute'].astype(str)=='capacity_oz')&(df['value'].astype(str)=='n/a')&(df['Capacity'].astype(str)!='nan')]\n",
    "print(len(capacity))\n",
    "capacity['Capacity'].explode().value_counts()\n",
    "capacity\n",
    "# trip=r'''(?i)(\")|(mm)|()'''\n",
    "# capacity['matches']=capacity['Capacity'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# capacity_s=capacity[(capacity['matches'].astype(str)!='[]')]\n",
    "# capacity_s['Capacity'].explode().value_counts()\n",
    "\n",
    "\n",
    "\n",
    "capacity['Q:capacity_oz']=capacity['Capacity'].apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?oz\\.)',' oz',str(x)))\n",
    "capacity['Q:capacity_oz'].explode().value_counts()\n",
    "match_capacity_s=capacity[['external_id','Q:capacity_oz']]\n",
    "match_capacity_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_capacity_s.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_capacity_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tube Size\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['Thickness'] # TemperatureRange\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness_mil=df[(df['attribute'].astype(str)=='thickness_mil')&(df['value'].astype(str)=='n/a')&(df['Thickness'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','Thickness']]\n",
    "print(len(thickness_mil))\n",
    "thickness_mil\n",
    "# thickness['Thickness'].explode().value_counts()\n",
    "\n",
    "# trip=r'''(?i)(\")|(mm)|()'''\n",
    "# thickness['matches']=thickness['Thickness'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# thickness_es=thickness[(thickness['matches'].astype(str)!='[]')]\n",
    "# thickness_es['Thickness'].explode().value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# thickness_es['Q:thickness']=thickness_es['Thickness'].apply(lambda x: re.sub(r'(?i)((?<=\\d)mm)',' mm',str(x)))\n",
    "# thickness_es['Q:thickness'].explode().value_counts()\n",
    "# match_thickness=thickness_es[['external_id','Q:thickness']]\n",
    "# match_thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_thickness.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tube Size\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['TubeSize'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tube_size=df[(df['attribute'].astype(str)=='tube_size')&(df['value'].astype(str)=='n/a')&(df['TubeSize'].astype(str)!='nan')][['attribute','buckets','value','external_id','product_name','long_desc','curated_date','TubeSize']]\n",
    "tube_size['TubeSize'].explode().value_counts()\n",
    "\n",
    "tube_sizes=tube_size[(tube_size['TubeSize'].astype(str)=='1/4\"')|(tube_size['TubeSize'].astype(str)=='3/16\"')|(tube_size['TubeSize'].astype(str)=='3/8\"')|(tube_size['TubeSize'].astype(str)=='5/16\"')]\n",
    "tube_sizes['TubeSize'].explode().value_counts()\n",
    "# trip=r'''(?i)(\")|()'''\n",
    "# tube_size['matches']=tube_size['TubeSize'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# tube_size_sae=tube_size[(tube_size['matches'].astype(str)!='[]')]\n",
    "# tube_size_sae['TubeSize'].explode().value_counts()\n",
    "\n",
    "tube_sizes['Q:tube_size']=tube_sizes['TubeSize']\n",
    "tube_sizes\n",
    "# # tube_od['Q:tube_outside_diameter_sae']=tube_od['MaleTubeO_D_']\n",
    "match_tube_siz=tube_sizes[['external_id','Q:tube_size']]\n",
    "match_tube_siz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_tube_siz.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_tube_siz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tube ID\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['MaleTubeO_D_'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MaleTubeO_D_'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tube_od=df[(df['attribute'].astype(str)=='tube_outside_diameter_sae')&(df['value'].astype(str)=='n/a')&(df['MaleTubeO_D_'].astype(str)!='nan')]\n",
    "tube_od['MaleTubeO_D_'].explode().value_counts()\n",
    "tube_od['Q:tube_outside_diameter_sae']=tube_od['MaleTubeO_D_']\n",
    "match_tube_OD_Male=tube_od[['external_id','Q:tube_outside_diameter_sae']]\n",
    "# match_tube_OD_Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_tube_OD_Male.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_tube_OD_Male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tube ID\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['FemaleTubeO_D_'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tube_od=df[(df['attribute'].astype(str)=='tube_outside_diameter_sae')&(df['value'].astype(str)=='n/a')&(df['FemaleTubeO_D_'].astype(str)!='nan')]\n",
    "tube_od['FemaleTubeO_D_'].explode().value_counts()\n",
    "tube_od['Q:tube_outside_diameter_sae']=tube_od['FemaleTubeO_D_']\n",
    "match_tube_OD_Female=tube_od[['external_id','Q:tube_outside_diameter_sae']]\n",
    "# match_tube_OD_Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_tube_OD_Female.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_tube_OD_Female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tube ID\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['TubeO_D_'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tube_od=df[(df['attribute'].astype(str)=='tube_outside_diameter_size')&(df['value'].astype(str)=='n/a')&(df['TubeO_D_'].astype(str)!='nan')]\n",
    "# tube_od['TubeO_D_'].explode().value_counts()\n",
    "\n",
    "# trip=r'''(M)|()'''\n",
    "# tube_od['matches']=tube_od['TubeO_D_'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# tube_od_metric=tube_od[(tube_od['matches'].astype(str)!='[]')]\n",
    "# tube_od['TubeO_D_'].explode().value_counts()\n",
    "\n",
    "# tube_od_metric['Q:tube_outside_diameter_sae']=tube_od_metric['TubeO_D_']\n",
    "# match_tube_od_metric=tube_od_metric[['external_id','Q:tube_outside_diameter_sae']]\n",
    "\n",
    "\n",
    "# depth['Q:depth']=depth['Depth']#.apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?\")',' in',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "# depths=depth[(depth['Q:depth'].astype(str)!='Diamond')&(temp['Q:depth'].astype(str)!='[]')]\n",
    "# depths['Q:depth'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "# match_depth=temps[['external_id','Q:arbor_hole']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_tube_od_metric.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_tube_od_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Depth'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=df[(df['attribute'].astype(str)=='depth')&(df['value'].astype(str)=='n/a')&(df['Depth'].astype(str)!='nan')]\n",
    "print(len(depth))\n",
    "depth['Depth'].explode().value_counts()\n",
    "# depth['Q:depth']=depth['Depth']#.apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?\")',' in',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "# depths=depth[(depth['Q:depth'].astype(str)!='Diamond')&(temp['Q:depth'].astype(str)!='[]')]\n",
    "# depths['Q:depth'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "# match_depth=temps[['external_id','Q:arbor_hole']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['attribute'].astype(str)=='depth')&(df['buckets'].astype(str)=='Liners & Sheeting')]#['Depth'].explode().value_counts()\n",
    "depth['curated_date'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arbor Hole\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['ArborHole'] # TemperatureRange\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df[(df['attribute'].astype(str)=='arbor_hole')&(df['value'].astype(str)=='n/a')&(df['ArborHole'].astype(str)!='nan')][['external_id','','','','','','','','','','']]\n",
    "print(len(temp))\n",
    "temp['ArborHole'].explode().value_counts()\n",
    "temp['Q:arbor_hole']=temp['ArborHole'].apply(lambda x: re.sub(r'((?<=\\/\\d)\\-)',' - ',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\/\\d)(?!\\d)(?!\"))|((?<=\\/\\d\\d)(?!\\d)(?!\"))','\"',str(x))).apply(lambda x: re.sub(r'((?<=\\d)(?!\\/)(?!\\d)(?!\")(?! )(?!\\.)(?!\\-))','\"',str(x)))\n",
    "temps=temp[(temp['Q:arbor_hole'].astype(str)!='Diamond')&(temp['Q:arbor_hole'].astype(str)!='[]')]\n",
    "temps['Q:arbor_hole'].explode().value_counts()#.reset_index()['index'].to_list()\n",
    "\n",
    "match_arbor_hole=temps[['external_id','Q:arbor_hole']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_arbor_hole.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_arbor_hole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThreadSize\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Depth'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df[(df['attribute'].astype(str)=='weight_capacity')&(df['value'].astype(str)=='n/a')&(df['Depth'].astype(str)!='nan')]\n",
    "print(len(temp))\n",
    "temp['Depth'].explode().value_counts()\n",
    "temp['Q:depth']=temp['Depth'].apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?\")',' in',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "temp['Q:depth'].explode().value_counts()\n",
    "\n",
    "match_depth=temp[['external_id','Q:depth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_depth.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThreadSize\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['LoadCapacity_Lbs__'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load=df[(df['attribute'].astype(str)=='weight_capacity')&(df['value'].astype(str)=='n/a')&(df['LoadCapacity_Lbs__'].astype(str)!='nan')]\n",
    "print(len(temp))\n",
    "load['LoadCapacity_Lbs__'].explode().value_counts()\n",
    "load['Q:weight_capacity']=load['LoadCapacity_Lbs__'].apply(lambda x: re.sub(r'(?i)(lbs\\.?)',' lb',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "load['Q:weight_capacity'].explode().value_counts()\n",
    "\n",
    "match_weight_capacity_three=load[['external_id','Q:weight_capacity']]\n",
    "match_weight_capacity_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_weight_capacity_three.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_weight_capacity_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThreadSize\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['RatedCapacity'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_capaicty=df[(df['attribute'].astype(str)=='weight_capacity')&(df['value'].astype(str)=='n/a')&(df['RatedCapacity'].astype(str)!='nan')]\n",
    "print(len(temp))\n",
    "weight_capaicty['RatedCapacity'].explode().value_counts()\n",
    "weight_capaicty['Q:weight_capacity']=weight_capaicty['RatedCapacity'].apply(lambda x: re.sub(r'(?i)((?<=\\d)(?!\\d)(?!\\,))',' lb',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "weight_capaicty['Q:weight_capacity'].explode().value_counts()\n",
    "\n",
    "match_weight_capacity=weight_capaicty[['external_id','Q:weight_capacity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_weight_capacity.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_weight_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThreadSize\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Capacity'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df[(df['attribute'].astype(str)=='weight_capacity')&(df['value'].astype(str)=='n/a')&(df['Capacity'].astype(str)!='nan')]\n",
    "print(len(temp))\n",
    "temp['Capacity'].explode().value_counts()\n",
    "temp['Q:weight_capacity']=temp['Capacity'].apply(lambda x: re.sub(r'(?i)(lbs\\.?)',' lb',str(x)))#.apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "temp['Q:weight_capacity'].explode().value_counts()\n",
    "\n",
    "match_weight_capacity_two=temp[['external_id','Q:weight_capacity']]\n",
    "match_weight_capacity_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_weight_capacity_two.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_weight_capacity_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThreadSize\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['DielectricStrength'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaelectric=df[(df['attribute'].astype(str)=='dielectric_strength')&(df['value'].astype(str)=='n/a')&(df['DielectricStrength'].astype(str)!='nan')]\n",
    "print(len(temp))\n",
    "diaelectric['DielectricStrength'].explode().value_counts()\n",
    "diaelectric['Q:dielectric_strength']=diaelectric['DielectricStrength'].apply(lambda x: re.sub(r'(?i)(600\\s?V(?!\\/)(?!olt))','600 V/mil',str(x))).apply(lambda x: re.sub(r'(volts)','Volts',str(x)))\n",
    "diaelectric['Q:dielectric_strength'].explode().value_counts()\n",
    "\n",
    "match_dielectric=diaelectric[['external_id','Q:dielectric_strength']]\n",
    "match_dielectric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diaelectric[diaelectric['value'].astype(str)=='n/a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_dielectric.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_dielectric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThreadSize\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['OperatingTemperature'] # TemperatureRange\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['attributes'].astype(str)=='maximum_operating_temperature']\n",
    "# df[df['attributes'].astype(str)=='minimum_operating_temperature']\n",
    "\n",
    "# df[df['attributes'].astype(str)=='maximum_operating_temperature_intermittent']\n",
    "# df[df['attributes'].astype(str)=='maximum_operating_temperature_continuous']\n",
    "\n",
    "\n",
    "# df['OperatingTemperature'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df[(df['attribute'].astype(str)=='maximum_operating_temperature_intermittent')&(df['value'].astype(str)=='n/a')&(df['OperatingTemperature'].astype(str)!='nan')]\n",
    "print(len(temp))\n",
    "temp['OperatingTemperature'].explode().value_counts()\n",
    "\n",
    "# trip=r'''(?i)(up to)|(?:medium|max|various)|()'''\n",
    "# temp['temp']=temp['OperatingTemperature'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# temps=temp[(temp['temp'].astype(str)=='[]')]\n",
    "# print(len(temps))\n",
    "\n",
    "\n",
    "temp['Q:maximum_operating_temperature_intermittent']=temp['OperatingTemperature'].apply(lambda x: re.sub(r'(?i)(.+\\((?=\\d+.{0,3}Intermittent))|(.+(?<!up.)to\\s?)|(\\s?°F(?: Int.+)?)','',str(x)))\n",
    "temps=temp[(temp['Q:maximum_operating_temperature_intermittent'].astype(str)!='Up to 250')&(temp['Q:maximum_operating_temperature_intermittent'].astype(str)!='Up to 1,200')]              \n",
    "# temps['Q:minimum_operating_temperature']=temps['Q:minimum_operating_temperature'].apply(lambda x: re.sub(r'°\\s?','',str(x)))\n",
    "temps['Q:maximum_operating_temperature_intermittent'].explode().value_counts()\n",
    "match_max_temp_three=temps[['external_id','Q:maximum_operating_temperature_intermittent']]\n",
    "match_max_temp_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp['value'].astype(str)=='n/a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_max_temp_three.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_max_temp_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df[(df['attribute'].astype(str)=='maximum_operating_temperature')&(df['value'].astype(str)=='n/a')&(df['OperatingTemperature'].astype(str)!='nan')]\n",
    "print(len(temp))\n",
    "temp['Q:maximum_operating_temperature']=temp['OperatingTemperature'].apply(lambda x: re.sub(r'(?i)(.+(?<!down )(?<!down)to\\s?)|(.+\\s\\-\\s)|(°\\s?F)|((?<=\\d)\\s?F)','',str(x)))\n",
    "temp=temp[(temp['Q:maximum_operating_temperature'].astype(str)!='Medium')&(temp['Q:maximum_operating_temperature'].astype(str)!='Various')&(temp['Q:maximum_operating_temperature'].astype(str)!='Down to -60')&(temp['Q:maximum_operating_temperature'].astype(str)!='Down to -70')]\n",
    "temp['Q:maximum_operating_temperature'].explode().value_counts()\n",
    "match_max_temp=temp[['external_id','Q:maximum_operating_temperature']]\n",
    "# match_max_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_max_temp.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_max_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThreadSize\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['BSPTPipeSize']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=df[(df['BSPTPipeSize'].astype(str)!='nan')&(df['attribute'].astype(str)=='pipe_size')&(df['value'].astype(str)=='n/a')]\n",
    "# thread=df[(df['attribute'].astype(str)=='thread_size')&(df['ThreadSize'].astype(str)!='nan')]\n",
    "pipe['BSPTPipeSize'].explode().value_counts()\n",
    "\n",
    "pipe['Q:pipe_size']=pipe['BSPTPipeSize'].apply(lambda x: re.sub(r'(?i)(\"?\\-(?!\\d\\/)(?!.\\d\\/))',' x ',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?x\\s?)',' x ',str(x))).apply(lambda x: re.sub(r'(?i)((?<!\\.)0+(?!\\d)(?!\\.)(?=\"))|(\\.0(?!\\d))','',str(x))).apply(lambda x: re.sub(r'(?<!\\d)\\.(?=\\d)','0.',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r\"''\",'\"',str(x)))\n",
    "pipe['Q:pipe_size'].explode().value_counts()\n",
    "match_pipe_size=pipe[['external_id','Q:pipe_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_pipe_size.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_pipe_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ThreadSize\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['ThreadSize']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread=df[(df['ThreadSize'].astype(str)!='nan')&(df['attribute'].astype(str)=='thread_size')&(df['value'].astype(str)=='n/a')]\n",
    "# thread=df[(df['attribute'].astype(str)=='thread_size')&(df['ThreadSize'].astype(str)!='nan')]\n",
    "thread['ThreadSize'].explode().value_counts()\n",
    "\n",
    "# thread\n",
    "# trip=r'''(?i)(\\d\\s?\")|()'''\n",
    "# thread['lwh']=thread['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# thread_size=thread[(thread['lwh'].astype(str)!='[]')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "thread['Q:thread_size']=thread['ThreadSize'].apply(lambda x: re.sub(r'(?i)(\"?\\-(?!\\d\\/)(?!.\\d\\/))',' x ',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?x\\s?)',' x ',str(x))).apply(lambda x: re.sub(r'(?i)((?<!\\.)0+(?!\\d)(?!\\.)(?=\"))|(\\.0(?!\\d))','',str(x))).apply(lambda x: re.sub(r'(?<!\\d)\\.(?=\\d)','0.',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r\"''\",'\"',str(x)))\n",
    "thread['Q:thread_size'].explode().value_counts()\n",
    "match_thread_size=thread[['external_id','Q:thread_size']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_thread_size.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_thread_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HeadDiameter\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['HeadDiameter']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head=df[(df['HeadDiameter'].astype(str)!='nan')&(df['attribute'].astype(str)=='head_diameter')&(df['value'].astype(str)=='n/a')]\n",
    "head['HeadDiameter'].explode().value_counts()\n",
    "\n",
    "head['Q:head_diameter']=head['HeadDiameter'].apply(lambda x: re.sub(r'(?<!\\.)0+(?!\\d)(?!\\.)(?=\")','',str(x))).apply(lambda x: re.sub(r'(?<!\\d)\\.(?=\\d)','0.',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r\"''\",'\"',str(x)))\n",
    "head['Q:head_diameter'].explode().value_counts()\n",
    "match_head_diameter=head[['external_id','Q:head_diameter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_head_diameter.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_head_diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=dfs[(dfs['attribute'].astype(str)=='length')&(dfs['value'].astype(str)=='n/a')]\n",
    "trip=r'''(?i)((?<!\\.)(?<!\\-)(?<!\\d)(?<!\\,)\\d{1,3}(?!\\d)(?:(?:\\-?\\s?\\d+\\/\\d+)?(?:\\.\\d+)?(?:\\/\\d+)?)?(?:\"|'|mm)?\\s?x\\s?\\d{1,3}(?!\\d)(?:(?:\\-?\\s?\\d+\\/\\d+)?(?:\\.\\d+)?(?:\\/\\d+)?)?(?:\"|'|mm)?(?:\\s?x\\s?\\d{1,3}(?!\\d)(?:(?:\\-?\\s?\\d+\\/\\d+)?(?:\\.\\d+)?(?:\\/\\d+)?)?(?:\"|'|mm)?)?)|()'''\n",
    "length['lwh']=length['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "lengths=length[(length['lwh'].astype(str)!='[]')]\n",
    "print(len(lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths['Q:length']=lengths['lwh'].apply(lambda x: re.sub(r'(?i)(\\s?x.+)',\"']\",str(x))).apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r\"(?i)((?<=\\[)')|('(?=\\]))\",'\"',str(x))).apply(lambda x: re.sub(r\"(\\\\)\",'',str(x))).apply(lambda x: re.sub(r'((?<=\\d)(?=\"\\]))','\"',str(x)))                           \n",
    "lengths['Q:length'].explode().value_counts()\n",
    "match_length_four=lengths[['external_id','Q:length']]\n",
    "# match_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_length_four.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_length_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['ShankLength']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=df[(df['ShankLength'].astype(str)!='nan')&(df['attribute'].astype(str)=='length')&(df['value'].astype(str)=='n/a')]\n",
    "length['ShankLength'].explode().value_counts()\n",
    "\n",
    "length['Q:length']=length['ShankLength'].apply(lambda x: re.sub(r'(?<!\\.)0+(?!\\d)(?!\\.)(?=\")','',str(x))).apply(lambda x: re.sub(r'(?<!\\d)\\.(?=\\d)','0.',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x)))\n",
    "length=length[(length['Q:length'].astype(str)!='Various')&(length['Q:length'].astype(str)!='Varies')&(length['Q:length'].astype(str)!='Bulk')&(length['Q:length'].astype(str)!='Assortment')&(length['Q:length'].astype(str)!='Close')&(length['Q:length'].astype(str)!='Varied')]\n",
    "length['Q:length'].explode().value_counts()\n",
    "match_length_three=length[['external_id','Q:length']]\n",
    "# match_length_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_length_three.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_length_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Length']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=df[(df['Length'].astype(str)!='nan')&(df['attribute'].astype(str)=='length')&(df['value'].astype(str)=='n/a')]\n",
    "length['Length'].explode().value_counts()\n",
    "\n",
    "length['Q:length']=length['Length'].apply(lambda x: re.sub(r'(?<!\\.)0+(?!\\d)(?!\\.)(?=\")','',str(x))).apply(lambda x: re.sub(r'(?<!\\d)\\.(?=\\d)','0.',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x)))\n",
    "length=length[(length['Q:length'].astype(str)!='Various')&(length['Q:length'].astype(str)!='Varies')&(length['Q:length'].astype(str)!='Bulk')&(length['Q:length'].astype(str)!='Assortment')&(length['Q:length'].astype(str)!='Close')&(length['Q:length'].astype(str)!='Varied')]\n",
    "length['Q:length'].explode().value_counts()\n",
    "match_length_two=length[['external_id','Q:length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_length_two.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_length_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['OverallLength']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=df[(df['OverallLength'].astype(str)!='nan')&(df['attribute'].astype(str)=='length')&(df['value'].astype(str)=='n/a')]\n",
    "length['OverallLength'].explode().value_counts()\n",
    "\n",
    "length['Q:length']=length['OverallLength'].apply(lambda x: re.sub(r'(?<!\\.)0+(?!\\d)(?!\\.)(?=\")','',str(x))).apply(lambda x: re.sub(r'(?<!\\d)\\.(?=\\d)','0.',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x)))\n",
    "length=length[(length['Q:length'].astype(str)!='Various')&(length['Q:length'].astype(str)!='Assortment')]\n",
    "length['Q:length'].explode().value_counts()\n",
    "match_length=length[['external_id','Q:length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_length.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['PrivateLabel']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private=df[(df['attribute'].astype(str)=='private_label')&(df['value'].astype(str)=='n/a')&(df['PrivateLabel'].astype(str)!='nan')]\n",
    "private['Q:private_label']=private['PrivateLabel']\n",
    "private['Q:private_label'].explode().value_counts()\n",
    "match_private=private[['external_id','Q:private_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_private.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HoseI_D_\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['HoseI_D_xO_D_']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hose_id['Q:hose_inside_diameter']=hose_id['HoseI_D_'].apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r'(\"\\-)','\" - ',str(x))).apply(lambda x: re.sub(r'(\\s?x\\s?)',' x ',str(x)))\n",
    "hose_id=hose_id[hose_id['attribute'].astype(str)=='hose_inside_diameter']\n",
    "hose_id['Q:hose_inside_diameter'].explode().value_counts()\n",
    "match_hose_id_two=hose_id[['external_id','Q:hose_inside_diameter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_hose_id_two.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_hose_id_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HoseI_D_\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['HoseI_D_']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hose_id=df[(df['HoseI_D_'].astype(str)!='nan')]\n",
    "hose_id['Q:hose_inside_diameter']=hose_id['HoseI_D_'].apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r'(\"\\-)','\" - ',str(x))).apply(lambda x: re.sub(r'(\\s?x\\s?)',' x ',str(x)))\n",
    "hose_id=hose_id[hose_id['attribute'].astype(str)=='hose_inside_diameter']\n",
    "hose_id['Q:hose_inside_diameter'].explode().value_counts()\n",
    "match_hose_id=hose_id[['external_id','Q:hose_inside_diameter']]\n",
    "print(len(match_hose_id))\n",
    "match_hose_id\n",
    "# hose_id[hose_id['HoseI_D_'].astype(str)=='5/16\" x 13/32\"']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_hose_id.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_hose_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HoseI_D_\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['HoseI_D_']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hole Diameter\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Flammability']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flam=df[(df['Flammability'].astype(str)!='nan')]\n",
    "flam['Q:flammable_non_flammable']=flam['Flammability'].apply(lambda x: re.sub(r'(flammable)','Flammable',str(x)))\n",
    "flam['Q:flammable_non_flammable'].explode().value_counts()\n",
    "flam=flam[flam['attribute'].astype(str)=='flammable_non_flammable']\n",
    "match_flammable=flam[['external_id','Q:flammable_non_flammable']]\n",
    "print(len(match_flammable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_flammable.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_flammable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hole Diameter\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['HoleSize']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hole=df[(df['HoleSize'].astype(str)!='nan')&(df['value'].astype(str)=='n/a')]\n",
    "hole['Q:hole_diameter']=hole['HoleSize'].apply(lambda x: re.sub(r'(?i)(\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?\\(.+\\)\\s?)','',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?x\\s?)',' x ',str(x)))\n",
    "hole['Q:hole_diameter']=hole['Q:hole_diameter'].apply(lambda x: re.sub(r'(?<!\\d)\\.(?=\\d)','0.',str(x))).apply(lambda x: re.sub(r'((?<!\\.)0+(?!\\d)(?!\\.)(?=\"))','',str(x))).apply(lambda x: re.sub(r'(.+or.+)','Assorted',str(x)))                                        \n",
    "hole['Q:hole_diameter'].explode().value_counts()\n",
    "diameter=hole[hole['attribute'].astype(str)=='hole_diameter']\n",
    "match_hole_diameter=diameter[['external_id','Q:hole_diameter']]\n",
    "match_hole_diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hole['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hole['Q:stud_size']=hole['Q:hole_diameter']\n",
    "# stud=hole[hole['attribute'].astype(str)=='stud_size']\n",
    "# match_stud_size=stud[['external_id','Q:stud_size']]\n",
    "# stud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_hole_diameter.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_hole_diameter)\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_stud_size.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_stud_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Size']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip=r'''(?i)(epoxy)|()'''\n",
    "# df['matches']=df['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "trip=r'''(?i)(\\d.?pt)|(pint)|()'''\n",
    "df['grams']=df['Size'].apply(lambda x: re_extract(trip,str(x)))\n",
    "gram=df[(df['grams'].astype(str)!='[]')]\n",
    "gram['Size'].explode().value_counts()\n",
    "# gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram['Q:volume_pint']=gram['Size'].apply(lambda x: re.sub(r'\\s?pt\\.',' pt',str(x)))\n",
    "match_pint=gram[['external_id','Q:volume_pint']]\n",
    "pints=gram[gram['attribute'].astype(str)=='volume_pint']\n",
    "match_pints=pints[['external_id','Q:volume_pint']]\n",
    "match_pints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_pints.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_pints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gram['attribute'].explode().value_counts()\n",
    "# print(len(gram[gram['attribute'].astype(str)=='volume_qt']))\n",
    "# gram[gram['attribute'].astype(str)=='volume_qt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['CanSize']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[dfs['attribute'].astype(str)=='']\n",
    "# dfs['attribute'].explode().value_counts()\n",
    "volume=df[(df['CanSize'].astype(str)!='nan')&(df['value'].astype(str)=='n/a')&((volume['attribute'].astype(str)=='volume_pint')|(volume['attribute'].astype(str)=='volume_gal')|(volume['attribute'].astype(str)=='volume_qt'))]\n",
    "volume['CanSize'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume['attribute'].explode().value_counts()\n",
    "volume['attribute'].explode().value_counts()\n",
    "volume[volume['attribute'].astype(str)=='volume_oz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(gal)|()'''\n",
    "volume['matches']=volume['CanSize'].apply(lambda x: re_extract(trip,str(x)))\n",
    "vols=volume[(volume['matches'].astype(str)!='[]')&(volume['attribute'].astype(str)=='volume_gal')]\n",
    "vols\n",
    "# vol['volume_oz']=vol['CanSize']\n",
    "# match_volume=vol[['external_id','Q:volume_oz']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_head_style.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_head_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['HeadStyle']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head=df[(df['HeadStyle'].astype(str)!='nan')&(df['value'].astype(str)=='n/a')&(df['attribute'].astype(str)=='head_style')]\n",
    "# height=height[(height['Height'].astype(str)!='Varies')&(height['Height'].astype(str)!='Various')]\n",
    "print(len(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "head['Q:head_style']=head['HeadStyle'].apply(lambda x: re.sub(r'(?i)(Flange(?!.Head)(?!.\\w))','Flange Head',str(x))).apply(lambda x: re.sub(r'(?i)(Button(?!.head)(?!.\\w))','Button Head',str(x))).apply(lambda x: re.sub(r'(?i)(Oval Washer Head)','Oval Head',str(x)))\n",
    "head['Q:head_style']=head['Q:head_style'].apply(lambda x: re.sub(r'(?i)((?<!\\w.)Sems(?!.Head)(?!.\\w))|(Hex Head Sems)','Hex Washer Sems',str(x))).apply(lambda x: re.sub(r'(?i)(Hex(?!.Head)(?!.\\w))','Hex Head',str(x))).apply(lambda x: re.sub(r'(?i)(Round(?!.Head)(?!.\\w))','Round Head',str(x)))\n",
    "head['Q:head_style']=head['Q:head_style'].apply(lambda x: re.sub(r'(?i)(Flush Washer)','Flush Mount',str(x))).apply(lambda x: re.sub(r'(?i)(Narrow Flange(?!.Head)(?!.\\w))','Narrow Flange Head',str(x)))\n",
    "heads=head[(head['Q:head_style'].astype(str)!='Binding Head')&(head['Q:head_style'].astype(str)!='Assortment')&(head['Q:head_style'].astype(str)!='Wafer Head')&(head['Q:head_style'].astype(str)!='Pan Washer Head')&(head['Q:head_style'].astype(str)!='XL Flange')&(head['Q:head_style'].astype(str)!='Round Truss Head')]\n",
    "\n",
    "heads['Q:head_style'].explode().value_counts()\n",
    "match_head_style=heads[['external_id','Q:head_style']]\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_head_style.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_head_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Width']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=df[(df['Width'].astype(str)!='nan')&(df['value'].astype(str)=='n/a')&(df['attribute'].astype(str)=='width')]\n",
    "height=height[(height['Width'].astype(str)!='Varies')&(height['Width'].astype(str)!='Various')]\n",
    "print(len(height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height['Q:width']=height['Height'].apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?\")',' in',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?mm)',' mm',str(x)))\n",
    "height['Q:width'].explode().value_counts()\n",
    "match_height=height[['external_id','Q:width']]\n",
    "match_height\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_width.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['Width']\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=df[(df['Width'].astype(str)!='nan')&(df['value'].astype(str)=='n/a')&(df['attribute'].astype(str)=='width')]\n",
    "print(len(width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width['Q:width']=width['Width'].apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?mm)',' mm',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?\")',' in',str(x)))\n",
    "widths=width[width['Q:width'].astype(str)!='Various']\n",
    "widths['Q:width'].explode().value_counts()\n",
    "match_width=widths[['external_id','Q:width']]\n",
    "match_width\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_width.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['ThreadType']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_type=df[(df['ThreadType'].astype(str)!='nan')&(df['value'].astype(str)=='n/a')&(df['attribute'].astype(str)=='thread_type')]\n",
    "print(len(thread_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_type[['value','ThreadType']]\n",
    "thread_type['ThreadType'].explode().value_counts()\n",
    "\n",
    "match_thread_type=thread_type[(thread_type['ThreadType'].astype(str)=='Metric Taper Thread')|(thread_type['ThreadType'].astype(str)=='MPT')|(thread_type['ThreadType'].astype(str)=='FPT')|(thread_type['ThreadType'].astype(str)=='Very Fine')|(thread_type['ThreadType'].astype(str)=='External')|(thread_type['ThreadType'].astype(str)=='Regular Pitch (Coarse Thread)')|(thread_type['ThreadType'].astype(str)=='Fine (SAE)')|(thread_type['ThreadType'].astype(str)=='NPT')|(thread_type['ThreadType'].astype(str)=='Coarse (USS)')|(thread_type['ThreadType'].astype(str)=='Metric')]\n",
    "match_thread_type['Q:thread_type']=match_thread_type['ThreadType']\n",
    "match_thread_type\n",
    "match_Thread_Type=match_thread_type[[\"external_id\",\"Q:thread_type\"]]\n",
    "# match_Thread_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match__not_thread_type=thread_type[(thread_type['ThreadType'].astype(str)!='Metric Taper Thread')&(thread_type['ThreadType'].astype(str)!='MPT')&(thread_type['ThreadType'].astype(str)!='FPT')&(thread_type['ThreadType'].astype(str)!='Very Fine')&(thread_type['ThreadType'].astype(str)!='External')&(thread_type['ThreadType'].astype(str)!='Regular Pitch (Coarse Thread)')&(thread_type['ThreadType'].astype(str)!='Fine (SAE)')&(thread_type['ThreadType'].astype(str)!='NPT')&(thread_type['ThreadType'].astype(str)!='Coarse (USS)')&(thread_type['ThreadType'].astype(str)!='Metric')]\n",
    "# match__not_thread_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_Max_RPM=fin[['external_id','Q:finish']]\n",
    "# match_Max_RPM\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_Thread_Type.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_Thread_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Finish']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finish=df[(df['Finish'].astype(str)!='nan')&(df['value'].astype(str)=='n/a')&(df['attribute'].astype(str)=='finish')]\n",
    "finish['Finish'].explode().value_counts()\n",
    "finish['Q:finish']=finish['Finish'].apply(lambda x: f'[\"{x}\"]').apply(lambda x: re.sub(r'(\\&)|(\\()',',',str(x))).apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x))).apply(lambda x: re.sub(r'(\"?\\s?\\,(?!\")(?! \"))','\",\"',str(x))).apply(lambda x: re.sub(r'(\\))','',str(x))).apply(lambda x: re.sub(r'Yellow\",\"Zinc','Yellow Zinc',str(x)))              \n",
    "finish['Q:finish']=finish['Q:finish'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x)))\n",
    "# finish['Q:finish']=finish['Q:finish'].apply(lambda x: re.sub(r'([\"Gold Chrome\",\"Zinc\"])|([\"Color-Coded Electro-Tin Plating\"])|([\"Dichromate Gold\"])|([\"Black With Oil Dipped Finish\"])|([\"Silver Organic Dacromet Finish\"])|([\"Satin Chrome\"])|([\"Color Coded\"])|([\"Natural Nylon\"])|([\"Maxi-Chrome\"])|([\"Zinc\"])|([\"Zinc Yellow Plated\"])|([\"Custom Blue Plating\"])|([\"Vinyl-Coated Steel\"])|((?<=gray)\\s?Surface Treatment)|([\"Tru-Guard\"])|([\"Zinc Dichromate\"])|([\"Nylon\"])|([\"Blue Extreme Coating\"])|([\"Black E-Coat\"])','',str(x)))\n",
    "fin=finish[(finish['Q:finish']!='[\"Flat\"]')&(finish['Q:finish']!='[\"Asst\"]')]\n",
    "print(len(finish))\n",
    "\n",
    "\n",
    "fin['Q:finish'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'[\"Zinc Dichromate\"]')|(finish['Q:finish'].astype(str)=='[\"Blue Extreme Coating\"]')|(finish['Q:finish'].astype(str)=='[\"Black E-Coat\"]')]\n",
    "x[(x['Q:finish'].astype(str)=='[\"Black E-Coat\"]')]['buckets'].explode().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_finish=fin[['external_id','Q:finish']]\n",
    "match_finish\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_finish.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['CanSize']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CanSize=df[df['CanSize'].astype(str)!='nan']\n",
    "trip=r'''(?i)(oz)|()'''\n",
    "CanSize['matches']=CanSize['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "vols=CanSize[(CanSize['matches'].astype(str)!='[]')&(CanSize['attribute'].astype(str)=='volume_oz')]\n",
    "vols['value'].explode().value_counts()\n",
    "vols[['value','CanSize']][0:500]\n",
    "vols['Q:volume_oz']=vols['CanSize'].apply(lambda x: re.sub(r'(?i)(\\s?oz\\.?)',' oz',str(x)))\n",
    "vols['Q:volume_oz'].explode().value_counts()\n",
    "match_vol_oz=vols[['external_id','Q:volume_oz']]\n",
    "match_vol_oz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_vol_oz.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_vol_oz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lubricant=dfs[(dfs['buckets'].astype(str)=='Lubricants')&(dfs['attribute'].astype(str)=='volume_oz')]\n",
    "# lubricant\n",
    "#['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume=df[(df['value'].astype(str)=='n/a')&(df['CanSize'].astype(str)!='nan')&((df['attribute'].astype(str)=='volume_oz')|(df['attribute'].astype(str)=='volume_gal')|(df['attribute'].astype(str)=='volume_qt'))]\n",
    "volume#['attribute'].explode().value_counts()\n",
    "\n",
    "\n",
    "trip=r'''(?i)(oz)|()'''\n",
    "volume['matches']=volume['CanSize'].apply(lambda x: re_extract(trip,str(x)))\n",
    "vols=volume[volume['matches'].astype(str)!='[]']\n",
    "\n",
    "\n",
    "ounce=vols[vols['attribute'].astype(str)=='volume_oz']\n",
    "ounce['Q:volume_oz']=ounce['CanSize'].apply(lambda x: re.sub(r'(?i)(oz\\.)','oz',str(x)))\n",
    "match_volume_ounce=ounce[['external_id','Q:volume_oz']]\n",
    "match_volume_ounce\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_volume_ounce.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_volume_ounce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['buckets'].astype(str)=='Vehicle Paint']['attribute'].explode().value_counts()\n",
    "volume[(volume['buckets'].astype(str)=='Vehicle Paint')&(volume['matches'].astype(str)=='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_gal=vols[(vols['attribute'].astype(str)=='volume_qt')]\n",
    "volume_gal['CanSize'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diameter=df[(df['attribute'].astype(str)=='diameter')&(df['value'].astype(str)=='n/a')&(df['Diameter'].astype(str)!='nan')]\n",
    "# diameter['Diameter'].explode().value_counts()\n",
    "# diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Finish']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter=df[(df['attribute'].astype(str)=='diameter')&(df['value'].astype(str)=='n/a')&(df['Diameter'].astype(str)!='nan')]\n",
    "# diameter['Diameter'].explode().value_counts()\n",
    "# diameter['external_id'].explode().value_counts()\n",
    "# df[df['external_id'].astype(str)=='84055']\n",
    "diameter['Q:diameter']=diameter['Diameter'].apply(lambda x: f'[\"{x}\"]').apply(lambda x: re.sub(r'(\\&)|(\\()',',',str(x))).apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x)))#.apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x)))\n",
    "dia=diameter[diameter['Q:diameter'].astype(str)!='[\"Assortment\"]']\n",
    "dia['Q:diameter']=dia['Q:diameter'].apply(lambda x: re.sub(r'(\"?\\s?\\,(?!\")(?! \"))','\",\"',str(x))).apply(lambda x: re.sub(r'(\\))','',str(x)))\n",
    "match_dia=dia[['external_id','Q:diameter']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_dia.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_size=diameter_size[(diameter_size['match'].astype(str)!='[]')|(diameter_size['matches'].astype(str)!='[]')|(diameter_size['matchez'].astype(str)!='[]')]\n",
    "dia_size['match']=dia_size['match'].apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x)))\n",
    "dia_size['matches']=dia_size['matches'].apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x)))\n",
    "dia_size['matchez']=dia_size['matchez'].apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x)))\n",
    "\n",
    "match=dia_size[dia_size['match'].astype(str)!='[]']\n",
    "matches=dia_size[dia_size['matches'].astype(str)!='[]']\n",
    "matchez=dia_size[dia_size['matchez'].astype(str)!='[]']\n",
    "\n",
    "dia_size['matchez'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dia_size))\n",
    "print(len(dia_size[(dia_size['match'].astype(str)!='[]')&(dia_size['matches'].astype(str)=='[]')]))\n",
    "print(len(dia_size[(dia_size['match'].astype(str)=='[]')&(dia_size['matches'].astype(str)!='[]')]))\n",
    "print(len(dia_size[(dia_size['match'].astype(str)!='[]')&(dia_size['matches'].astype(str)!='[]')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match=dia_size[(dia_size['match'].astype(str)!='[]')&(dia_size['matches'].astype(str)=='[]')]\n",
    "matches=dia_size[(dia_size['match'].astype(str)=='[]')&(dia_size['matches'].astype(str)!='[]')]\n",
    "both=dia_size[(dia_size['match'].astype(str)!='[]')&(dia_size['matches'].astype(str)!='[]')]\n",
    "\n",
    "match['Q:diameter_size']=match['match'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x)))\n",
    "matches['Q:diameter_size']=matches['matches'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x)))\n",
    "both['Q:diameter_size']=both['match'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"(?<=\\[)\\s?'|(?<=\\,)\\s?'|'\\s?(?=\\])|'\\s?(?=\\,)\",'\"',str(x)))\n",
    "\n",
    "both['Q:diameter_size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_diameter_size=match[['external_id','Q:diameter_size']]\n",
    "match_diameter_sizes=matches[['external_id','Q:diameter_size']]\n",
    "match_diameter_size_both=both[['external_id','Q:diameter_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_diameter_size.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_diameter_size)\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_diameter_sizes.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_diameter_sizes)\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_diameter_size_both.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_diameter_size_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Material']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material=df[(df['attribute'].astype(str)=='material')&(df['value'].astype(str)=='n/a')&(df['Material'].astype(str)!='nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material[['value','Material']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# material['value'].explode().value_counts()\n",
    "three=material[material['Material'].astype(str)=='316 Stainless Steel']\n",
    "three['value'].explode().value_counts()\n",
    "six=three[three['value'].astype(str)!='316 Stainless Steel']\n",
    "six['material']='316 Stainless Steel'\n",
    "match_three_sixteen=six[['external_id','material']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_three_sixteen.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_three_sixteen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(Roll.?Pin)|()'''                                                              \n",
    "material['match']=material['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "materials=material[material['match'].astype(str)!='[]']\n",
    "\n",
    "trip=r'''(?i)((?<!1070.)carbon.?steel)|()'''\n",
    "materials['matches']=materials['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "rolls=materials[materials['matches'].astype(str)!='[]']\n",
    "rolls['Q:material']='1070 Carbon Steel'\n",
    "material_rolls=rolls[['external_id','Q:material']]\n",
    "\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-material_rolls.csv',index=False) \n",
    "# looks_good('Kimball Midwest',material_rolls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(sheet.?metal.?screw)|()'''   \n",
    "trip=r'''(?i)(Power.?Thread.?screw)|()''' \n",
    "\n",
    "\n",
    "material['match']=material['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "materials=material[material['match'].astype(str)!='[]']\n",
    "\n",
    "materials['Q:material']='Steel'\n",
    "match_power_thread_screw=materials[['external_id','Q:material']]\n",
    "# match_sheet_metal\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_self_driving.csv',index=False) \n",
    "# # looks_good('Kimball Midwest',match_self_driving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # material[material.apply(lambda x: material['value'] != material['Material'], axis = 1)]\n",
    "# import numpy as np\n",
    "# # material['que'] = np.where((material['value'] == material['Material']))\n",
    "# not_match=material[(material[\"value\"] != material[\"Material\"])]\n",
    "# fixed_na=not_match[(not_match['value'].astype(str)=='n/a')&(not_match['Material'].astype(str)!='nan')]\n",
    "# fixed_na['Q:material']=fixed_na['Material']\n",
    "# match_fixed_na=fixed_na[['external_id','Q:material']]\n",
    "# match_fixed_na\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-match_power_thread_screw.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_power_thread_screw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[\"1020 Steel\",\n",
    "\"1030 Carbon Steel\",\n",
    "\"1035 Carbon Steel\",\n",
    "\"1035 Steel\",\n",
    "\"1040 Steel\",\n",
    "\"1070 Carbon Steel\",\n",
    "\"12L14 Carbon Steel\",\n",
    "\"18-8 Stainless Steel\",\n",
    "\"2745 Brass Alloy\",\n",
    "\"304 Stainless Steel\",\n",
    "\"316 Stainless Steel\",\n",
    "\"6/6 Nylon\",\n",
    "\"ABS\",\n",
    "\"Acetal Copolymer\",\n",
    "\"Acrylic\",\n",
    "\"Alloy Steel\",\n",
    "\"Aluminum\",\n",
    "\"Aluminum Alloy\",\n",
    "\"Aluminum Oxide\",\n",
    "\"Annealed Wire\",\n",
    "\"Anodized Aluminum\",\n",
    "\"Bi-Metal\",\n",
    "\"Bi-Metal Steel\",\n",
    "\"Brass\",\n",
    "\"Bronze\",\n",
    "\"C1010/ C1008 Steel\",\n",
    "\"C1018 Steel\",\n",
    "\"C1020 Steel\",\n",
    "\"C1045 Steel\",\n",
    "\"C1110 Steel\",\n",
    "\"C4150 Alloy Steel\",\n",
    "\"CA360 Brass\",\n",
    "\"Canvas\",\n",
    "\"Carbide\",\n",
    "\"Carbon Fiber\",\n",
    "\"Carbon Fiberglass\",\n",
    "\"Carbon Spring Steel\",\n",
    "\"Carbon Steel\",\n",
    "\"Cardboard\",\n",
    "\"Cardstock Paper\",\n",
    "\"Case Hardened Steel\",\n",
    "\"Cast Copper\",\n",
    "\"Cast Iron\",\n",
    "\"Cast Steel\",\n",
    "\"Cellulose\",\n",
    "\"Ceramic\",\n",
    "\"Ceramic Alumina\",\n",
    "\"Chloroprene\",\n",
    "\"Chrome\",\n",
    "\"Chrome-Moly Steel\",\n",
    "\"Chrome Vanadium Alloy Steel\",\n",
    "\"Cloth\",\n",
    "\"Cold Formed Steel\",\n",
    "\"Cold Rolled Steel\",\n",
    "\"Composite\",\n",
    "\"Concrete\",\n",
    "\"Copper\",\n",
    "\"Copper Alloy\",\n",
    "\"Cotton\",\n",
    "\"Diamond\",\n",
    "\"Drop Forged Steel\",\n",
    "\"Dyanite Carbide\",\n",
    "\"Elastic\",\n",
    "\"Elastomer\",\n",
    "\"Electrolytic Copper\",\n",
    "\"Emery\",\n",
    "\"Enamel\",\n",
    "\"Engineered Wood\",\n",
    "\"EPDM\",\n",
    "\"EPDM Rubber\",\n",
    "\"Epoxy\",\n",
    "\"Ethylene Propylene Rubber\",\n",
    "\"Fabric\",\n",
    "\"Faux Leather\",\n",
    "\"Ferrous Oxide\",\n",
    "\"Fiber\",\n",
    "\"Fiberglass\",\n",
    "\"Fluorocarbon\",\n",
    "\"Flux Core Steel\",\n",
    "\"Foam\",\n",
    "\"Forged Steel\",\n",
    "\"Galvanized Steel\",\n",
    "\"Gel\",\n",
    "\"Glass\",\n",
    "\"Glass Fiber\",\n",
    "\"Glass Filled Nylon\",\n",
    "\"Glass Filled Polypropylene\",\n",
    "\"Glass Filled Synthetic\",\n",
    "\"Glass Reinforced Nylon 6/6\",\n",
    "\"Glass Reinforced Polymer\",\n",
    "\"Gold\",\n",
    "\"Hardened Steel\",\n",
    "\"HDPE\",\n",
    "\"High Carbon Alloy\",\n",
    "\"High Carbon Steel\",\n",
    "\"High Molybdenum Steel\",\n",
    "\"High Speed Steel\",\n",
    "\"Hi-Tungsten Steel\",\n",
    "\"Hog Hair\",\n",
    "\"HSN\",\n",
    "\"Hybrid Polymer\",\n",
    "\"Hydrogenated Nitrile Butadiene Rubber\",\n",
    "\"Impact Grade steel\",\n",
    "\"Iron\",\n",
    "\"Iron Oxide\",\n",
    "\"Isoplastic\",\n",
    "\"Jersey\",\n",
    "\"Kevlar\",\n",
    "\"Laminated Steel\",\n",
    "\"Latex\",\n",
    "\"Lead\",\n",
    "\"Lead Alloy\",\n",
    "\"Leather\",\n",
    "\"Low Carbon Steel\",\n",
    "\"M22 Tungsten-Molybdenum High Speed Steel\",\n",
    "\"M-2 Alloy Steel\",\n",
    "\"M-2 High Speed Steel\",\n",
    "\"M2 High Speed Tool Steel\",\n",
    "\"M-42 Cobalt\",\n",
    "\"Magnesium Alloy\",\n",
    "\"Malleable Iron\",\n",
    "\"Malleable Steel\",\n",
    "\"MB Spring Steel\",\n",
    "\"Medium Carbon Alloy Steel\",\n",
    "\"Mesh\",\n",
    "\"Metal\",\n",
    "\"Microfiber\",\n",
    "\"Mild Steel\",\n",
    "\"Molybdenum\",\n",
    "\"Molybdenum Alloy Steel\",\n",
    "\"M Series Alloy\",\n",
    "\"M Series High Speed Steel\",\n",
    "\"Mylar\",\n",
    "\"Natural Material\",\n",
    "\"NBR\",\n",
    "\"Neoprene\",\n",
    "\"Nickel\",\n",
    "\"Nitrile\",\n",
    "\"Nylon\",\n",
    "\"Nylon 11\",\n",
    "\"Nylon 6/6\",\n",
    "\"Nylon/Carbon Steel\",\n",
    "\"Palmetto\",\n",
    "\"Paper\",\n",
    "\"Plastic\",\n",
    "\"Plastisol\",\n",
    "\"Polyamide\",\n",
    "\"Polycarbonate\",\n",
    "\"Polyester\",\n",
    "\"Polyethylene\",\n",
    "\"Polyethylene Terephthalate (PET)\",\n",
    "\"Polymer\",\n",
    "\"Polymer Plastic\",\n",
    "\"Polyolefin\",\n",
    "\"Polypropylene\",\n",
    "\"Polystyrene\",\n",
    "\"Polyurethane\",\n",
    "\"Proprietary Alloy Steel\",\n",
    "\"PTFE\",\n",
    "\"Pure Tungsten\",\n",
    "\"PVC\",\n",
    "\"Resin\",\n",
    "\"Rubber\",\n",
    "\"S2 Impact Steel\",\n",
    "\"Silcone\",\n",
    "\"Silicon Bronze\",\n",
    "\"Silicon Carbide\",\n",
    "\"Silicone\",\n",
    "\"Silver\",\n",
    "\"Sintered Bronze\",\n",
    "\"Solid Steel\",\n",
    "\"Spandex\",\n",
    "\"Spring Steel\",\n",
    "\"Stainless Steel\",\n",
    "\"Stainless Steel\",\n",
    "\"Steel\",\n",
    "\"Steel Alloy\",\n",
    "\"Stone\",\n",
    "\"Tampico\",\n",
    "\"Tempered Steel\",\n",
    "\"Thermoplastic\",\n",
    "\"Thoriated Tungsten\",\n",
    "\"Tin\",\n",
    "\"Tool Steel\",\n",
    "\"Tungsten\",\n",
    "\"Tungsten Carbide\",\n",
    "\"Tungsten Steel\",\n",
    "\"Various\",\n",
    "\"Vellumoid\",\n",
    "\"Vinyl\",\n",
    "\"Wood\",\n",
    "\"Wood\",\n",
    "\"Wool\",\n",
    "\"Zamak Alloy Carbon Steel\",\n",
    "\"Zinc\",\n",
    "\"Zinc Alloy\",\n",
    "\"Zinc Die Cast\",\n",
    "\"Zirconia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_match=material[(material[\"value\"] != material[\"Material\"])]\n",
    "x=not_match[(not_match['value'].astype(str)!='n/a')&(not_match['value'].astype(str)!='[\"n/a\"]')]\n",
    "x[x['external_id'].astype(str)=='26605']\n",
    "x[x['Material'].astype(str)!='Forged Alloy Steel'][0:500]\n",
    "matches=x[~(x['Material'].isin(lst))&(x['value'].astype(str)!='Alloy Steel')&(x['Material'].astype(str)!='nan')&(x['Material'].astype(str)!='Aluminum Oxide/Silicon Carbide')&(x['Material'].astype(str)!='Silicone Carbide')&(x['value'].astype(str)!='M Series Alloy')]                                   \n",
    "print(len(matches))\n",
    "matches['value'].explode().value_counts()\n",
    "\n",
    "# Chlorinated Polyvinyl Chloride \n",
    "# Polyvinyl Chloride\n",
    "# Lead-Free Zinc\n",
    "# Food Grade Acetyl Copolymer\n",
    "# Chlorinated Polyvinyl Chloride\n",
    "# Polybutylene Terephthalate Resin\n",
    "# Glass Tube\n",
    "# Hi-Molybdenum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# material[(material['Material'].astype(str)=='Isoplastic')]#['value'].explode().value_counts()#&(df['value'].astype(str)=='terminal value')]\n",
    "# material['Material'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['attribute'].astype(str)=='material')&(df['value'].astype(str)=='n/a')&(df['Material'].astype(str)!='nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '144'\n",
    "customer_name='%motionapac%'\n",
    "dateszs='2021-11-01'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "motion = query_from_file(file_name='../query/curated_all_attributes_date_family.sql', params=params)\n",
    "print(len(motion))\n",
    "# df['time']=df['time'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(.{0,20}BS\\dM.{0,20})|()'''\n",
    "motion['matches']=motion['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "motions=motion[(motion['matches'].astype(str)!='[]')]\n",
    "motions['matches'].explode().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion[motion['atttribute'].astype(str)=='thread_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion['attribute'].explode().value_counts()\n",
    "motion[(motion['attribute'].astype(str)=='amperage')]['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsuccessful=owc['external_id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_width=motion[motion['attribute'].astype(str)=='overall_width']\n",
    "# na_ow=overall_width[overall_width['value'].astype(str)=='n/a']\n",
    "# overall=overall_width[overall_width['value'].astype(str)!='n/a']\n",
    "# id_ow=na_ow['external_id'].to_list()\n",
    "# overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ow=motion[(motion['external_id'].isin(unsuccessful))&(motion['attribute'].astype(str)=='overall_width')]\n",
    "# ow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall=motion[(motion['attribute'].astype(str)=='overall_width_converted')&(motion['value'].astype(str)!='n/a')]\n",
    "# print(len(overall))\n",
    "# trip=r'''(\\d+\\,\\d+)|()'''                                                              \n",
    "# overall['match']=overall['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# fix=overall[(overall['match'].astype(str)!='[]')]\n",
    "# print(len(fix))\n",
    "# fix['Q:overall_width']=fix['value'].apply(lambda x: re.sub(r'\\s?MM',' mm',str(x)))\n",
    "# fix['Q:overall_width']=''\n",
    "# match_fix=fix[['external_id','Q:overall_width']]\n",
    "# fix['match'].explode().value_counts()[-500:]\n",
    "# fix[fix['value'].astype(str)=='12,700 MM']\n",
    "# fix[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall[overall['value'].astype(str)=='unsucessful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motions=motion[(motion['value'].astype(str)!='n/a')]\n",
    "trip=r'''(?i)(\\d)|()'''                                                              \n",
    "motions['match']=motions['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=motions[motions['match'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(\\d\\s\\d)|(\\d{2,}\\s?\\-\\s?\\d)|(MM)|(\\d\\\\\\d+\\\\\\d)|()'''                                                              \n",
    "bracket['matches']=bracket['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "fix=bracket[(bracket['matches'].astype(str)!='[]')&(bracket['resolution'].astype(str)!='rules')]\n",
    "print(len(fix))\n",
    "bracket[(bracket['resolution'].astype(str)!='rules')]['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=bracket[(bracket['resolution'].astype(str)!='rules')&(bracket['attribute'].astype(str)=='cone_width')]\n",
    "\n",
    "# trip=r'''(\\ds\\d)|(in)|()'''                                                              \n",
    "# x['x']=x['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# x[(x['x'].astype(str)!='[]')]\n",
    "# x[0:500]            \n",
    "            \n",
    "# print(len(x))\n",
    "# x['value'].explode().value_counts()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip=r'''(MM)|()'''                                                              \n",
    "# bracket['matches']=bracket['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# fixing=bracket[bracket['matches'].astype(str)!='[]']\n",
    "# bracket[bracket['resolution'].astype(str)!='rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw=fix[fix['attribute'].astype(str)=='cone_width']\n",
    "cw['Q:cone_width']=''\n",
    "match_cw=cw[['external_id','Q:cone_width']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_cw.csv',index=False) \n",
    "looks_good('Motion APAC', match_cw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od=fix[fix['attribute'].astype(str)=='outside_diameter']\n",
    "od['Q:outside_diameter']=''\n",
    "match_od=od[['external_id','Q:outside_diameter']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_od.csv',index=False) \n",
    "looks_good('Motion APAC', match_od) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inside=fix[fix['attribute'].astype(str)=='inside_diameter']\n",
    "inside['Q:inside_diameter']=''\n",
    "match_inside=inside[['external_id','Q:inside_diameter']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_inside.csv',index=False) \n",
    "looks_good('Motion APAC', match_inside) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ow=fix[fix['attribute'].astype(str)=='overall_width']\n",
    "ow['Q:overall_width']=''\n",
    "match_ow=ow[['external_id','Q:overall_width']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready for uploads' \n",
    "    matches.to_csv(f'{drive_path}/Motion --{get_df_name(matches)}match_ow.csv',index=False) \n",
    "looks_good('Motion APAC', match_ow) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dollar Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '135'\n",
    "customer_name='%dollartree%'\n",
    "dateszs='2022-06-11'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "# dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# fields = ['Set_Size']\n",
    "# df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# josABank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '39'\n",
    "customer_name='%josabank%'\n",
    "dateszs='2001-06-01'\n",
    "dateszsz='2023-01-12'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'dateszsz':dateszsz}\n",
    "wbm = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "wbm=wbm[wbm['resolution'].astype(str)!='rules']\n",
    "print(len(wbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=wbm\n",
    "cs=df[df['attribute'].astype(str)=='collar_style']\n",
    "pat='''(?i)(hidden)|()'''\n",
    "cs['m_name']=cs['product_name'].apply(lambda x: re_extract(pat,x))\n",
    "cs['m_long']=cs['product_name'].apply(lambda x: re_extract(pat,x))\n",
    "cs['m_custom']=cs['product_name'].apply(lambda x: re_extract(pat,x))\n",
    "hid=cs[(cs['m_name'].astype(str)!='[]')|(cs['m_long'].astype(str)!='[]')|(cs['m_custom'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hid))\n",
    "hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden Button-Down Collar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lovely Skin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '115'\n",
    "customer_name='%lovelyskin%'\n",
    "dateszs='2022-06-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "wbm = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "wbm=wbm[wbm['resolution'].astype(str)!='rules']\n",
    "print(len(wbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbm[wbm['attribute'].astype(str)=='skin_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mens Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '21'\n",
    "customer_name='%menswearhouse%'\n",
    "dateszs='2022-06-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "wbm = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "wbm=wbm[wbm['resolution'].astype(str)!='rules']\n",
    "print(len(wbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbm['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SallyBeauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '19'\n",
    "customer_name='%sallybeauty%'\n",
    "dateszs='2022-06-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "wbm = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "wbm=wbm[(wbm['resolution'].astype(str)!='rules')]\n",
    "print(len(wbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbm['attribute'].explode().value_counts()\n",
    "# wbm[(wbm['attribute'].astype(str)=='benefit')&(wbm['resolution'].astype(str)!='rules')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tractor Supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '64'\n",
    "customer_name='%tractorsupply%'\n",
    "dateszs='2022-06-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfs=dfs[dfs['resolution'].astype(str)!='rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_stage=dfs[(dfs['attribute'].astype(str)=='life_stage')&(dfs['value'].astype(str)=='n/a')&((dfs['buckets'].astype(str)=='Livestock Control Products & Accessories')|dfs['buckets'].astype(str)=='Livestock Feed')|(dfs['buckets'].astype(str)=='Livestock & Poultry Supplements')]\n",
    "print(len(life_stage))\n",
    "life=life_stage[['buckets','value','external_id','long_desc','custom_fields']]\n",
    "life#['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life['Q:life_stage']=''\n",
    "match_life=life[['external_id','Q:life_stage']]\n",
    "print(len(match_life))\n",
    "match_life\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_ReadyForUpload' \n",
    "    matches.to_csv(f'{drive_path}/TractorSupply --{get_df_name(matches)}-{today}match_life.csv',index=False) \n",
    "looks_good('TractorSupply', match_life) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbm[wbm['attribute'].astype(str)=='shoe_style']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '32'\n",
    "customer_name='%eddiebauer%'\n",
    "dateszs='2022-07-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "wbm = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "# df=df[df['resolution'].astype(str)!='rules']\n",
    "print(len(wbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbm[wbm['buckets'].astype(str)=='']['insulation_type']\n",
    "x=wbm[wbm['attribute'].astype(str)=='material']['buckets'].explode().value_counts().reset_index()['index'].to_list()\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=wbm[wbm['attribute'].astype(str)=='Closure']['buckets'].explode().value_counts().reset_index()['index'].to_list()\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wbm))\n",
    "# wbm=wbm[(wbm['attribute'].astype(str)=='care')&(wbm['resolution'].astype(str)!='rules')]\n",
    "wbm=wbm[(wbm['resolution'].astype(str)!='rules')]\n",
    "\n",
    "print(len(wbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm[(wbm['attribute'].astype(str)=='neckline')&(wbm['resolution'].astype(str)!='rules')]['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbm['attribute'].explode().value_counts()\n",
    "# wbm[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm=eb\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()\n",
    "# width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "# depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "# height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WBMason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '90'\n",
    "customer_name='%wbmason%'\n",
    "dateszs='2001-01-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfs=dfs[dfs['resolution'].astype(str)!='rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ring=dfs[dfs['attribute'].astype(str)=='ring_size']\n",
    "\n",
    "trip=r'''(?i)(\\d+\\s\\d+\\/)|()'''                                                              \n",
    "ring['match']=ring['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "ring_size=ring[ring['match'].astype(str)!='[]']\n",
    "\n",
    "\n",
    "ring_size['Q:ring_size']=ring_size['value'].apply(lambda x: re.sub(r'((?<=\\d) (?=\\d))','-',str(x)))\n",
    "print(len(ring_size))\n",
    "match_ring_size=ring_size[['external_id','Q:ring_size']]\n",
    "match_ring_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}match_ring_size-{today}.csv',index=False) \n",
    "# looks_good('WBMason', match_ring_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol=dfs[dfs['attribute'].astype(str)=='volume_ml']\n",
    "\n",
    "trip=r'''(?i)(\\d\\d\\d\\d)|()'''                                                              \n",
    "vol['match']=vol['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "vol_ml=vol[vol['match'].astype(str)!='[]']\n",
    "\n",
    "\n",
    "vol_ml['Q:volume_ml']=vol_ml['value'].apply(lambda x: re.sub(r'((?<=\\d)(?=\\d\\d\\d(?!\\d)))',',',str(x)))\n",
    "vol_ml\n",
    "match_volume_ml=vol_ml[['external_id','Q:volume_ml']]\n",
    "# match_volume_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}match_volume_ml-{today}.csv',index=False) \n",
    "# looks_good('WBMason', match_volume_ml) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oz=dfs[dfs['attribute'].astype(str)=='capacity_oz']\n",
    "\n",
    "trip=r'''(?i)(oz\\.)|()'''                                                              \n",
    "oz['match']=oz['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "capacity=oz[oz['match'].astype(str)!='[]']\n",
    "\n",
    "\n",
    "capacity['Q:capacity_oz']=capacity['value'].apply(lambda x: re.sub(r'(oz\\.)','oz',str(x)))\n",
    "# capacity\n",
    "match_capacity=capacity[['external_id','Q:capacity_oz']]\n",
    "capacity[capacity['match'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}match_capacity-{today}.csv',index=False) \n",
    "# looks_good('WBMason', match_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bond_time, bulb_base_size, capacity_c, coins_per_minute, decibels_db, diameter_metric, diameter_sae, diopter, effective_megapixels, fire_extinguisher_class,fits_strapping_width, flow_rate_gpm,handlebar_height, indicator_type\n",
    "# jaw_width, keg_capacity, lens_height,lubricant_material,maximum_focal_length,maximum_optical_zoom, maximum_torque,milliamp_hours_mah,offset_bond, pallet_type, plate_thickness, psi, rackable_load_capacity\n",
    "# rack_spacing, results_timing, seat_height, shelf_life, surveillance_camera_resolution, teeth_per_inch,trim_length, video_recorder_type, volume_gram,wire_gauge_awg\n",
    "\n",
    "#### grade (commercial, residential)\n",
    "#### handle_length (\\d \\d\\/\\d)\n",
    "#### hard_drive_form_factor (in. also m.2 2280)\n",
    "#### impression_width (\\d -\\d\\/\\d)\n",
    "### ink_color(double check all colors)\n",
    "### Length-several values off--->also check Height\n",
    "### marker_type (art and Art)\n",
    "### nutritional_information (double check)\n",
    "### packaging_material_type (double check)\n",
    "### pages_per_minute (3,000 pages per minute seems a bit high)\n",
    "### pallet_quantity (thousand comma seperator)\n",
    "### pile (PIle)\n",
    "### post_consumer_recycled_content_percent (.30%-->do we need to drop the zero)\n",
    "### printer_type (double check)\n",
    "### processor_series (double check)\n",
    "### product_form (double check)\n",
    "### random_access_memory_ram (\\d GB)\n",
    "\n",
    "### scent (double check)\n",
    "### size (double check)\n",
    "### spindle_speed_rpm (no thousand comma seperator)\n",
    "### steel_gauge ( 18 and no gauge)\n",
    "### subject (double check)\n",
    "### surface_application (double check)\n",
    "### table_type (double check)\n",
    "### tape_type (double check)\n",
    "### thickness (.\\d)\n",
    "### thickness_mil (\\d\\s\\smil)\n",
    "### tip_style (double check)\n",
    "### toilet_paper_type (double check)\n",
    "### total_recycled_content_percent (.0%)\n",
    "### voltage_dc (120 V)\n",
    "### volume_gal (gal.)\n",
    "### volume_lb (lbs)\n",
    "### volume_ml (should we have thousand commsubjecta seperators?)\n",
    "### volume_oz (oz.)\n",
    "### water_type (double check)\n",
    "### weight_capacity (double check)\n",
    "### (width)\n",
    "\n",
    "\n",
    "### volume_ml (thousand comma seperators)\n",
    "### ring_size (\\d \\d\\/\\d)\n",
    "### rack_spacing (\" instead of inch)\n",
    "### maximum_laptop_size (size in \" not in inches)\n",
    "# capacity_oz--clean up oz. and oz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d=dfs[dfs['attribute'].astype(str)=='processor_speed_g_hz'] #Dots Per Inch Printers/Scanners (DPI)\n",
    "print(len(three_d))\n",
    "# three_d['buckets'].explode().value_counts()\n",
    "three_d['value'].explode().value_counts()#[500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three_s=three_d[(three_d['value'].astype(str)=='16 - 23.9 oz.')|(three_d['value'].astype(str)=='80 oz. or Greater')|(three_d['value'].astype(str)=='72 - 79.9 oz.')|(three_d['value'].astype(str)=='8 - 15.9 oz..')|(three_d['value'].astype(str)=='24 - 31.9 oz.')|(three_d['value'].astype(str)=='32 - 39.9 oz.')|(three_d['value'].astype(str)=='16 - 23.9 oz.')]\n",
    "# three_s['Q:volume_oz']=three_s['value'].apply(lambda x: re.sub(r'(?i)(oz\\.)','oz',str(x)))\n",
    "# # # # three_s['Q:pile'].explode().value_counts()\n",
    "# match_volume_oz=three_s[['external_id','Q:volume_oz']]\n",
    "# match_volume_oz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(heights,col, texto):\n",
    "    regex_pattern_rounding=rf'''((?<!\\d.)(?:in|ft|mil|lb|gal|oz|yd))|(\\d\\s\\d+\\/\\d+)|(\\d\\d\\d\\d)|((?<!\\d)\\.\\d)|(\\d\\s\\-)|((?:in|ft|mil|lb|gal|oz)\\.)|([cehj-kp-su-x])|()'''         \n",
    "    heights['rounding'] = heights[col].apply(lambda x: re_extract(regex_pattern_rounding, x))\n",
    "    print('Number of SKUs that need Rounding: '+ str(len(heights[heights['rounding'].astype(str)!='[]'])))\n",
    "    return heights[heights['rounding'].astype(str)!='[]'] \n",
    "\n",
    "r=rounding(three_d, 'value','\\d\\,\\sa-eghj-lo-su-z')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['Q:impression_width']=r['value'].apply(lambda x: re.sub(r'((?<=\\d)\\s(?=\\d\\/))|((?<=\\d)\\s(?=\\d\\d\\/))','-',str(x)))\n",
    "match_impression_width=r[['external_id','Q:impression_width']]\n",
    "match_impression_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}match_volume_oz-{today}.csv',index=False) \n",
    "looks_good('WBMason', match_volume_oz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_s=three_d[(three_d['value'].astype(str)=='1,000  DPI')]\n",
    "three_s['Q:dots_per_inch_mice_dpi']=three_s['value'].apply(lambda x: re.sub(r'(\\s\\s)',' ',str(x)))\n",
    "print(len(three_s))\n",
    "three_s\n",
    "match_dots_per_inch_mice_dpi=three_s[['external_id','Q:dots_per_inch_mice_dpi']]\n",
    "match_dots_per_inch_mice_dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=['bond_time', 'bulb_base_size', 'capacity_c', 'coins_per_minute', 'decibels_db', 'diameter_metric', 'diameter_sae', 'diopter', 'effective_megapixels', 'fire_extinguisher_class','fits_strapping_width', \n",
    "     'flow_rate_gpm','handlebar_height','indicator_type', 'jaw_width', 'keg_capacity', 'lens_height','lubricant_material','maximum_focal_length','maximum_optical_zoom', 'maximum_torque','milliamp_hours_mah',\n",
    "     'offset_bond', 'pallet_type', 'plate_thickness', 'psi','rackable_load_capacity', 'rack_spacing', 'results_timing', 'seat_height', 'shelf_life', 'surveillance_camera_resolution', 'teeth_per_inch','trim_length', \n",
    "     'video_recorder_type', 'volume_gram','wire_gauge_awg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs['attribute'].astype(str)=='lens_height']['value'].explode().value_counts().reset_index()['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(lst)):\n",
    "#     print('')\n",
    "#     print('Attribute: '+f'{lst[i]}')\n",
    "#     x=dfs[dfs['attribute'].astype(str)==f'{lst[i]}']\n",
    "#     print('Total Number of SKUs: '+str(len(x)))\n",
    "#     na=x[x['value'].astype(str)=='n/a']\n",
    "#     print('Total Number of N/A Values: '+str(len(na)))\n",
    "#     try:\n",
    "#         print('Percent of N/A Values: '+str(round((len(na)/len(x))*100,0))+'%')\n",
    "#     except:\n",
    "#         print('There are no SKUs')\n",
    "#     print('Values: '+str(x['value'].explode().value_counts().reset_index()['index'].to_list()))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d['value'].explode().value_counts()\n",
    "# three_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_s=three_d[(three_d['value'].astype(str)=='1,000  DPI')]\n",
    "three_s['Q:dots_per_inch_mice_dpi']=three_s['value'].apply(lambda x: re.sub(r'(\\s\\s)',' ',str(x)))\n",
    "print(len(three_s))\n",
    "three_s\n",
    "match_dots_per_inch_mice_dpi=three_s[['external_id','Q:dots_per_inch_mice_dpi']]\n",
    "match_dots_per_inch_mice_dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}match_dots_per_inch_mice_dpi-{today}.csv',index=False) \n",
    "looks_good('WBMason', match_dots_per_inch_mice_dpi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload'\n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}-AI.csv',index=False) \n",
    "looks_good('WBMason', match_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_s=three_d[three_d['buckets'].astype(str)=='Sofas/Couches/Loveseats/Settees']\n",
    "print(len(three_d))\n",
    "three_s['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_d[(three_d['value'].astype(str)=='27,000A')|(three_d['value'].astype(str)=='125 ft')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=[8,9,10,11,12,13,14,15,16,17,18,19,'[2-9][0-9]']\n",
    "\n",
    "for kk in range(len(abc)):\n",
    "    print(f'''((?<!\\d)(?!')(?<!'.)(?<!\".)(?<!\"){abc[kk]}(?!\\d)(?!.foot)(?!.inch)(?!.light)(?!.drawer)(?!.door)(?!')(?!\")(?!.x)(?:\\W?piece)?(?!\\d))|(pack of.?(?<!\\d){abc[kk]}(?!\\d))|((?<!\\d){abc[kk]}(?!\\d).?pcs)|(set(?:.?of.?)?.?(?<!\\d)({abc[kk]}?!\\d))''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rules=len(wbm[(wbm['attribute'].astype(str)=='product_type')|(wbm['attribute'].astype(str)=='features')|(wbm['attribute'].astype(str)=='material')|(wbm['attribute'].astype(str)=='color')|(wbm['attribute'].astype(str)=='indoor_outdoor')])\n",
    "total=len(wbm)\n",
    "percent=str(round((no_rules/total)*100,2))+'%'\n",
    "\n",
    "print('Product Type/Features/Material/Color/indoor_outdoor: '+str(no_rules))\n",
    "print('Total WBM SKUs for June/July/August: '+str(total))\n",
    "print('Percentage Attributes Cannot Write Rules: '+str(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak=wbm[wbm['attribute'].astype(str)=='peak_transfer_speed']\n",
    "\n",
    "trip=r'''(?i)(\\d\\d\\d\\d(?!\\d))|()'''                                                              \n",
    "peak['match']=peak['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "peaks=peak[peak['match'].astype(str)!='[]']\n",
    "peaks['matches']=peaks['value'].apply(lambda x: re.sub(r'(?<=\\d)(?=\\d\\d\\d(?!\\d))',',',str(x)))\n",
    "peaks['Q:peak_transfer_speed']=peaks['matches']\n",
    "match_peaks=peaks[['external_id','Q:peak_transfer_speed']]\n",
    "peaks['matches'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload'\n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}-AI.csv',index=False) \n",
    "looks_good('WBMason', match_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBBY Bed Bath and Beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bbby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2022-11-01'\n",
    "dateszsz='2022-11-30'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'dateszsz':dateszsz}\n",
    "print('start')\n",
    "# dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_dates.sql', params=params)\n",
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2022-11-01'\n",
    "dateszsz='2022-11-30'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'dateszsz':dateszsz}\n",
    "print('start')\n",
    "# dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfs = query_from_file(file_name='../query/internal_external.sql', params=params)\n",
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs[dfs['resolution'].astype(str)=='standard']\n",
    "\n",
    "def three(usa,reg):\n",
    "    print('Start')\n",
    "    trip=fr'''(?i){reg}|()''' \n",
    "    usa['m_name']=usa['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    usa['m_desc']=usa['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    usa['m_custom']=usa['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    main=usa[(usa['m_name'].astype(str)!='[]')]\n",
    "    middle=usa[(usa['m_name'].astype(str)=='[]')&((usa['m_desc'].astype(str)!='[]')|(usa['m_custom'].astype(str)!='[]'))]\n",
    "    na=usa[(usa['m_name'].astype(str)=='[]')&(usa['m_desc'].astype(str)=='[]')&(usa['m_custom'].astype(str)=='[]')]\n",
    "    print('')\n",
    "    print('values: '+str(len(main)))\n",
    "    print('No name but call outs: '+str(len(middle)))\n",
    "    print('no values: '+str(len(na)))\n",
    "    print('')\n",
    "    return main,middle,na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_id = '5'\n",
    "# customer_name='%bedbathandbeyond%'\n",
    "# dateszs='2001-08-11'\n",
    "# attribut='origin'\n",
    "# params = {'customer_id': customer_id,\n",
    "#           'customer_name':customer_name,\n",
    "#          'dateszs':dateszs,\n",
    "#          'attribute':attribut}\n",
    "# print('start')\n",
    "# dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "# print('continuing')\n",
    "# # dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "# # print('dfs')\n",
    "# # dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # print('customs')\n",
    "# # custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# # df=pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "# # print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_field_df=pd.json_normalize(dfs['custom_fields'])\n",
    "# df=pd.concat([dfs.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# care=dfs[dfs['attribute'].astype(str)=='care']\n",
    "# care['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dollar tree/family dollar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs[(dfs['attribute'].astype(str)!='keywords')&(dfs['resolution'].astype(str)!='rules')]\n",
    "print(len(df))\n",
    "df['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df['attribute'].value_counts().reset_index()['index'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst=df['attribute'].value_counts().reset_index()['index'].to_list()\n",
    "# for i in range(len(lst)):\n",
    "#     lst[i]=pd.DataFrame()\n",
    "#     lst[i]=df[df['attribute'].astype(str)==lst[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "care=df[(df['attribute'].astype(str)=='rug_size')]\n",
    "print(len(care))\n",
    "print(len(care[care['value'].astype(str)=='n/a']))\n",
    "# pat='''(.{0,10}(?:\\d\\'\\s?x\\s?\\d+\\'|\\d+\\'\\s?round|\\d+\\'\\s?rug.?runner|\\d+\\'\\s?square|\\d+\\'\\s?runner).{0,10})'''\n",
    "# x,y=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by\n",
    "((?<!\\d)(?:2)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?\\s?x\\s?(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:2)?)|((?:18|24)(?:\\\\?\")?[^\\w]x[^\\w](?:36)(?:\\\\?\")?)|\n",
    "((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:[45])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?)|((?<!\\d)42\\\\?\"\\s?x\\s?66\\\\?\")|\n",
    "((?<!\\d)(?:[7])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:[8])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:1[0-1])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:[7])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:1[0-1])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:[8])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|                      \n",
    "((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6|9)?)|((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|\n",
    "((?<!\\d)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11|7)?)|    \n",
    "((?<!\\d)(?:6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|\n",
    "((?<!\\d)(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|\n",
    "((?<!\\d)(?:10)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|\n",
    "((?<!\\d)(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round\n",
    "((?<!\\d)(?:3)\\'?[^\\w]?x[^\\w]?(?:3)\\'?)|((?:3)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)3'?\\s?[0-7][^\\w]?x[^\\w]?3'?\\s?[0-7])|(3'?\\s?x\\s?(?:round|square))|\n",
    "((?<!\\d)(?:4)\\'?[^\\w]?x[^\\w]?(?:4)\\'?)|((?:4)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)4'?\\s?[0-7][^\\w]?x[^\\w]?4'?\\s?[0-7])|(4'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'4'')|\n",
    "((?<!\\d)(?:5)\\'?[^\\w]?x[^\\w]?(?:5)\\'?)|((?:5)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)5'?\\s?[0-7][^\\w]?x[^\\w]?5'?\\s?[0-7])|(5'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'5'')|\n",
    "((?<!\\d)(?:6)\\'?[^\\w]?x[^\\w]?(?:6)\\'?)|((?:6)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)6'?\\s?[0-7][^\\w]?x[^\\w]?6'?\\s?[0-7])|(6'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'6'')|\n",
    "((?<!\\d)(?:7)\\'?[^\\w]?x[^\\w]?(?:7)\\'?)|((?:7)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)7'?\\s?[0-7][^\\w]?x[^\\w]?7'?\\s?[0-7])|(7'?\\s?x\\s?(?:round|square))(sku.?size\\'\\:\\s?\\'7'')|\n",
    "((?<!\\d)(?:8)\\'?[^\\w]?x[^\\w]?(?:8)\\'?)|((?:8)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)8'?\\s?[0-7][^\\w]?x[^\\w]?8'?\\s?[0-7])|(8'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'8'')|\n",
    "((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'9'')|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner\n",
    "((?<!\\d)(?:4)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:4)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:4)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:5)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:5)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:5)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:6)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:6)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:6)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:7)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:7)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:7)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:8)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:8)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:8)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:9)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:9)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:9)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:10)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:10)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:10)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:11)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:11)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:11)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:12)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:12)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:12)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:1[3-9])\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:1[3-9])\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:1[3-9])\\'?\\s?(?:2)?)|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N/A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (?i)((?<!\\d)(?:3)\\'?[^\\w]?x[^\\w]?(?:3)\\'?)|((?:3)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)3'?\\s?[0-7][^\\w]?x[^\\w]?3'?\\s?[0-7])|(3'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:4)\\'?[^\\w]?x[^\\w]?(?:4)\\'?)|((?:4)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)4'?\\s?[0-7][^\\w]?x[^\\w]?4'?\\s?[0-7])|(4'?\\s?x\\s?(?:round|square))((?<!\\d)(?:5)\\'?[^\\w]?x[^\\w]?(?:5)\\'?)|((?:5)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)5'?\\s?[0-7][^\\w]?x[^\\w]?5'?\\s?[0-7])|(5'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:6)\\'?[^\\w]?x[^\\w]?(?:6)\\'?)|((?:6)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)6'?\\s?[0-7][^\\w]?x[^\\w]?6'?\\s?[0-7])|(6'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:7)\\'?[^\\w]?x[^\\w]?(?:7)\\'?)|((?:7)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)7'?\\s?[0-7][^\\w]?x[^\\w]?7'?\\s?[0-7])|(7'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:8)\\'?[^\\w]?x[^\\w]?(?:8)\\'?)|((?:8)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)8'?\\s?[0-7][^\\w]?x[^\\w]?8'?\\s?[0-7])|(8'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:2)\\'?(?:\\s)?(?:[0-6])?\\s?x\\s?(?:3)\\'?(?:\\s)?(?:2)?)|((?<!\\d)(?:3)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:[45])\\'?(?:\\s)?(?:6)?)|((?<!\\d)42\\\\?\"\\s?x\\s?66\\\\?\")|((?<!\\d)(?:[7])\\'?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:9)\\'?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:[8])\\'?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:1[0-1])\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:[7])\\'?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:1[0-1])\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:[8])\\'?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:9)\\'?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:5)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)\\'?(?:\\s)?(?:6|9)?)|((?<!\\d)(?:5)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:4)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)\\'?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:3)\\'?(?:\\s)?(?:6)?(?:\\d)?\\s?x\\s?(?:5)\\'?(?:\\s)?(?:6)?)|((?<!\\d)(?:3)\\'?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:5)\\'?(?:\\s)?(?:11|7)?)|((?<!\\d)(?:6)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:5)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)\\'?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:4)\\'?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:7)\\'?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:7)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:9)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:12|13)\\'?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?:10)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)\\'?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?:12)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)\\'?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?:4)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:4)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:4)\\'?\\s?(?:2)?)|((?<!\\d)(?:5)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:5)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:5)\\'?\\s?(?:2)?)|((?<!\\d)(?:6)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:6)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:6)\\'?\\s?(?:2)?)|((?<!\\d)(?:7)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:7)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:7)\\'?\\s?(?:2)?)|((?<!\\d)(?:8)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:8)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:8)\\'?\\s?(?:2)?)|((?<!\\d)(?:9)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:9)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:9)\\'?\\s?(?:2)?)|((?<!\\d)(?:10)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:10)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:10)\\'?\\s?(?:2)?)|((?<!\\d)(?:11)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:11)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:11)\\'?\\s?(?:2)?)|((?<!\\d)(?:12)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:12)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:12)\\'?\\s?(?:2)?)|((?<!\\d)(?:1[3-9])\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:1[3-9])\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:1[3-9])\\'?\\s?(?:2)?)   \n",
    "trip=r'''(?i)((?<!\\d)(?:4)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:4)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:4)\\'?\\s?(?:2)?)|((?<!\\d)(?:5)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:5)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:5)\\'?\\s?(?:2)?)|((?<!\\d)(?:6)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:6)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:6)\\'?\\s?(?:2)?)|((?<!\\d)(?:7)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:7)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:7)\\'?\\s?(?:2)?)|((?<!\\d)(?:8)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:8)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:8)\\'?\\s?(?:2)?)|((?<!\\d)(?:9)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:9)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:9)\\'?\\s?(?:2)?)|((?<!\\d)(?:10)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:10)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:10)\\'?\\s?(?:2)?)|((?<!\\d)(?:11)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:11)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:11)\\'?\\s?(?:2)?)|((?<!\\d)(?:12)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:12)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:12)\\'?\\s?(?:2)?)|((?<!\\d)(?:1[3-9])\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:1[3-9])\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:1[3-9])\\'?\\s?(?:2)?)|((?<!\\d)(?:3)\\'?[^\\w]?x[^\\w]?(?:3)\\'?)|((?:3)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)3'?\\s?[0-7][^\\w]?x[^\\w]?3'?\\s?[0-7])|(3'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:4)\\'?[^\\w]?x[^\\w]?(?:4)\\'?)|((?:4)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)4'?\\s?[0-7][^\\w]?x[^\\w]?4'?\\s?[0-7])|(4'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'4'')|((?<!\\d)(?:5)\\'?[^\\w]?x[^\\w]?(?:5)\\'?)|((?:5)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)5'?\\s?[0-7][^\\w]?x[^\\w]?5'?\\s?[0-7])|(5'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'5'')|((?<!\\d)(?:6)\\'?[^\\w]?x[^\\w]?(?:6)\\'?)|((?:6)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)6'?\\s?[0-7][^\\w]?x[^\\w]?6'?\\s?[0-7])|(6'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'6'')|((?<!\\d)(?:7)\\'?[^\\w]?x[^\\w]?(?:7)\\'?)|((?:7)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)7'?\\s?[0-7][^\\w]?x[^\\w]?7'?\\s?[0-7])|(7'?\\s?x\\s?(?:round|square))(sku.?size\\'\\:\\s?\\'7'')|((?<!\\d)(?:8)\\'?[^\\w]?x[^\\w]?(?:8)\\'?)|((?:8)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)8'?\\s?[0-7][^\\w]?x[^\\w]?8'?\\s?[0-7])|(8'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'8'')|((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'9'')|((?<!\\d)(?:2)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?\\s?x\\s?(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:2)?)|((?:18|24)(?:\\\\?\")?[^\\w]x[^\\w](?:36)(?:\\\\?\")?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:[45])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?)|((?<!\\d)42\\\\?\"\\s?x\\s?66\\\\?\")|((?<!\\d)(?:[7])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:[8])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:1[0-1])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:[7])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:1[0-1])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:[8])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6|9)?)|((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11|7)?)|((?<!\\d)(?:6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:10)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|()'''\n",
    "x,y,na=three(care,trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=x[x['value'].astype(str)=='n/a']\n",
    "print(len(val))\n",
    "na=y[y['value'].astype(str)!='n/a']\n",
    "print(len(na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na[(na['value'].astype(str)!=\"5' Round/Square\")]['product_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eight_by_ten=care[care['value'].astype(str)==\"4' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\d)(?:2|2\\.25)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?:2|2\\.25)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\d)7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2))?)|((?<!\\.)(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?)?[^\\w]?x[^\\w]?(?<!\\d)(?:2|2\\.25)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|(2\\'\\s?x\\s?7\\')'''                            \n",
    "four_runner,middle,na=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(care[care['value'].astype(str)==\"4' Runner\"]))\n",
    "# print(na['value'].value_counts())\n",
    "print(len(na[(na['value'].astype(str)=='n/a')]))\n",
    "na[(na['value'].astype(str)=='n/a')&((na['m_name'].astype(str)!='''[]''')|(na['m_desc'].astype(str)!='''[]''')|(na['m_custom'].astype(str)!='''[]'''))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(care[care['value'].astype(str)==\"4' Runner\"]))\n",
    "print(middle['value'].value_counts())\n",
    "middle[(middle['value'].astype(str)=='n/a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(care[care['value'].astype(str)==\"4' Runner\"]))\n",
    "print(four_runner['value'].value_counts())\n",
    "four_runner[(four_runner['value'].astype(str)=='n/a')&(four_runner['value'].astype(str)!='''6' Runner''')]['product_name'].value_counts()\n",
    "four_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(num_one,num_two):        \n",
    "    pat=fr'''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:{num_one})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:{num_two})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:{num_one})(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:{num_two})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:{num_two}))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:{num_one})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:{num_two})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:{num_two})|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:{num_two})'?\\s?x\\s?{num_one}\\'?)'''                        \n",
    "    print(pat)\n",
    "\n",
    "run('4','''2|2\\.25|2'?\\s?0\"?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run('4',2)\n",
    "print(\"4' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"4' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?4\\'?)'''                            \n",
    "four_first,four_mid,four_na=three(care,pat)\n",
    "\n",
    "print(\"5' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"5' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?5\\'?)'''                            \n",
    "five_first,five_mid,five_na=three(care,pat)\n",
    "\n",
    "print(\"6' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"6' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?6\\'?)'''                            \n",
    "six_first,six_mid,six_na=three(care,pat)\n",
    "\n",
    "print(\"7' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"7' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?7\\'?)'''                            \n",
    "seven_first,seven_mid,seven_na=three(care,pat)\n",
    "\n",
    "print(\"8' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"8' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?8\\'?)'''\n",
    "eight_first,eight_mid,eight_na=three(care,pat)\n",
    "\n",
    "print(\"9' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"9' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?9\\'?)'''                            \n",
    "nine_first,nine_mid,nine_na=three(care,pat)\n",
    "\n",
    "print(\"10' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"10' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?10\\'?)'''                            \n",
    "ten_first,ten_mid,ten_na=three(care,pat)\n",
    "\n",
    "print(\"11' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"11' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?11\\'?)'''                            \n",
    "el_first,el_mid,el_na=three(care,pat)\n",
    "\n",
    "print(\"12' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"12' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?12\\'?)'''                            \n",
    "tw_first,tw_mid,tw_na=three(care,pat)\n",
    "\n",
    "print(\"13' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"13' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?1[3-9]\\'?)'''                            \n",
    "th_first,th_mid,th_na=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_mid#['m_name'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un(num_one,num_two,num_three,num_four):\n",
    "    pat=f'''(?i)((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})((?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)\\s?(?:{num_two}))?\\[^\\w\\]?x[^\\w]?(?:{num_three}((?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)\\s?(?:{num_four}))?)|()'''\n",
    "    print(pat)\n",
    "    \n",
    "un(2,'[0-6]',3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2x3\")\n",
    "#un(2,'[0-6]',3,2)\n",
    "eight_by_ten=x[x['value'].astype(str)==\"2' x 3'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9]|1[0-1])?[^\\w]?x[^\\w]?(?:{num_two})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:{num_two})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9]|1[0-1])?[^\\w]?x[^\\w]?(?:{num_two})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:{num_two})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)'''                            \n",
    "by_tt_first,by_tt_mid,by_tt_na=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_tt_mid['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_tt_mid[by_tt_mid['value'].astype(str)==\"3' x 5'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2x3\")\n",
    "# good\n",
    "eight_by_ten=x[x['value'].astype(str)==\"2' x 3'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:2)((?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:[0-6]))?\\s?x\\s?(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:18|24)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:36)(?:\\\\?\\s?\"|\".?inch)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:36)(?:\\\\?\\s?\"|\".?inch)?[^\\w]?x[^\\w]?(?:18|24)(?:\\\\?\"|\"|.?inch)?[^\\w])|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)2\\s?(?:\\'|\\\\?\")?\\s?x\\s?3\\s?(?:\\'|\\\\?\")?)'''                            \n",
    "by_tt_first,by_tt_mid,by_tt_na=three(care,pat)\n",
    "\n",
    "print(\"3x5\")\n",
    "#un(3,'[0-6]','[45]',6)\n",
    "eight_by_ten=x[x['value'].astype(str)==\"3' x 5'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?(?:\\s[0-6])?)?[^\\w]?x[^\\w]?(?:[45])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s?[0-6])?))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)3\\s?(?:\\'|\\\\?\")?\\s?x\\s?5\\s?(?:\\'|\\\\?\")?)|((?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:66)(?:\\\\?\\s?\"|\".?inch)?)|([^\\w](?:66)(?:\\\\?\\s?\"|\".?inch)?^\\w]?x[^\\w]?(?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w])'''                            \n",
    "by_tf_first,by_tf_mid,by_tf_na=three(care,pat)\n",
    "\n",
    "\n",
    "# print(\"7x9\")\n",
    "# #un('[7]','[6-9]|1[0-1]','9','[6-9]')\n",
    "# # un('[7]','[6-9]|1[0-1]','1[0-1]','0')\n",
    "# eight_by_ten=x[x['value'].astype(str)==\"8' x 10'\"]\n",
    "# pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[7])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9]|1[0-1])?[^\\w]?x[^\\w]?(?:9)(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[7])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9]|1[0-1])?[^\\w]?x[^\\w]?(?:1[0-1])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)'''                                \n",
    "# by_et_first,by_et_mid,by_et_na=three(care,pat)\n",
    "\n",
    "print(\"7x9\")\n",
    "#un('7','[0-6]','9','0')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"7' x 9'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)'''                            \n",
    "by_sn_first,by_sn_mid,by_sn_na=three(care,pat)\n",
    "\n",
    "print(\"8x10\")\n",
    "# un('[8]','0','1[0-1]','0')\n",
    "# un('[8]','0','9','[6-9]')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"8' x 10'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:1[0-1])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:9)(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)'''                                \n",
    "by_et_first,by_et_mid,by_et_na=three(care,pat)\n",
    "\n",
    "# print(\"5x7\")\n",
    "# # un(5,'[0-6]','7','6|9')\n",
    "# eight_by_ten=x[x['value'].astype(str)==\"5' x 8'\"]\n",
    "# pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6|9)?)'''                            \n",
    "# by_fe_first,by_two_mid,by_two_na=three(care,pat)\n",
    "\n",
    "print(\"5x7\")\n",
    "#un('5','[0-6]','7','0|10')\n",
    "# un('4','11','7','0|10')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"5' x 7'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)'''                            \n",
    "by_fs_first,by_fs_mid,by_fs_na=three(care,pat)\n",
    "\n",
    "\n",
    "print(\"5x8\")\n",
    "# un(5,'[0-6]','8','0')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"5' x 8'\"]\n",
    "pat='''((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)'''                            \n",
    "by_fe_first,by_two_mid,by_two_na=three(care,pat)\n",
    "\n",
    "print(\"4x6\")\n",
    "# un(4,'[0-6]','5|6','[6-9]')\n",
    "# un(3,'6','5','6')\n",
    "# un(3,'11','5','11|7')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"4' x 6'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:6)\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:[6-9|1[0-6]]))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11)(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11|7))'''                            \n",
    "by_fx_first,by_fx_mid,by_fx_na=three(care,pat)\n",
    "\n",
    "print(\"6x9\")\n",
    "# un(6,'[0-6]','9|8','0')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"6' x 9'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)'''                            \n",
    "by_xn_first,by_xn_mid,by_xn_na=three(care,pat)\n",
    "\n",
    "print(\"9x12\")\n",
    "# un('9','[0-6]','12|13','[0-5]')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"9' x 12'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)'''                            \n",
    "by_nt_first,by_nt_mid,by_nt_na=three(care,pat)\n",
    "\n",
    "print(\"10x14\")\n",
    "#un('10','[0-6]','14|13','[0-5]')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"10' x 14'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:10)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)'''                            \n",
    "by_tfou_first,by_tfou_mid,by_tfou_na=three(care,pat)\n",
    "\n",
    "print(\"12x15\")\n",
    "#un('12','[0-6]','15','[0-5]')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"12' x 15'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)'''                            \n",
    "by_twfif_first,by_twfif_mid,by_twfif_na=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_tfou_first['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_et_first[by_et_first['value'].astype(str)==\"3' x 5'\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round/Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roun(num_one,num_two):\n",
    "    pat=f'''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})\\s?\\'?[^\\w]?x[^\\w]?(?:{num_one})\\s?\\'?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})\\s?\\'?\\s?(?:{num_two})?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})\\s?\\'?\\s?{num_two}[^\\w]?x[^\\w]?(?:{num_one})\\s?'?\\s?{num_two})|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})\\s?'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'(?:{num_one})'')|(SKU_SIZE[^\\w]{0,4}(?:{num_one})\\s?\\'?(?:{num_two})?\"?\\s?(?:round|square)'''       \n",
    "    print(pat)\n",
    "    \n",
    "roun(8,'[0-7]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('three')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"3' Round/Square\"]\n",
    "pat='''(?i)((?<!\\d)(?:3)\\'?[^\\w]?x[^\\w]?(?:3)\\'?)|((?:3)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)3'?\\s?[0-7][^\\w]?x[^\\w]?3'?\\s?[0-7])|(3'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'3'')|()'''                            \n",
    "three_round,na_three=three(eight_by_ten,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('three')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"3' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?[^\\w]?x[^\\w]?(?:3)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:3)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:3)'')|(SKU_SIZE[^\\w](0, 4)(?:3)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "three_round_first,three_round_mid,na_three=three(care,pat)\n",
    "\n",
    "print('four')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"4' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?[^\\w]?x[^\\w]?(?:4)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:4)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:4)'')|(SKU_SIZE[^\\w](0, 4)(?:4)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "four_round,four_round_mid,na_four=three(care,pat)\n",
    "\n",
    "print('five')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"5' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?[^\\w]?x[^\\w]?(?:5)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:5)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:5)'')|(SKU_SIZE[^\\w](0, 4)(?:5)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "five_round,five_round_mid,na_five=three(care,pat)\n",
    "\n",
    "print('six')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"6' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?[^\\w]?x[^\\w]?(?:6)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:6)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:6)'')|(SKU_SIZE[^\\w](0, 4)(?:6)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "six_round,six_round_mid,na_six=three(care,pat)\n",
    "\n",
    "print('seven')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"7' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?[^\\w]?x[^\\w]?(?:7)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:7)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:7)'')|(SKU_SIZE[^\\w](0, 4)(?:7)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "seven_round,seven_round_mid,na_seven=three(care,pat)\n",
    "\n",
    "print('eight')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"8' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?[^\\w]?x[^\\w]?(?:8)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:8)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:8)'')|(SKU_SIZE[^\\w](0, 4)(?:8)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "eight_round,eight_round_mid,na_eight=three(care,pat)\n",
    "\n",
    "print('nine')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"9' Round/Square\"]\n",
    "pat='''((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'9'')'''                            \n",
    "nine_round,nine_round_mid,na_nine=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin=df[df['attribute'].astype(str)=='origin']\n",
    "print(len(origin))\n",
    "origin['curated_date']=pd.to_datetime(origin['curated_date'])\n",
    "no=origin[(origin['curated_date']>='11-01-2022')&(origin['curated_date']<='11-30-2022')]\n",
    "nov=no[no['resolution'].astype(str)=='standard']\n",
    "print(len(nov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(n\\/a)|()''' \n",
    "nov['values']=nov['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "mach=nov[nov['values'].astype(str)!='[]']\n",
    "print(len(mach))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=three(mach,'''(\\b(?:united.?states|united.?states.?of.?america|USA(?!.glass)(?!opoly)|AMerica|made.?in.?(?:us|u\\.s\\.))\\b)|(imported)|(made.?in.?(?:canada|turkey|china|france|india|germany|italy|the.?uk|poland|malaysia|belgium|vienna|pakistan))|(.{0,10}(?<!hand.)(?<!hand)made(?!.for)(?!.out)(?!.by)(?!.of)(?!.with)(?!.from).{0,10})|(.{0,10}\\busa(?!.glass)\\b.{0,10})''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=nov[nov['value'].astype(str)=='Imported']\n",
    "print(len(imp))\n",
    "na=nov[nov['value'].astype(str)=='n/a']\n",
    "print(len(na))\n",
    "usa=nov[nov['value'].astype(str)=='Made in the USA']\n",
    "print(len(usa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nov['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip=r'''(?i)(imported)|(made in Canada)|(euro.?sham)|(made.?in)|()''' \n",
    "trip=r'''(?i)(\\b(?:united.?states|united.?states.?of.?america|USA(?!.glass)(?!opoly)|AMerica|made.?in.?(?:us|u\\.s\\.))\\b)|(imported)|(made.?in.?(?:canada|turkey|china|france|india|germany|italy|the.?uk|poland|malaysia|belgium|vienna|pakistan))|(.{0,10}(?<!hand.)(?<!hand)made(?!.for)(?!.out)(?!.by)(?!.of)(?!.with)(?!.from).{0,10})|(.{0,10}\\busa(?!.glass)\\b.{0,10})|()''' \n",
    "usa['m_name']=usa['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "usa['m_desc']=usa['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "usa['m_custom']=usa['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "imported=usa[(usa['m_name'].astype(str)!='[]')|(usa['m_desc'].astype(str)!='[]')|(usa['m_custom'].astype(str)!='[]')]\n",
    "print(len(imported))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported#[['external_id','m_name','m_desc','m_custom']][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impor=na[(na['m_name'].astype(str)=='[]')&(na['m_desc'].astype(str)=='[]')&(na['m_custom'].astype(str)=='[]')]\n",
    "print(len(impor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impor['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trip=r'''(?i)((.{0,10}(?<!hand.)(?<!hand)made(?!.for)(?!.out)(?!.by)(?!.of)(?!.with)(?!.from).{0,10})|(.{0,10}\\busa(?!.glass)\\b.{0,10}))|()''' \n",
    "impor['m_name']=impor['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print('one')\n",
    "impor['m_desc']=impor['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print('two')\n",
    "impor['m_custom']=impor['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print('three')\n",
    "im=impor[(impor['m_name'].astype(str)!='[]')|(impor['m_desc'].astype(str)!='[]')|(impor['m_custom'].astype(str)!='[]')]\n",
    "print(len(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(im))\n",
    "im[['external_id','m_name','m_desc','m_custom']][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported['Q:origin']=''\n",
    "match_na_re_curates=imported[['external_id','Q:origin']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_na_re_curates.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_na_re_curates) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na=dfs[(dfs['attribute'].astype(str)=='nan')|(dfs['attribute'].astype(str)=='None')]\n",
    "print(len(na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2022-08-11'\n",
    "attribut='size'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print('continuing')\n",
    "dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "print('dfs')\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "print('customs')\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "df=pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material=df[['attribute','buckets','value','external_id','product_name','long_desc','LONG_DESCRIPTION','gbi_exp_product_type','gbi_syn_product_type','gbi_syn_size','gbi_product_type_affinity','Fill_Material','s_f_Fill_Material','s_f_binFill_Material']]\n",
    "print(len(material))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=\"(?i)(duvet)|()\"\n",
    "material['d']=material['gbi_exp_product_type'].apply(lambda x: re_extract(trips,str(x)))\n",
    "material['u']=material['gbi_syn_product_type'].apply(lambda x: re_extract(trips,str(x)))\n",
    "material['v']=material['gbi_syn_size'].apply(lambda x: re_extract(trips,str(x)))\n",
    "material['match']=material['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "material['matches']=material['LONG_DESCRIPTION'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "\n",
    "duvet=material[(material['d'].astype(str)!='[]')|(material['u'].astype(str)!='[]')|(material['v'].astype(str)!='[]')|(material['match'].astype(str)!='[]')|(material['matches'].astype(str)!='[]')]\n",
    "print(len(duvet))\n",
    "print(duvet['buckets'].explode().value_counts().reset_index()['index'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del duvet['d']\n",
    "del duvet['u']\n",
    "del duvet['v']\n",
    "# del duvet['e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill=duvet[(duvet['external_id'].astype(str)!='nan')&((duvet['Fill_Material'].astype(str)!='nan')|(duvet['s_f_Fill_Material'].astype(str)!='nan')|(duvet['s_f_binFill_Material'].astype(str)!='nan'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=\"(?i)(.{0,10}fill.?material.{0,10})|()\"\n",
    "duvet['fill']=duvet['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "duvet['fills']=duvet['LONG_DESCRIPTION'].apply(lambda x: re_extract(trips,str(x)))\n",
    "x=duvet[(duvet['fill'].astype(str)!='[]')|(duvet['fills'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=\"(?i)(.{0,10}(?:duvet).{0,10})|()\"\n",
    "mat['match']=mat['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "mat['matches']=mat['product_name'].apply(lambda x: re_extract(trips,str(x)))\n",
    "duvet=mat[(mat['match'].astype(str)!='[]')|(mat['matches'].astype(str)!='[]')]\n",
    "duvet=duvet[duvet['value'].astype(str)=='n/a']\n",
    "print(len(duvet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duvet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_id = '5'\n",
    "# customer_name='%bedbathandbeyond%'\n",
    "# dateszs='2022-08-11'\n",
    "# params = {'customer_id': customer_id,\n",
    "#           'customer_name':customer_name,\n",
    "#          'dateszs':dateszs}\n",
    "# print('start')\n",
    "# dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "# print('continuing')\n",
    "# dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "# print('dfs')\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# print('customs')\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# # dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# # custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# # fields = ['Set_Size']\n",
    "# # df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# # print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=\"(?i)(.{0,10}(?:comforter|duvet|sheets).{0,10})|()\"\n",
    "df['match']=df['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "df['matches']=df['product_name'].apply(lambda x: re_extract(trips,str(x)))\n",
    "duvet=df[(df['match'].astype(str)!='[]')|(df['matches'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(duvet))\n",
    "duvet_na=duvet[duvet['value'].astype(str)=='n/a']\n",
    "print(len(duvet_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=duvet_na[(duvet_na['Fill_Material'].astype(str)!='nan')|(duvet_na['s_f_Fill_Material'].astype(str)!='nan')|(duvet_na['s_f_binFill_Material'].astype(str)!='nan')|(duvet_na['s_f_binMaterial'].astype(str)!='nan')]\n",
    "print(len(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Fill_Material','s_f_Fill_Material','s_f_binFill_Material','s_f_binMaterial']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill=df[(df['Fill_Material'].astype(str)!='nan')&(df['s_f_Fill_Material'].astype(str)=='nan')&(df['s_f_binFill_Material'].astype(str)=='nan')&(df['s_f_binMaterial'].astype(str)=='nan')]\n",
    "print(len(fill))\n",
    "\n",
    "fills=df[(df['Fill_Material'].astype(str)=='nan')&(df['s_f_Fill_Material'].astype(str)!='nan')&(df['s_f_binFill_Material'].astype(str)=='nan')&(df['s_f_binMaterial'].astype(str)=='nan')]\n",
    "print(len(fills))\n",
    "\n",
    "fillz=df[(df['Fill_Material'].astype(str)=='nan')&(df['s_f_Fill_Material'].astype(str)=='nan')&(df['s_f_binFill_Material'].astype(str)!='nan')&(df['s_f_binMaterial'].astype(str)=='nan')]\n",
    "print(len(fillz))\n",
    "\n",
    "filling=df[(df['Fill_Material'].astype(str)=='nan')&(df['s_f_Fill_Material'].astype(str)=='nan')&(df['s_f_binFill_Material'].astype(str)=='nan')&(df['s_f_binMaterial'].astype(str)!='nan')]\n",
    "print(len(filling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillings=df[((df['Fill_Material'].astype(str)!='nan')|(df['s_f_Fill_Material'].astype(str)!='nan')|(df['s_f_binFill_Material'].astype(str)!='nan'))&(df['s_f_binMaterial'].astype(str)=='nan')&(df['external_id'].astype(str)!='nan')]\n",
    "# print(len(fillings))\n",
    "# fillings\n",
    "# filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filling['buckets'].explode().value_counts()\n",
    "x=filling[filling['buckets'].astype(str)!='nan']\n",
    "print(len(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(.{0,20}duvet.{0,20})|(.{0,20}fill.{0,20})|()'''                                                              \n",
    "fill['matches']=fill['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "duvet=fill[fill['matches'].astype(str)!='[]']\n",
    "duvet#[duvet['s_f_binMaterial'].astype(str)=='''['Cotton Blend']''']\n",
    "print(len(duvet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duvet[duvet['value'].astype(str)=='n/a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_material=df[(df['attribute'].astype(str)=='fill_material')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_materials=fill_material[(fill_material['Fill_Material'].astype(str)!='nan')|(fill_material['s_f_Fill_Material'].astype(str)!='nan')|(fill_material['s_f_binFill_Material'].astype(str)!='nan')|(fill_material['s_f_binMaterial'].astype(str)!='nan')|(fill_material['Fill_Material'].astype(str)!='nan')]\n",
    "# del fill_materials ['buckets']\n",
    "# del fill_materials ['bucket_id']\n",
    "del fill_materials ['customer_name']\n",
    "del fill_materials ['curated_date']\n",
    "del fill_materials ['resolution']\n",
    "del fill_materials ['curation_tasks.curated_by']\n",
    "\n",
    "fill_materials#['value'].explode().value_counts()\n",
    "\n",
    "trip=r'''(?i)(duvet)|()'''                                                              \n",
    "fill_materials['matches']=fill_materials['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "duvet=fill_materials[fill_materials['matches'].astype(str)!='[]']\n",
    "duvet#[duvet['s_f_binMaterial'].astype(str)=='''['Cotton Blend']''']\n",
    "\n",
    "duvets=duvet[(duvet['s_f_binMaterial'].astype(str)!='nan')&(duvet['s_f_binMaterial'].astype(str)!=\"['Other']\")&(duvet['s_f_binMaterial'].astype(str)!=\"['Modal']\")&(duvet['s_f_binMaterial'].astype(str)!=\"['Cotton Blend']\")]\n",
    "duvets['Q:fill_material']=duvets['s_f_binMaterial']\n",
    "\n",
    "match_duvets=duvets[['external_id','Q:fill_material']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_duvets.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_duvets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs['attribute'].explode().value_counts()\n",
    "# dfs[(dfs['attribute'].astype(str)!='keywords')&(dfs['attribute'].astype(str)!='metal_finish')&(dfs['attribute'].astype(str)!='material')&(dfs['attribute'].astype(str)!='features')&(dfs['attribute'].astype(str)!='occasion')&(dfs['attribute'].astype(str)!='set_size')&(dfs['attribute'].astype(str)!='origin')&(dfs['attribute'].astype(str)!='care')&(dfs['attribute'].astype(str)!='personalization_type')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs['attribute'].astype(str)=='personalization_type']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[(dfs['attribute'].astype(str)=='personalization_type')&(dfs['value'].astype(str)=='n/a')]#['value'].explode().value_counts()\n",
    "# dfs[(dfs['attribute'].astype(str)=='origin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attribute'].explode().value_counts()[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '16'\n",
    "customer_name='%cb2%'\n",
    "dateszs='2022-07-01'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfs=dfs[dfs['resolution'].astype(str)!='rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIFMA Certified\n",
    "FSC® Certified\n",
    "Organic\n",
    "STANDARD 100 by OEKO-TEX® Certified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[(dfs['attribute'].astype(str)=='bed_size')&(dfs['value'].astype(str)=='Art')]#['product_name'].explode().value_counts()[0:500]\n",
    "dfs[(dfs['attribute'].astype(str)=='bed_size')]['value'].explode().value_counts()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_size=cb2[(cb2['attribute'].astype(str)=='set_size')]\n",
    "print(len(set_size))\n",
    "\n",
    "trip=r'''(?i)(set.?of)|()'''                                                              \n",
    "set_size['match']=set_size['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "set_size['matches']=set_size['name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "set_size[(set_size['value'].astype(str)!='Set of 2')&(set_size['value'].astype(str)!='Set of 4')&((set_size['match'].astype(str)!='[]')|(set_size['matches'].astype(str)!='[]'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stool=cb2[(cb2['attribute'].astype(str)=='product_type')&(cb2['buckets'].astype(str)=='Stools')]\n",
    "# print(len(stool))\n",
    "# trip=r'''(?i)(counter.?stool)|(sized.?for.?counters)|(counter.?height)|()'''                                                              \n",
    "# stool['match']=stool['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# stool['matches']=stool['name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# counter=stool[(stool['value'].astype(str)!='Counter Stools')&((stool['match'].astype(str)!='[]')|(stool['matches'].astype(str)!='[]'))]\n",
    "# print(len(counter))\n",
    "# counter['Q:product_type']='Counter Stools'\n",
    "# match_counter=counter[['external_id','Q:product_type']]\n",
    "# counter\n",
    "\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/CB2 --{get_df_name(matches)}-match_counter.csv',index=False) \n",
    "# looks_good('CB2',match_counter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 179046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb2['external_id'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=cb2['attribute'].explode().value_counts().reset_index()['index'].to_list()\n",
    "lst.sort()\n",
    "cb2['value']=cb2['value'].apply(lambda x: re.sub(r\"'\\, '\",'\",\"',str(x))).apply(lambda x: re.sub(r'\"\\,\"',',,',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb2[cb2['attribute'].astype(str)=='air_filter_capability']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(lst)):\n",
    "#     antena=cb2[cb2['attribute'].astype(str)==f'{lst[i]}']\n",
    "#     print('')\n",
    "#     print('###################################################')\n",
    "#     print(lst[i])\n",
    "# #     print(antena['value'].explode().value_counts())#.reset_index()['index'].to_list()\n",
    "#     antena['match']=antena['value'].apply(lambda x: re.sub(r'\\[|\\]|\\\\|\"','',str(x)))\n",
    "#     # antena['match'].explode().value_counts()\n",
    "#     print(antena['match'].str.get_dummies(',,').sum().reset_index()['index'].to_list())\n",
    "#     print('###################################################')\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm=cb2\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tilde umlaut diacritical mark (accent mark)\n",
    "# .title()\n",
    "# # Get rid of 's\n",
    "# Ignore \\. between names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbm[wbm['attribute'].astype(str)=='designer']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slate_design=wbm[(wbm['value'].astype(str)=='Slate Design')] # This is different?\n",
    "print(len(slate_design))\n",
    "# slate_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amanda=wbm[(wbm['value'].astype(str)=='Amanda Ip')|(wbm['value'].astype(str)=='Amanda Ip of Slate Design')|(wbm['value'].astype(str)=='Amanda Ip of Slate Design.')]\n",
    "print(len(amanda))\n",
    "# Amanda Ip of (left out: Slate Design ) (123439)  # include everything to Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aurele=wbm[(wbm['value'].astype(str)=='Aurèle Sack')|(wbm['value'].astype(str)=='Aurele Sack')] #different callouts (622789, 112285) # \n",
    "print(len(Aurele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bryn=wbm[(wbm['value'].astype(str)=='Brynn Namavari')|(wbm['value'].astype(str)=='Bryn Namavari')|(wbm['value'].astype(str)=='Bryn E. Namavari')] # normalize: Bryn Namavari\n",
    "# Bryn['external_id'].explode().value_counts()\n",
    "# print(len(Bryn))\n",
    "# Bryn['value'].explode().value_counts()\n",
    "\n",
    "trip=r'''(?i)(designed by Bryn Namavari)|()'''                                                              \n",
    "wbm['match']=wbm['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print(len(wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]))\n",
    "bryns=wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]\n",
    "bryns['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "# Different callouts--> Bryn Namavari(620391)\n",
    "# Different Callouts--> Brynn Namavari(488756)\n",
    "# Different Callouts--> Bryn E. Namavari(641981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candice_kaye=wbm[(wbm['value'].astype(str)=='Candice Kaye')|(wbm['value'].astype(str)=='Candice Kaye Design')] # Different callouts (195374, 454577)\n",
    "candice_kaye['value'].explode().value_counts()\n",
    "print(len(candice_kaye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slate=wbm[(wbm['value'].astype(str)=='Diana Lu of Slate Design')|(wbm['value'].astype(str)=='Diana Lu')]  # Slate Design\n",
    "# print(len(slate))\n",
    "# slate['external_id'].explode().value_counts()\n",
    "\n",
    "trip=r'''(Diana Lu)|()'''                                                              \n",
    "wbm['match']=wbm['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print(len(wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]))\n",
    "estudio=wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]\n",
    "estudio['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "# Calls out Slate Design but its ambigious for cuators I guess: Diana Lu of Slate Design (493886, 378482)\n",
    "# slate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estudiobola=wbm[(wbm['value'].astype(str)=='estudiobola')|(wbm['value'].astype(str)=='Estudiobola')|(wbm['value'].astype(str)=='Estudio Bola')] \n",
    "# estudiobola['value'].explode().value_counts()\n",
    "\n",
    "trip=r'''(estudiobola)|()'''                                                              \n",
    "wbm['match']=wbm['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print(len(wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]))\n",
    "estudio=wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]\n",
    "estudio['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "\n",
    "# print(len(estudiobola))\n",
    "# Different call outs--> estudiobola (351841, 317515) its callout lower case\n",
    "# Estudio Bola (652581, 612143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found=wbm[(wbm['value'].astype(str)=='Found My Animal')] # This is good (202763) #Designed by Found My Animal\n",
    "found['external_id'].explode().value_counts()\n",
    "# print(len(found))\n",
    "# found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goop=wbm[(wbm['value'].astype(str)=='goop')|(wbm['value'].astype(str)=='Goop')] #Goop (672957) goop(592866) # Normalize in .title() format\n",
    "goop['value'].explode().value_counts()\n",
    "print(len(goop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tullmann=wbm[(wbm['value'].astype(str)=='Hettler Tulllman')|(wbm['value'].astype(str)=='Hettler Tullmann')|(wbm['value'].astype(str)=='Hettler.Tullmann')|(wbm['value'].astype(str)=='Hettler.Tüllmann')] \n",
    "Tullmann['value'].explode().value_counts()\n",
    "print(len(Tullmann))\n",
    "# Mispelled Tullmann in description (124485)\n",
    "# Period in between name(423225, 196052)\n",
    "# Umlot(435054)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heras=wbm[(wbm['value'].astype(str)=='House of Haras')|(wbm['value'].astype(str)=='House of Heras')] # Mispelled Heras(219229)\n",
    "Heras['value'].explode().value_counts()\n",
    "print(len(Heras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Robertson=wbm[(wbm['value'].astype(str)=='Isabelle Grizzard')|(wbm['value'].astype(str)=='Isabelle Grizzard Robertson')] \n",
    "# Robertson['value'].explode().value_counts()\n",
    "print(len(Robertson))\n",
    "\n",
    "trip=r'''(Isabelle Grizzard Robertson)|()'''                                                              \n",
    "wbm['match']=wbm['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print(len(wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]))\n",
    "kitchen=wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]\n",
    "kitchen['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "# Robertson in description but looked it up and should be the same thing Robertson(578183, 356150) Without (361303, 361263)\n",
    "# Robertson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kitchen=wbm[(wbm['value'].astype(str)=='Jennifer Fisher')|(wbm['value'].astype(str)=='Jennifer Fisher Kitchen')] # Calls out Jennifer Fisher Kitchen in description (550613,550644,550636)\n",
    "# kitchen['external_id'].explode().value_counts()\n",
    "\n",
    "trip=r'''(?i)(Jennifer Fisher kitchen)|()'''                                                              \n",
    "wbm['match']=wbm['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print(len(wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]))\n",
    "kitchen=wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]\n",
    "kitchen['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "\n",
    "# print(len(kitchen))\n",
    "# kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jordi=wbm[(wbm['value'].astype(str)=='Jordi Kutarq')|(wbm['value'].astype(str)=='Kutarq Studio')] # I looked it up online and it mentions Jordi (657120)\n",
    "jordi['external_id'].explode().value_counts()\n",
    "# print(len(jordi))\n",
    "# jordi\n",
    "# Still waiting on confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "julie=wbm[(wbm['value'].astype(str)=='Julia Von Werz')|(wbm['value'].astype(str)=='Julia von Werz')|(wbm['value'].astype(str)=='Julie von Werz')] # Dont know where julie came from (247835, 247828)\n",
    "julie['value'].explode().value_counts()\n",
    "# print(len(julie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenny=wbm[(wbm['value'].astype(str)=='Lenny Kravitz')|(wbm['value'].astype(str)=='Kravitz Design')] # Lenny Kravitz is called out in multiple SKUs for Kravitz design (509274, 513491, 561873, 509238)\n",
    "lenny['value'].explode().value_counts()\n",
    "# print(len(lenny))\n",
    "# lenny\n",
    "# Still waiting on confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leohnhard=wbm[(wbm['value'].astype(str)=='Leohnhard Pfeifer')|(wbm['value'].astype(str)=='Leonhard Pfeifer')] # this is called out 322535-->Leohnhard\n",
    "# Leohnhard['external_id'].explode().value_counts()\n",
    "\n",
    "# trip=r'''(estudiobola)|()'''                                                              \n",
    "# wbm['match']=wbm['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# print(len(wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]))\n",
    "# estudio=wbm[(wbm['match'].astype(str)!='[]')&(wbm['attribute'].astype(str)=='designer')]\n",
    "# estudio['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "\n",
    "# print(len(Leohnhard))\n",
    "# Leohnhard\n",
    "# Still waiting on confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mash=wbm[wbm['value'].astype(str)=='MASHstudios'] #looks good\n",
    "mash['value'].explode().value_counts()\n",
    "# print(len(mash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu=wbm[wbm['value'].astype(str)=='MENU'] #looksgood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veers=wbm[(wbm['value'].astype(str)=='Matthew Williamson')|(wbm['value'].astype(str)==\"Matthew Williamson veers\")] # verrs in a direction (drop this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mermelda_mexa=wbm[(wbm['value'].astype(str)=='Mermelada Estudio')|(wbm['value'].astype(str)==\"Mermelada Estudio and Mexa Design\")|(wbm['value'].astype(str)==\"Mexa Design\")]\n",
    "mermelda_mexa=wbm[(wbm['value'].astype(str)==\"Mermelada Estudio\")]\n",
    "mermelda_mexa['external_id'].explode().value_counts()[0:40]\n",
    "# print(len(mermelda_mexa))\n",
    "\n",
    "# Mermelada Estudio (639968)\n",
    "# Mexa Design (505553)\n",
    "# Mermelada Estudio and Mexa Design (532054)\n",
    "# I dont think these two companies are the same \n",
    "# mermelda_mexa\n",
    "\n",
    "# Still waiting on confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicholas=wbm[(wbm['value'].astype(str)=='Nicholas Obeid')|(wbm['value'].astype(str)==\"Nicolas Obeid\")] # Mispelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noel=wbm[(wbm['value'].astype(str)=='Noel Ashby')|(wbm['value'].astype(str)==\"Noël Ashby\")] # leave off umlots (ë)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patrick=wbm[(wbm['value'].astype(str)=='PATRICK ST. GERMAIN')|(wbm['value'].astype(str)==\"Patrick St. Germain\")] # leave values as lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mccob=wbm[(wbm['value'].astype(str)=='Paul McCobb')|(wbm['value'].astype(str)==\"Paul McCobb's\")] # Get rid of 's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produck=wbm[wbm['value'].astype(str)=='Producks Design Ltd'] #leave as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tae=wbm[(wbm['value'].astype(str)=='Taeyoung Choi')|(wbm['value'].astype(str)=='SAIC student Taeyoung Choi')] # Normalize these two values\n",
    "tae['value'].explode().value_counts()\n",
    "# print(len(tae))\n",
    "# tae\n",
    "# Still waiting on confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "von=wbm[(wbm['value'].astype(str)=='Sarah Von Dreele')|(wbm['value'].astype(str)=='Sarah von Dreele')] # Capitalize every letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sasha=wbm[(wbm['value'].astype(str)=='Sasha Adle')|(wbm['value'].astype(str)=='Sasha Adler')] # Mispelling\n",
    "# sasha['Q:designer']='[\"Sasha Adler\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celi=wbm[(wbm['value'].astype(str)=='Ceci Thompson')|(wbm['value'].astype(str)=='Vuue Pty Ltd')|(wbm['value'].astype(str)=='VUUE, Ceci Thompson')|(wbm['value'].astype(str)=='VUUE')] # Combine these values\n",
    "# celi['Q:designer']='[\"Ceci Thompson\",\"VUUE\"]'\n",
    "# match_celi=celi[['external_id','Q:designer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fferrone=wbm[wbm['value'].astype(str)=='fferrone design'] # This just looks like fferrone --> lowercase??????????????????\n",
    "fferrone['value'].explode().value_counts()\n",
    "# fferrone\n",
    "# Still waiting on confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv=wbm[wbm['value'].astype(str)=='ivdesign.it'] # is this IVdesign.it?IVdesign or ivdesign.it??????????????????\n",
    "iv['value'].explode().value_counts()\n",
    "# iv\n",
    "# iv\n",
    "# Still waiting on confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbm=cb2[cb2['attribute'].astype(str)=='designer']\n",
    "# wbm['match']=wbm['value'].apply(lambda x: re.sub(r'\"\\,\"',',,',str(x))).apply(lambda x: re.sub(r'\\[|\\]|\\\\|\"','',str(x)))\n",
    "# wbm['match'].str.get_dummies(',,').sum().reset_index()['index'].to_list()\n",
    "# # cb2[cb2['attribute'].astype(str)=='designer']['value'].explode().value_counts()\n",
    "# # cb2['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb2[cb2['attribute'].astype(str)=='light_filtration']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb2[cb2['attribute'].astype(str)=='light_filtration']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lights=pd.read_csv('crate_light_filtration.csv')\n",
    "lights=lights[lights['SKU'].astype(str)!='nan']\n",
    "lights['SKU']=lights['SKU'].apply(lambda x: int(x))\n",
    "lights['Q:light_filtration']=lights['LIGHT FILTERING LEVEL'].apply(lambda x: re.sub(r'SHEER','Sheer',str(x))).apply(lambda x: re.sub(r'LIGHT FILTERING','Light Filtering',str(x))).apply(lambda x: re.sub(r'ROOM DARKENING','Room Darkening',str(x))).apply(lambda x: re.sub(r'BLACKOUT','Blackout',str(x)))\n",
    "lights['Q:light_filtration'].explode().value_counts()\n",
    "# lights[lights['SKU'].astype(str)=='445692']\n",
    "# lights['SKU'].explode().value_counts()\n",
    "lights['external_id']=lights['SKU']\n",
    "match_lights=lights[['external_id','Q:light_filtration']]\n",
    "match_lights\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/CB2 --{get_df_name(matches)}-match_light.csv',index=False) \n",
    "looks_good('CB2',match_lights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BJs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '66'\n",
    "customer_name='%bjs%'\n",
    "\n",
    "dateszs='2022-07-01'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[(dfs['attribute'].astype(str)=='concern')&(dfs['value'].astype(str)=='[\"Cruelty Free\",\"Sulfate Free\",\"Vegan\",\"Vegetarian\"]')]\n",
    "# dfs[(dfs['attribute'].astype(str)=='concern')]['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['attribute'].explode().value_counts()[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm=bj\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()\n",
    "# width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "# depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "# height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['attribute'].astype(str)=='concern']['value'].explode().value_counts()\n",
    "# # df[(df['attribute'].astype(str)=='seat_count')&(df['value'].astype(str)=='10-Seat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Container Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# container store\n",
    "customer_id = '77'\n",
    "customer_name='%containerstore%'\n",
    "dateszs='2001-07-01'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['Product_ID']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia=df[df['attribute'].astype(str)=='product_type_cs']#['value'].explode().value_counts()\n",
    "print(len(dia))\n",
    "# dia[dia['value'].astype(str)=='Water Bottle']\n",
    "lst=dia['value'].explode().value_counts().reset_index()['index'].to_list()\n",
    "lst.sort()\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia=df[df['attribute'].astype(str)=='features']\n",
    "print(len(dia))\n",
    "dia[dia['value'].astype(str)=='Paintable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[(dfs['attribute'].astype(str)=='tier_count')&(dfs['value'].astype(str)!='n/a')]#['product_name'].explode().value_counts()\n",
    "# df[(df['attribute'].astype(str)=='height')]['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm=container\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()\n",
    "# width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "# depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "# height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt=df[df['attribute']=='product_type_cs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pt))\n",
    "na=pt[pt['value'].astype(str)=='n/a']\n",
    "patz=\"(?i)(Battery Storage)|(felt pads)|(casters)|(travel towels)|(wrapping.?paper)|(weekend.{0,7}bag)|(water.?bottle)|(waste.?basket)|(washing.?access)|(wall.?organizer)|(wall.?mounted.?shelv)|(wall.?mounted.?hook)|(ventilated.?shelving)|(vacuum.?bag)|(umbrella.?stand)|(travel.?bottle)|(travel.?access)|(trash.?can)|(commercial.?can)|(trash.?bag(?:.{0,4}access)?)|(track.{0,4}standard)|(\\btools?\\b)|(tool.?oranization)|(toiletry.?organizer)|(toilet.?plunger)|(toilet.?brush)|(tissue.{0,4}filler)|(tissue.?boxes)|(\\btins?\\b)|(tiered.?organizer)|(tables)|(surface.?protection)|(storage.?tot)|(storage.?bag)|(sticky.?note.{0,4}tab)|(step.?stool)|(stemware.?cup.?storage)|(steamers)|(sport.{0,3}storage)|(spice.?rack)|(spice.?organizer)|(specialty.?storage)|(solid.shelving)|(soap.?dispens)|(sink.?organiz)|(shower.{0,4}tub.?access)|(shoe.?rack)|(shelving.?unit)|(shelving(?!.unit))|(shelves)|(shelf.{0,4}rod.?organizer)|(shelf.?liner)|(seating)|(riser.{0,4}easel)|(ribbon.{0,4}bow)|(reusable.?bag)|(recycling)|(power.?strip.{0,4}charger)|(pitcher.{0,4}carafe)|(pill.?box)|(photo.{0,3}archival.?storage)|(pet.?food.?storage)|(pest.?protection)|(\\bmarkers\\b)|(\\bpencils?\\b)|(pencil.?cup)|(\\bpens?\\b)|(pegboard)|(paper.?towel.?holder)|(paper.?clip)|(over.?the.?door.?rack)|(over.?the.?door.?hook)|(notepad)|(notebook)|(\\bmops?\\b)|(monitor.?stand)|(mirror)|(message.?board)|(Chalkboards)|(Cork Boards)|(Dry Erase Boards)|(Foam Bulletin Boards)|(Fabric Boards)|(makeup.?organizer)|(magnetic.?strip)|(magnetic.?board)|(luggage.?accessori)|(luggage)|(lazy.?susan)|(laundry.?hamper)|(laundry.?basket)|(laundry.?bag)|(laptop.?bag)|(ladders?)|(\\blabels?\\b)|(knife.?storage)|(kitchen.?utensil)|(kitchen.?gadget)|(\\bjars?\\b)|(\\birons?\\b)|(ironing.?board)|(household.?cleaner)|(\\bhooks?\\b)|(hardware)|(gift.?wrap.?organiz)|(gift.?wrap access)|(gift.?tag)|(money.?holder)|(gift.?card)|(gift.?box)|(gift.?bag)|(wardrobe)|(garment.?rack)|(detergent)|(garment.?care)|(garment.?bag)|(furniture)|(freezer.?organizer)|(fridge.?organizer)|(free.?standing.?shelving)|(food.?storage)|(food.?safe.?container)|(filing.?cabinet)|(file.?folder)|(fabric.?care)|(pouches)|(envelope)|(drying.?rack)|(drying.?accessor)|(drawers)|(drawer.?organizer)|(drawer.?liner)|(wall.?rack)|(door.?rack)|(\\btray)|(doormat)|(drainer)|(dish.?rack)|(dish.?brush)|(desk top)|(desk\\b)|(desk.?organizer)|(desk leg)|(deodorizer)|(dehumidifier)|(decorative.?tap)|(countertop.?organizer)|(tea.?storage)|(coffee.?stroage)|(cleaning.?gadget)|(chair)|(cart)|(car.?organizer)|(canister)|(cabinet.?organizer)|(dustpan)|(brooms)|(\\bmops?\\b)|(boxes)|(\\bbin)|(bench)|(basket)|(backpack)|(anti.?theft.?bag)|(Adhesive.?hook)|(Accessory.?storage)|()\"                  \n",
    "na['match']=na['name'].apply(lambda x: re_extract(patz, str(x)))\n",
    "na['matches']=na['long_desc'].apply(lambda x: re_extract(patz, str(x)))\n",
    "print(len(na))\n",
    "prods=na[(na['match'].astype(str)!='[]')]\n",
    "print(len(prods))\n",
    "# prods[0:500]\n",
    "# prods['Q:product_type_cs']=''\n",
    "# match_prod=prods[['external_id','Q:product_type_cs']]\n",
    "# # prods['matches'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks=na[(na['match'].astype(str)=='[]')&(na['matches'].astype(str)!='[]')]\n",
    "blanks['Q:product_type_cs']=''\n",
    "match_blanks=blanks[['external_id','Q:product_type_cs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prods['matchez']=prods['match'].apply(lambda x: str(x).title()).apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'\\s?\"\\s?','\"',str(x))).apply(lambda x: re.sub(r'(?i)wall.?rack','Door & Wall Racks',str(x)))\n",
    "# prods['matchez']=prods['matchez'].apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r'Gift.?Wrap.?Organize?r?','Gift Wrap Organizers',str(x))).apply(lambda x: re.sub(r'Sink Organiz','Sink Organizer',str(x)))\n",
    "# prods['matchez']=prods['matchez'].apply(lambda x: re.sub(r'Soap.?Dispens','Soap Dispensers',str(x))).apply(lambda x: re.sub(r'Wrapping.?Paper','Wrapping Paper',str(x))).apply(lambda x: re.sub(r'Gift.?Box','Gift Boxes',str(x)))\n",
    "# prods['matchez']=prods['matchez'].apply(lambda x:re.sub(r'Paper.?Clip','Paper Clips',str(x))).apply(lambda x: re.sub(r'Pencil Cup','Pens, Pencils & Markers',str(x))).apply(lambda x: re.sub(r'Commercial Can','Trash Can',str(x)))\n",
    "\n",
    "# # .apply(lambda x: re.sub(r'','',str(x)))\n",
    "\n",
    "\n",
    "# import ast\n",
    "# def remove_duplicates(A):\n",
    "#     [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "#     return A\n",
    "# prods['matchez']=prods['matchez'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)]))\n",
    "# prods['matchez']=prods['matchez'].apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r\"'\",'\"',str(x)))\n",
    "# prods['matchez']=prods['matchez'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'\\s?\"\\s?','\"',str(x)))\n",
    "# prods['matchez']=prods['matchez'].apply(lambda x: re.sub(r'(\\[\"Casters\"\\,\"Filing Cabinet\"\\])|(\\[\"Dish Brush\"\\,\"Soap Dispensers\"\\])|(\\[\"Basket\"\\,\"Ladder\"\\])|(\\[\\])','',str(x)))\n",
    "# prods['matchez'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prods['Q:product_type_cs']=prods['matchez']\n",
    "# match_prods=prods[['external_id','Q:product_type_cs']]\n",
    "# match_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/ - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/container-{get_df_name(matches)}-matches_blank.csv',index=False) \n",
    "    \n",
    "looks_good('Container Store', df, match_blanks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crate And Barrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '11'\n",
    "customer_name='%crateandbarrel%'\n",
    "dateszs='2001-02-15'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "crate = query_from_file(file_name='../query/curated_all_attributes_date_family.sql', params=params)\n",
    "print(len(crate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed=crate[(crate['attribute'].astype(str)=='bedding_size')&((crate['buckets'].astype(str)=='Duvets/Quilts')|(crate['buckets'].astype(str)=='Duvet Inserts')|(crate['buckets'].astype(str)=='Duvet Covers'))]\n",
    "trip=r'''(?i)(full)|(queen)|()'''                                                              \n",
    "bed['match']=bed['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bed[bed['match'].astype(str)!='[]']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed[bed['value'].astype(str)=='[\"Full\",\"Queen\"]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crate[(crate['name'].astype(str)=='NorCal Kids Organic Glow-in-the-Dark White Full Quilt')&(crate['attribute'].astype(str)=='bedding_size')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(full.queen|\\bF(?:\\/|\\-)Q)|(duvet)|()'''                                                              \n",
    "crate['match']=crate['name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "trip=r'''(?i)(botanical|baby|toddler|king|queen|twin)|()'''                                                              \n",
    "crate['not_match']=crate['name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "\n",
    "duvet=crate[(crate['match'].astype(str)!='[]')&(crate['attribute'].astype(str)=='bedding_size')&(crate['value'].astype(str)!='Full/Queen')&(crate['buckets'].astype(str)=='Duvet Covers')]\n",
    "print(len(duvet))\n",
    "duvet['Q:bedding_size']='[\"Full/Queen\"]'\n",
    "match_duvet_bedding_size=duvet[['external_id','Q:bedding_size']]\n",
    "\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer,  matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-match_duvet_bedding_size.csv',index=False) \n",
    "# looks_good('Crate and Barrel', match_duvet_bedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dish=crate[(crate['attribute'].astype(str)=='features')&(crate['external_id'].astype(str)=='656248')]\n",
    "dish['Q:features']='[\"Dishwasher Safe\",\"Chip-Resistant\",\"Warp-Resistant\"]'\n",
    "\n",
    "match_dish=dish[['external_id','Q:features']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer,  matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-match_dish.csv',index=False) \n",
    "looks_good('Crate and Barrel', match_dish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crate_composite=pd.read_csv(r'Crate_composite.csv')\n",
    "crate_dishwasher=pd.read_csv(r'Crate_dishwasher.csv')\n",
    "lst=crate_composite['SKU'].to_list()\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[\"162762\",\n",
    " \"162783\",\n",
    " \"163547\",\n",
    " \"529282\",\n",
    " \"529330\",\n",
    " \"205240\",\n",
    " \"656303\",\n",
    " \"656312\",\n",
    " \"656334\",\n",
    " \"656358\",\n",
    " \"656381\",\n",
    " \"656411\",\n",
    " \"610805\",\n",
    " \"610842\",\n",
    " \"610854\",\n",
    " \"244986\",\n",
    " \"245043\",\n",
    " \"245064\",\n",
    " \"315093\",\n",
    " \"165847\",\n",
    " \"656140\",\n",
    " \"656206\",\n",
    " \"656236\",\n",
    " \"656248\",\n",
    " \"165496\",\n",
    " \"165724\",\n",
    " \"265102\",\n",
    " \"265174\",\n",
    " \"265185\",\n",
    " \"265193\",\n",
    " \"265215\",\n",
    " \"265220\",\n",
    " \"265256\",\n",
    " \"265264\",\n",
    " \"265290\",\n",
    " \"265311\",\n",
    " \"323975\",\n",
    " \"221492\",\n",
    " \"265852\",\n",
    " \"265901\",\n",
    " \"265928\",\n",
    " \"266131\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=crate[(crate['external_id'].isin(lst))&(crate['attribute'].astype(str)=='material')]\n",
    "# x.to_csv('Crate_Material_Composite.csv')\n",
    "x\n",
    "# crate[(crate['external_id'].isin(lst))&(crate['attribute'].astype(str)=='features')]\n",
    "\n",
    "trip=r'''(?i)(composite)|()'''                                                              \n",
    "x['match']=x['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "composite=x[x['match'].astype(str)=='[]']\n",
    "composite['Q:material']=composite['value'].apply(lambda x: re.sub(r'','',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm=crate\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()\n",
    "# width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "# depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "# height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite=crate[((crate['attribute'].astype(str)=='material'))]#&((crate['buckets'].astype(str)=='Serving Utensils & Cutlery Variety Packs')|(crate['buckets'].astype(str)=='Chopping/Slicing/Cutting Boards'))]\n",
    "print(len(composite))\n",
    "# composite['Q:material']=''\n",
    "# match_composite=composite[['external_id','Q:material']]\n",
    "# match_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer,  matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-match_composite.csv',index=False) \n",
    "    \n",
    "looks_good('Crate and Barrel', match_composite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patz=\"(?i)(Dishwasher.?Safe)|()\"                  \n",
    "crate['match']=crate['long_desc'].apply(lambda x: re_extract(patz, str(x)))\n",
    "\n",
    "patz=\"(?i)(Dishwasher.?Safe)|()\"                  \n",
    "crate['values']=crate['value'].apply(lambda x: re_extract(patz, str(x)))\n",
    "\n",
    "feats=crate[(crate['attribute'].astype(str)=='features')&(crate['buckets'].astype(str)=='Chopping/Slicing/Cutting Boards')]\n",
    "# feats=crate[(crate['buckets'].astype(str)=='Chopping/Slicing/Cutting Boards')]\n",
    "dishes=feats[feats['match'].astype(str)!='[]']\n",
    "dishes['buckets'].explode().value_counts()\n",
    "feats[feats['external_id'].astype(str)=='656140']['attribute'].explode().value_counts()\n",
    "# dishes['Q:features']=''\n",
    "# match_dish=dishes[['external_id','Q:features']]\n",
    "# match_dish\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer,  matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-match_dish.csv',index=False) \n",
    "    \n",
    "# looks_good('Crate and Barrel', match_dish)\n",
    "\n",
    "# 245043, 656140, 265193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patz=\"(?i)(Composite)|()\"                  \n",
    "crate['match']=crate['long_desc'].apply(lambda x: re_extract(patz, str(x)))\n",
    "\n",
    "patz=\"(?i)(Composite)|()\"                  \n",
    "crate['values']=crate['value'].apply(lambda x: re_extract(patz, str(x)))\n",
    "\n",
    "mat=crate[(crate['attribute'].astype(str)=='material')&(crate['buckets'].astype(str)=='Chopping/Slicing/Cutting Boards')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat[mat['values'].astype(str)=='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dish=crate[(crate['attribute'].astype(str)=='features')&(crate['match'].astype(str)!='[]')&(crate['bucket_id'].astype(str)=='nan')]#['buckets'].explode().value_counts()\n",
    "# print(len(dish))\n",
    "# dish['matches']=dish['value'].apply(lambda x: f'[\"Dishwasher Safe\",\"{x}\"]').apply(lambda x: re.sub(r'\"\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\\,\"\\[\"',',\"',str(x))).apply(lambda x: re.sub(r'\"Dishwasher Safe\",\"Dishwasher Safe\"','\"Dishwasher Safe\"',str(x))).apply(lambda x: re.sub(r'\"Dishwasher Safe\",\"Beveled\",\"Dishwasher Safe\"','\"Beveled\",\"Dishwasher Safe\"',str(x)))                                       \n",
    "# dish['external_id'].explode().value_counts().reset_index()['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# material_kitchen=pd.read_csv('material_kitchen.csv')\n",
    "# print(len(material_kitchen))\n",
    "# material_kitchen['external_id']=material_kitchen['SKU']\n",
    "# material_kitchen['Q:material']=''\n",
    "# match_mat_kit=material_kitchen[['external_id','Q:material']]\n",
    "# match_mat_kit\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer,  matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-match_mat_kit.csv',index=False) \n",
    "    \n",
    "# looks_good('Crate and Barrel', match_mat_kit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crate[crate['attribute'].astype(str)=='light_filtration']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wood=crate[(crate['attribute'].astype(str)=='wood_finish')&((crate['external_id'].astype(str)=='418965')|(crate['external_id'].astype(str)=='418991')|(crate['external_id'].astype(str)=='419018')|(crate['external_id'].astype(str)=='419006'))]\n",
    "# wood['Q:wood_finish']='Maple'\n",
    "# match_wood=wood[['external_id','Q:wood_finish']]\n",
    "# match_wood\n",
    "crate[(crate['attribute'].astype(str)=='wood_finish')&(crate['value'].astype(str)=='Maple')]['external_id'].explode().value_counts()\n",
    "# wood['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer,  matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-match_wood.csv',index=False) \n",
    "    \n",
    "looks_good('Crate and Barrel', match_wood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate[(crate['attribute'].astype(str)=='wood_finish')&(crate['value'].astype(str)!='n/a')]#['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crate[(crate['buckets'].astype(str)=='Chopping/Slicing/Cutting Boards')&(crate['attribute'].astype(str)=='wood_finish')]['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wood=crate[(crate['buckets'].astype(str)=='Chopping/Slicing/Cutting Boards')&(crate['attribute'].astype(str)=='wood_finish')]#['value'].explode().value_counts()\n",
    "wood['Q:wood_finish']=''\n",
    "match_wood=wood[['external_id','Q:wood_finish']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer,  matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-match_wood.csv',index=False) \n",
    "    \n",
    "looks_good('Crate and Barrel', match_wood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip=r'''(?i)(ebonized)|(maple)|(walnut)|(grey wash)|(teak)|(accacia)|()'''                                                              \n",
    "# crate['match']=crate['name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# crate['matches']=crate['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# # crate['attribute'].explode().value_counts()\n",
    "# print(len(crate))\n",
    "# print(len(crate[(crate['match'].astype(str)!='[]')|(crate['matches'].astype(str)!='[]')]))\n",
    "# crate[(crate['match'].astype(str)!='[]')|(crate['matches'].astype(str)!='[]')]['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chopping=crate[(crate['buckets'].astype(str)=='Chopping/Slicing/Cutting Boards')&((crate['match'].astype(str)!='[]')|(crate['matches'].astype(str)!='[]'))]\n",
    "# chops=chopping[(chopping['value'].astype(str)=='n/a')&(chopping['attribute'].astype(str)=='wood_finish')]\n",
    "# print(len(chops))\n",
    "\n",
    "# chops['Q:wood_finish']=''\n",
    "# # chops['attribute'].explode().value_counts()\n",
    "# chops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = pd.DataFrame({\"external_id\": ['235701','579388','246640', '645590', '246559', '518667'],\"Q:coffee_maker_type\":['[\"Drip Coffee Makers\",\"Single Serve\"]','[\"Combination Machines\",\"Single Serve\"]','[\"Automatic\",\"Semi-Automatic Machines\"]','[\"Automatic\",\"Semi-Automatic Machines\"]','[\"Automatic\",\"Semi-Automatic Machines\"]','[\"Automatic\",\"Capsule/Single Serve\"]',]})\n",
    "# abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer,  matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/ - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-WoodCutter.csv',index=False) \n",
    "    \n",
    "looks_good('Crate and Barrel',  abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string = map(str, lst) \n",
    "x=crate[crate['external_id'].isin(list_string)]\n",
    "# ups=x[x['attribute'].astype(str)=='coffee_maker_type']\n",
    "# ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate[(crate['external_id'].astype(str)=='426161')]\n",
    "# x[(x['attribute'].astype(str)=='coffee_maker_type')]['value'].explode().value_counts()\n",
    "\n",
    "# x['attribute'].explode().value_counts()\n",
    "# crate[(crate['external_id'].astype(str)=='260956')&(crate['attribute'].astype(str)=='coffee_maker_type')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=r'''(?i)(Crate . Barrel EvenCook Core.?.? 6 Qt)|(\\blid\\b)|(Crate .? Barrel EvenCook Core)|(BBQ Grill Basket with Lid)'''\n",
    "crate['matchz']=crate['long_desc'].apply(lambda x: re_extract(pat, str(x)))\n",
    "crate[(crate['external_id'].astype(str)=='514383')&(crate['attribute'].astype(str)=='features')]\n",
    "a=crate[(crate['matchz'].astype(str)!='[]')&(crate['attribute'].astype(str)=='features')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(a))\n",
    "\n",
    "import ast\n",
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A\n",
    "\n",
    "a['match']=a['value'].apply(lambda x: f'[\"{x}\"]')\n",
    "a['match']=a['match'].apply(lambda x: re.sub(r'\"\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\\[\"\\[\"','[\"',str(x))).apply(lambda x: re.sub(r'\\[\"n/a\"\\]','[\"Includes Lid\"]',str(x))).apply(lambda x: re.sub(r'\"\\]','\",\"Includes Lid\"]',str(x))).apply(lambda x: re.sub(r\"(?<=')Adjustable Settings(?=')\",'[\"Adjustable Settings\",\"Includes Lid\"]',str(x)))\n",
    "\n",
    "a['matches']=a['match'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x))\n",
    "a['Q:features']=a['matches'].apply(lambda x: re.sub(r\"\\s?'\\s?\\,\\s?'\\s?\",'\",\"',str(x))).apply(lambda x: re.sub(r\"((?<=\\[)')|('(?=\\]))\",'\"',str(x)))\n",
    "# a['Q:features']\n",
    "a['Q:features'].explode().value_counts()\n",
    "match=a[['external_id','Q:features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/ - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-match_lid.csv',index=False) \n",
    "    \n",
    "looks_good('Crate and Barrel', df, match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=crate[(crate['attribute'].astype(str)=='features')&((crate['buckets'].astype(str)=='Kitchen Merchandise Variety Packs')|(crate['buckets'].astype(str)=='Kitchen Textiles & Clothing Replacement Parts & Accessories')|(crate['buckets'].astype(str)=='Specialty Kitchen Tools')|(crate['buckets'].astype(str)=='Cookware & Bakeware Variety Packs'))]\n",
    "patz=\"(?i)(\\blid\\b)|()\"                  \n",
    "x['match']=x['name'].apply(lambda x: re_extract(patz, str(x)))\n",
    "x['matches']=x['long_desc'].apply(lambda x: re_extract(patz, str(x)))\n",
    "lids=x[(x['match'].astype(str)!='[]')|(x['matches'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patz=\"(?i)(wood)|()\"                  \n",
    "crate['match']=crate['value'].apply(lambda x: re_extract(patz, str(x)))\n",
    "crate[(crate['attribute'].astype(str)=='material')&(crate['buckets'].astype(str)=='Chopping/Slicing/Cutting Boards')]['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate[crate['attribute'].astype(str)=='shape']\n",
    "# crate['buckets'].explode().value_counts()[1000:1500]\n",
    "# # Cookware & Bakeware Variety Packs\n",
    "# # Bakeware Set\n",
    "# # Cookware & Bakeware Other\n",
    "# crate[crate['attribute'].astype(str)=='material']['value'].explode().value_counts()\n",
    "# patz=\"(?i)(porcelain)|(ceramic)|(marble)|()\"                  \n",
    "# crate['match']=crate['value'].apply(lambda x: re_extract(patz, str(x)))\n",
    "# crate[crate['attribute'].astype(str)=='material']['match'].explode().value_counts()\n",
    "# crate[(crate['attribute'].astype(str)=='material')&(crate['buckets'].astype(str)=='Kitchen Merchandise Variety Packs')]['value'].explode().value_counts()[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESN 102033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# material=df[df['attribute'].astype(str)=='material']\n",
    "# pat=r'(?i)([^\\s]{1,15}.?wood.?[^\\s]{0,15})|()'\n",
    "# material['match'] = material['long_desc'].apply(lambda x: re_extract(pat, str(x)))\n",
    "# material[material['match'].astype(str)!='[]'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat=df[df['attribute'].astype(str)=='features']\n",
    "# pat=r'(?i)(reversible)|()'\n",
    "# feat['match'] = feat['value'].apply(lambda x: re_extract(pat, str(x)))\n",
    "# reverse=feat[feat['match'].astype(str)!='[]']#['buckets'].explode().value_counts()\n",
    "# reverse['Q:features']=reverse['value'].apply(lambda x: re.sub(r'(?i)(\\[\"Reversible\"\\])|(\\,\"Reversible\")|(\"Reversible\"\\,)','',str(x)))\n",
    "# match_reverse=reverse[['external_id','Q:features']]\n",
    "# match_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/ - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-matches_remove_reverse.csv',index=False) \n",
    "    \n",
    "looks_good('Crate and Barrel', df, match_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=df[df['attribute'].astype(str)=='material']\n",
    "pat=r'(?i)(ceramic non.?stick fry pan set)|(ceramic non.?stick fry pan)|()'\n",
    "mat['match'] = mat['name'].apply(lambda x: re_extract(pat, str(x)))\n",
    "\n",
    "cer=r'(?i)(ceramic)|()'\n",
    "mat['matches'] = mat['value'].apply(lambda x: re_extract(cer, str(x)))\n",
    "\n",
    "cer=mat[(mat['match'].astype(str)!='[]')&(mat['matches'].astype(str)=='[]')]\n",
    "cer['Q:material']=cer['value'].apply(lambda x: re.sub(r'\\[\"Metal\",\"Aluminum\"\\]','[\"Ceramic\",\"Metal\",\"Aluminum\"]',str(x)))\n",
    "matcer=cer[['external_id','Q:material']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/ - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "looks_good('Crate and Barrel', df, matcer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['buckets'].astype(str)=='Vases']\n",
    "# df['bucket_id'].explode().value_counts().reset_index()['index'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat=df[df['attribute'].astype(str)=='material']\n",
    "# certs='''(?i)(nylon)|(synthetic)|()'''\n",
    "# mat['match']=mat['value'].apply(lambda x: re_extract(certs,str(x)))\n",
    "# print(len(mat[(mat['match'].astype(str)!='[]')&(mat['buckets'].astype(str)!='Beds/Bedsteads/Bedframes/Bases')&(mat['buckets'].astype(str)!='None')]))\n",
    "# mat[(mat['match'].astype(str)!='[]')&(mat['buckets'].astype(str)!='Beds/Bedsteads/Bedframes/Bases')&(mat['buckets'].astype(str)!='None')]#['buckets'].explode().value_counts()\n",
    "\n",
    "# # certs='''(?i)(Audra Kids Twin Yellow Velvet Quilt)|(Audra Kids Twin Cream Velvet Quilt)|(Audra Kids Full/Queen Pink Velvet Quilt)|()'''\n",
    "# # mat['names']=mat['name'].apply(lambda x: re_extract(certs,str(x)))\n",
    "# # mat[mat['names'].astype(str)!='[]']#['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baby & Kids      Bedding & Bath\n",
    "# # In-Stock Baby & Kids Bedding\n",
    "# mat[(mat['buckets'].astype(str)=='Baby & Kids Bedding')|(mat['buckets'].astype(str)=='In-Stock')]\n",
    "# print(len(mat['buckets'].explode().value_counts()))\n",
    "# mat['buckets'].explode().value_counts()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.query('external_id in [408695,408857,261911,261975,409323,409412,409422,409565,409694]')\n",
    "# # df[df['external_id'].isin([408695,408857,261911,261975,409323,409412,409422,409565,409694])]\n",
    "# lst=[408695,408857,261911,261975,409323,409412,409422,409565,409694]\n",
    "# df.query('external_id in @lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pat=r'(?i)(409798)|(409043)|(467528)|()|(410277)|(408901)|(410162)|(410158)|(410132)|(410114)|(410068)|(409992)|(409727)|(409694)|(409565)|(409422)|(409412)|(409323)|(261975)|(261911)|(408857)|(408695)|()'\n",
    "# # val=r'(?i)(Grenadine)|(Matte.?Black)|(Graphite)|(Dark.?Blue)|(Cherry)|(White)|(Turquoise)|(Metallic.?Blue)|(Basil)|(Rustic.?Red)|(Rustic.?Ivory)|(Rustic.?Turquoise)|()|()|()|()'\n",
    "# # buck=r'(?i)(Baking Dishes)|(Breakfast & Specialty Pans)|(Cookware & Bakeware Variety Packs)|(Dutch Ovens & Braisers)|(Frying Pans & Skillets)|(Grill Pans & Griddles)|(Teapots & Teakettles)|()'\n",
    "# df['match'] = df['external_id'].apply(lambda x: re_extract(pat, str(x)))\n",
    "# # df['buck'] = df['buckets'].apply(lambda x: re_extract(buck, str(x)))\n",
    "# # df['valuez'] = df['long_desc'].apply(lambda x: re_extract(val, str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['external_id'].astype(str)==410277)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst=['410277','408695','408857','261911','261975','409323','409412','409422','409565','409694','409727','409992','410068','410114','410132','410158','410162','408901','409798','409043','467528']                           \n",
    "# for i in lst:\n",
    "#     print(f'{i}')\n",
    "# #     print(df[(df['external_id'].astype(str)==i)&(df['attribute'].astype(str)=='features')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df[(df['match'].astype(str)!='[]')&(df['attribute'].astype(str)=='features')]))\n",
    "# df[(df['match'].astype(str)!='[]')&(df['attribute'].astype(str)=='features')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df[(df['attribute'].astype(str)=='staub_color')&(df['match'].astype(str)!='[]')]))\n",
    "# print(len(df[(df['attribute'].astype(str)=='staub_color')&(df['match'].astype(str)!='[]')&(df['valuez'].astype(str)!='[]')]))\n",
    "\n",
    "# # staub=df[(df['attribute'].astype(str)=='staub_color')&(df['match'].astype(str)!='[]')]\n",
    "# # staub=''\n",
    "# # match_staub=staub[['external_id','Q:staub_color']]\n",
    "\n",
    "\n",
    "# print(len(df[(df['attribute'].astype(str)=='staub_color')]))\n",
    "# # df[(df['attribute'].astype(str)=='staub_color')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df[df['match'].astype(str)!='[]']))\n",
    "# df[df['match'].astype(str)!='[]']#['attribute'].explode().value_counts()#.reset_index()['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['match'].astype(str)!='[]']['buckets'].explode().value_counts()#.reset_index()['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df[df['attribute'].astype(str)=='crate_dresser_chest_size']))\n",
    "# crate=df[df['attribute'].astype(str)=='crate_dresser_chest_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crate['Q:crate_dresser_chest_size']=''\n",
    "# match=crate[['external_id','Q:crate_dresser_chest_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "\n",
    "# def looks_good(customer, df, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "# #     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "# #     non_matches[curation_col] = r'n/a'\n",
    "# #     non_matches.to_csv(f'{drive_path}/ - {attribute} - na upload {buckets}.csv',index=False)\n",
    "#     matches.to_csv(f'{drive_path}/CB-{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "# looks_good('Bed Bath & Beyond', df, match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '55'\n",
    "customer_name='%cvs%'\n",
    "dateszs='2001-01-01'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "cvs = query_from_file(file_name='../query/curated_all_attributes_date_family.sql', params=params)\n",
    "print(len(cvs))\n",
    "# df['time']=df['time'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm=cvs\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()\n",
    "# width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "# depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "# height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(teeth whitening)|()'''                                                              \n",
    "cvs['match']=cvs['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "x=cvs[(cvs['match'].astype(str)!='[]')&(cvs['attribute'].astype(str)=='product_type')]\n",
    "x['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x))\n",
    "x['attribute'].explode().value_counts()\n",
    "x[x['attribute'].astype(str)=='search_product_type']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[197945,929469,871740,669862,351690,415290,503493,455613,529260,438688,630924,632583,437022,645922,594832,110800,568457,510678,486077,626310,446301,331639,377049,119366,246690,326583,448648,545023,184147,492460,497152,503477,598797,670343,629682,433535,488738,\n",
    "499583,616824,114794,465256,432838,493670,238199,479540,586673,625356,556268,644125,279069,598624]\n",
    "list_string = map(str, lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concern=df[df['attribute'].astype(str)=='concern']\n",
    "x=concern[concern['external_id'].isin(list_string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['values']=x['value'].apply(lambda x: re.sub(r'n\\/a','[\"Sensitive Friendly\"]',str(x))).apply(lambda x: re.sub(r'\"\\]','\",\"Sensitive Friendly\"]',str(x))).apply(lambda x: re.sub(r'(?<!\")Acne','[\"Acne\",\"Sensitive Friendly\"]',str(x))).apply(lambda x: re.sub(r'(?<!\")Scars','[\"Scars\",\"Sensitive Friendly\"]',str(x))).apply(lambda x: re.sub(r'(?<!\")Wrinkles','[\"Sensitive Friendly\",\"Wrinkles\"]',str(x))).apply(lambda x: re.sub(r'(?<!\")SPF','[\"Sensitive Friendly\",\"SPF\"]',str(x))).apply(lambda x: re.sub(r'(?<!\")Personal Hygiene','[\"Personal Hygiene\",\"Sensitive Friendly\"]',str(x))).apply(lambda x: re.sub(r'(?<!\")Dermatologist Tested','[\"Dermatologist Tested\",\"Sensitive Friendly\"]',str(x)))                                                                                    \n",
    "\n",
    "# import ast\n",
    "# def remove_duplicates(A):\n",
    "#     [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "#     return A\n",
    "# x['values']=x['values'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)]))\n",
    "# x['values']=x['values'].apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r\"'\",'\"',str(x)))\n",
    "# # x['Q:concern']=x['values']\n",
    "# # match_csv_concern=x[['external_id','Q:concern']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "# lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lst=match_x['external_id'].explode().value_counts().reset_index()['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for element in x_lst:\n",
    "#     if element not in lst:\n",
    "#         print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Crate and Barrel --{get_df_name(matches)}-.csv',index=False) \n",
    "    \n",
    "looks_good('Crate and Barrel', df, match_csv_concern) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sense=concern[concern['external_id'].isin(list_string)][['external_id','value']]\n",
    "# sense['value'].apply(lambda x: re.sub(r'n\\/a','[\"Sensitive Friendly\"]',str(x))).apply(lambda x: re.sub(r'\"\\]','\",\"Sensitive Friendly\"]',str(x)))\n",
    "sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "# def remove_duplicates(A):\n",
    "#     [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "#     return A\n",
    "# from natsort import natsorted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvs=pd.read_csv('cvs.csv')\n",
    "# cvs['Q:product_type']='[\"'+cvs['Product Types']+'\",\"'+cvs['Product Type ']+'\"]'\n",
    "# upload=cvs[['external_id','Q:product_type']]\n",
    "# upload['Q:product_type']=upload['Q:product_type'].apply(lambda x: re.sub(r'Whitening','Teeth Whitening',str(x))).apply(lambda x: re.sub(r'Teeth Teeth','Teeth',str(x)))\n",
    "# upload['Q:product_type']=upload['Q:product_type'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x))\n",
    "# upload['Q:product_type']=upload['Q:product_type'].apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r'\\s?\\,\\s?','\",\"',str(x))).apply(lambda x: re.sub(r'''(\"')|('\")''','\"',str(x)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teeth Whitening Strips \n",
    "# Teeth Whitening Pens\n",
    "# Teeth Whitening Trays\n",
    "# Manual Toothbrushes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[df['attribute'].astype(str)=='product_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['external_id'].astype(str)=='496671']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df[df['value'].astype(str)=='Teeth Whitening']))\n",
    "# pt=df[df['value'].astype(str)=='Teeth Whitening']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex_pattern_na=r'(?i)(teeth.?whitening.{0,20}(?:strip|pen|tray))|((?<!vs.a.)(?<!regular.)(?<!ordinary..)(?<!same technique to brush as a )(?<!ordinary )(?<!vs..a.)(?<!better clean than a )(?<!more plaque than a )(?<!more plaque removal than brushing with a )(?<!better than a )(?<!than a )(?<!vs. a regular flat trim )manual.?toothbrush)|()'                    \n",
    "# pt['match'] = pt['long_desc'].apply(lambda x: re_extract(regex_pattern_na, x))\n",
    "# pt['match'].explode().value_counts()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teeth_pt=pt[pt['match'].astype(str)!=\"[]\"]\n",
    "# teeth_pt['match']=teeth_pt['match'].apply(lambda x: str(x).title()).apply(lambda x: re.sub(r\"((?<=\\[)')|((?<=\\[)')|('(?=\\]))\",'\"',str(x)))\n",
    "# teeth_pt['Q:product_type']=teeth_pt['match']\n",
    "# match_pt=teeth_pt[['external_id','Q:product_type']]\n",
    "# match_pt['Q:product_type']=match_pt['Q:product_type'].apply(lambda x: re.sub(r'''\"Manual Toothbrush'\\, 'Manual Toothbrush\"''','\"Manual Toothbrush\"',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "\n",
    "# def looks_good(customer, df, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "# #     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "# #     non_matches[curation_col] = r'n/a'\n",
    "# #     non_matches.to_csv(f'{drive_path}/ - {attribute} - na upload {buckets}.csv',index=False)\n",
    "#     matches.to_csv(f'{drive_path}/--{get_df_name(matches)}-matches-cvs.csv',index=False) \n",
    "    \n",
    "# looks_good('Bed Bath & Beyond', df, upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spt=df[df['attribute'].astype(str)=='search_product_type']\n",
    "# regex_pattern_na=r'(?i)(teeth.?whitening.?(?:strip|pen|tray))|()'\n",
    "# spt['match'] = spt['long_desc'].apply(lambda x: re_extract(regex_pattern_na, x))\n",
    "# spt['match'].explode().value_counts()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teeth_spt=spt[spt['match'].astype(str)!=\"[]\"]\n",
    "# teeth_spt['match']=teeth_spt['match'].apply(lambda x: str(x).title()).apply(lambda x: re.sub(r\"((?<=\\[)')|((?<=\\[)')|('(?=\\]))\",'\"',str(x)))\n",
    "# teeth_spt['Q:search_product_type']=teeth_spt['match']\n",
    "# match_spt=teeth_spt[['external_id','Q:search_product_type']]\n",
    "# # match_spt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_pt\n",
    "# match_spt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EB\n",
    "\n",
    "customer_id = '32'\n",
    "customer_name='%eddiebauer%'\n",
    "dateszs='2021-11-01'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "eb = query_from_file(file_name='../query/curated_all_attributes_date_family.sql', params=params)\n",
    "print(len(eb))\n",
    "# df['time']=df['time'].fillna(0)\n",
    "\n",
    "wbm=eb\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()\n",
    "# width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "# depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "# height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['family_friendly'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Total Yes/No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Percent of Yes: '+str(round(len(df[df['family_friendly'].astype(str)=='Yes'])/len(df)*100,2)))\n",
    "# print('Percent of No: '+str(round(len(df[df['family_friendly'].astype(str)=='No'])/len(df)*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Yes/No only for December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_date=df[(df['curated_date'].astype(str)<'2022-01-01')]\n",
    "# dfno=df[(df['family_friendly'].astype(str)=='No')&(df['curated_date'].astype(str)<'2022-01-01')]\n",
    "# dfyes=df[(df['family_friendly'].astype(str)=='Yes')&(df['curated_date'].astype(str)<'2022-01-01')]\n",
    "# print('Percent of Yes: '+str(round(len(dfyes[dfyes['family_friendly'].astype(str)=='Yes'])/len(df_date)*100,2)))\n",
    "# print('Percent of No: '+str(round(len(dfno[dfno['family_friendly'].astype(str)=='No'])/len(df_date)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes=df['attribute'].explode().value_counts().reset_index()\n",
    "# attributes.sort_values('attribute',ascending=False)[0:5]\n",
    "\n",
    "# dfexternal=df[['attribute','buckets','family_friendly','external_id','time']]\n",
    "# dfsum=df[['attribute','buckets','family_friendly','time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_time=df[df['time']!=0]\n",
    "# att_sum_time=df_time.groupby(['attribute','buckets','family_friendly','time'], as_index=False)['external_id'].count()\n",
    "# no_time=att_sum_time[(att_sum_time['family_friendly'].astype(str)=='No')&(att_sum_time['time'].astype(str)!='0.0')&(att_sum_time['attribute'].astype(str)!='color')&(att_sum_time['attribute'].astype(str)!='pattern')].sort_values('external_id',ascending=False)\n",
    "# yes_time=att_sum_time[(att_sum_time['family_friendly'].astype(str)=='Yes')&(att_sum_time['time'].astype(str)!='0.0')].sort_values('external_id',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes_time[0:500]#['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zero=df[df['time']==0]\n",
    "# att_sum=df_zero.groupby(['attribute','buckets','family_friendly','time'], as_index=False)['external_id'].count()\n",
    "# no_zero=att_sum[(att_sum['family_friendly'].astype(str)=='No')&(att_sum['time'].astype(str)=='0.0')].sort_values('external_id',ascending=False)\n",
    "# no_zero_plus=no_zero[(no_zero['attribute'].astype(str)!='product_type')&(no_zero['attribute'].astype(str)!='pattern')&(no_zero['attribute'].astype(str)!='color')]\n",
    "# yes_zero=att_sum[(att_sum['family_friendly'].astype(str)=='Yes')&(att_sum['time'].astype(str)=='0.0')].sort_values('external_id',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_zero_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['attribute', 'buckets','family_friendly']).sum()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=df['buckets'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "# print(len(df[df['resolution'].astype(str)=='family']))\n",
    "# df[df['resolution'].astype(str)=='family']\n",
    "# df['resolution'].explode().value_counts()\n",
    "\n",
    "# att=df['attribute'].explode().value_counts().reset_index()['index'].to_list()\n",
    "\n",
    "# for i in range(len(att)):\n",
    "#     df[df['attribute'].astype(str)==f'fabric']['buckets'].explode().value_counts().reset_index()\n",
    "\n",
    "# for i in range(len(att)):\n",
    "#     print(att[i])\n",
    "#     att[i]=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JosABank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '39'\n",
    "customer_name='%josabank%'\n",
    "dateszs='1990-12-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "jab = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "# df=df[df['resolution'].astype(str)!='rules']\n",
    "print(len(jab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm=jab\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()\n",
    "# width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "# depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "# height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jab['value'].explode().value_counts()[0:500]\n",
    "jab[jab['value'].astype(str)=='[\"Slim Fit\"]']\n",
    "jab[jab['attribute'].astype(str)=='fit']['value'].explode().value_counts()\n",
    "jab['external_id'].explode().value_counts()\n",
    "jab[jab['external_id'].astype(str)=='JAB_5EPZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[\"Jab Class Code\",\n",
    "\n",
    "\"Current Facet\",\n",
    "\n",
    "\"Expected Facet\",\n",
    "\n",
    "\"JAB_5EPZ\",\n",
    "\n",
    "\"FIT: SLIM FIT\",\n",
    "\n",
    "\"FIT: TAILORED FIT\",\n",
    "\n",
    "\"JAB_5EUJ\",\n",
    "\n",
    "\"FIT: SLIM FIT\",\n",
    "\n",
    "\"FIT: TAILORED FIT\",\n",
    "\n",
    "\"JAB_5D72\",\n",
    "\n",
    "\"FIT: TAILORED FIT\",\n",
    "\n",
    "\"FIT: SLIM FIT\",\n",
    "\n",
    "\"JAB_6K8U\",\n",
    "\n",
    "\"Type: Hoodie\",\n",
    "\n",
    "\"Type: Sweaters\",\n",
    "\n",
    "\"JAB_6KAR\",\n",
    "\n",
    "\"Type: Hoodie\",\n",
    "\n",
    "\"Type:Quarter Zip\",\n",
    "\n",
    "\"JAB_6K8R\",\n",
    "\n",
    "\"Type: Hoodie\",\n",
    "\n",
    "\"Type:Quarter Zip\",\n",
    "\n",
    "\"JAB_6KA6\",\n",
    "\n",
    "\"Type: Dress Shirt\",\n",
    "\n",
    "\"Type: Sportshirt\",\n",
    "\n",
    "\"JAB_6K8V\",\n",
    "\n",
    "\"Type: Hoodie\",\n",
    "\n",
    "\"Type: Sweaters\",\n",
    "\n",
    "\"JAB_3VTH\",\n",
    "\n",
    "\"Type: Pajama Sets\",\n",
    "\n",
    "\"Type: Standard Suit\",\n",
    "\n",
    "\"JAB_3V19\",\n",
    "\n",
    "\"Type: Pajama Sets\",\n",
    "\n",
    "\"Type: Standard Suit\",\n",
    "\n",
    "\"JAB_3V0H\",\n",
    "\n",
    "\"Type: Pajama Sets\",\n",
    "\n",
    "\"Type: Standard Suit\",\n",
    "\n",
    "\"JAB_3V0K\",\n",
    "\n",
    "\"Type: Pajama Sets\",\n",
    "\n",
    "\"Type: Standard Suit\",\n",
    "\n",
    "\"JAB_3V17\",\n",
    "\n",
    "\"Type: Pajama Sets\",\n",
    "\n",
    "\"Type: Standard Suit\",\n",
    "\n",
    "\"JAB_3V1C\",\n",
    "\n",
    "\"Type: Pajama Sets\",\n",
    "\n",
    "\"Type: Standard Suit\",\n",
    "\n",
    "\"JAB_15JN\",\n",
    "\n",
    "\"Type: Suit Separate Jacket\",\n",
    "\n",
    "\"Type: Dinner Jacket\",\n",
    "\n",
    "\"JAB_15JP\",\n",
    "\n",
    "\"Type: Suit Separate Jacket\",\n",
    "\n",
    "\"Type: Dinner Jacket\"]\n",
    "external_id=lst[::3]\n",
    "external_id=external_id[1:]\n",
    "\n",
    "current=lst[1::3]\n",
    "current=current[1:]\n",
    "\n",
    "new=lst[2::3]\n",
    "new=new[1:]\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match=pd.DataFrame()\n",
    "match['external_id']=external_id\n",
    "match['Q:fit']=new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_fit=match[(match['external_id'].astype(str)=='JAB_6KAR')|(match['external_id'].astype(str)=='JAB_6K8R')]\n",
    "\n",
    "match_fit['Q:product_type']=match_fit['Q:fit'].apply(lambda x: re.sub(r'(?i)Type:\\s?','',str(x))).apply(lambda x: str(x).title())\n",
    "matches=match_fit[['external_id','Q:product_type']]\n",
    "matches\n",
    "\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer,matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/Jos A Bank --{get_df_name(matches)}-matches.csv',index=False) \n",
    "# looks_good('Jos A Bank',matches) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_type=match[3:]\n",
    "# .apply(lambda x: re.sub(r'','',str(x)))\n",
    "match_type['Q:product_type']=match_type['Q:fit'].apply(lambda x: re.sub(r'Type:\\s?','',str(x))).apply(lambda x: re.sub(r'Sportshirt(?!s)','Sportshirts',str(x))).apply(lambda x: re.sub(r'Standard Suit(?!s)','Standard Suits',str(x))).apply(lambda x: re.sub(r'Dinner Jacket(?!s)','Dinner Jackets',str(x)))\n",
    "match_types=match_type[['external_id','Q:product_type']]\n",
    "match_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_fit=match[0:3]\n",
    "match_fit['Q:fit']=match_fit['Q:fit'].apply(lambda x: re.sub(r'FIT:\\s?','',str(x))).apply(lambda x: str(x).title())\n",
    "match_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/Jos A Bank --{get_df_name(matches)}-match_fit.csv',index=False) \n",
    "# looks_good('Jos A Bank', match_fit) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer,matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Jos A Bank --{get_df_name(matches)}-match_type.csv',index=False) \n",
    "    \n",
    "looks_good('Jos A Bank',match_types) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[\"Class\",\n",
    "\n",
    "\"Remove From Type\",\n",
    "\n",
    "\"Update to in Type\",\n",
    "\n",
    "\"JAB_3V1A\",\n",
    "\n",
    "\"Pajama Sets\",\n",
    "\n",
    "\"Standard Suit\",\n",
    "\n",
    "\"JAB_3V0G\",\n",
    "\n",
    "\"Pajama Sets\",\n",
    "\n",
    "\"Standard Suit\",\n",
    "\n",
    "\"JAB_3V0J\",\n",
    "\n",
    "\"Pajama Sets\",\n",
    "\n",
    "\"Standard Suit\",\n",
    "\n",
    "\"JAB_3VTG\",\n",
    "\n",
    "\"Pajama Sets\",\n",
    "\n",
    "\"Standard Suit\",\n",
    "\n",
    "\"JAB_3W33\",\n",
    "\n",
    "\"Pajama Sets\",\n",
    "\n",
    "\"Standard Suit\",\n",
    "\n",
    "\"JAB_3W3E\",\n",
    "\n",
    "\"Pajama Sets\",\n",
    "\n",
    "\"Standard Suit\",\n",
    "\n",
    "\"JAB_3V16\",\n",
    "\n",
    "\"Pajama Sets\",\n",
    "\n",
    "\"Standard Suit\",\n",
    "\n",
    "\"JAB_3V18\",\n",
    "\n",
    "\"Pajama Sets\",\n",
    "\n",
    "\"Standard Suit\",\n",
    "\n",
    "\"JAB_15JM\",\n",
    "\n",
    "\"Suit Separate Jackets\",\n",
    "\n",
    "\"Dinner Jacket\",\n",
    "\n",
    "\"JAB_15JR\",\n",
    "\n",
    "\"Suit Separate Jackets\",\n",
    "\n",
    "\"Dinner Jacket\"]\n",
    "external_id=lst[::3]\n",
    "external_id=external_id[1:]\n",
    "\n",
    "current=lst[1::3]\n",
    "current=current[1:]\n",
    "\n",
    "new=lst[2::3]\n",
    "new=new[1:]\n",
    "\n",
    "\n",
    "match=pd.DataFrame()\n",
    "match['external_id']=external_id\n",
    "match['Q:product_type']=new\n",
    "match['Q:product_type']=match['Q:product_type'].apply(lambda x: re.sub(r'Standard Suit(?!s)','Standard Suits',str(x))).apply(lambda x: re.sub(r'Dinner Jacket(?!s)','Dinner Jackets',str(x)))\n",
    "match_types=match[['external_id','Q:product_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jab[jab['external_id'].astype(str)=='JAB_41Z9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jab[jab['attribute'].astype(str)=='product_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '90'\n",
    "customer_name='%wbmason%'\n",
    "dateszs='1990-12-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "wbm = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "# df=df[df['resolution'].astype(str)!='rules']\n",
    "print(len(wbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width['Q:width']=width['matches']\n",
    "depth['Q:depth']=depth['matches']\n",
    "height['Q:height']=height['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_width=width[['external_id','Q:width']]\n",
    "match_depth=depth[['external_id','Q:depth']]\n",
    "match_height=height[['external_id','Q:height']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['value'].astype(str)=='Multicolour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['attribute'].astype(str)=='blade_width']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df['attribute'].explode().value_counts()\n",
    "# x=df['attribute'].explode().value_counts().reset_index()['index'].to_list()\n",
    "# x.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# micron=df[(df['attribute'].astype(str)=='thickness_micron')&(df['buckets'].astype(str)=='Waste / Refuse Bags')]#['value'].explode().value_counts()\n",
    "# micron['Q:thickness_micron']=micron['value'].apply(lambda x: x.lower())\n",
    "# matchmicron=micron[['external_id','Q:thickness_micron']]\n",
    "# # micron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/ - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}-height.csv',index=False) \n",
    "    \n",
    "looks_good('WBMason', df, match_height) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=wbm['attribute'].explode().value_counts().reset_index()['index'].to_list()\n",
    "lst.sort()\n",
    "wbm['value']=wbm['value'].apply(lambda x: re.sub(r\"'\\, '\",'\",\"',str(x))).apply(lambda x: re.sub(r'\"\\,\"',',,',str(x)))\n",
    "\n",
    "wbm[wbm['attribute'].astype(str)=='air_filter_capability']['value'].explode().value_counts()\n",
    "\n",
    "for i in range(len(lst)):\n",
    "    antena=wbm[wbm['attribute'].astype(str)==f'{lst[i]}']\n",
    "    print('')\n",
    "    print('###################################################')\n",
    "    print(lst[i])\n",
    "#     print(antena['value'].explode().value_counts())#.reset_index()['index'].to_list()\n",
    "    antena['match']=antena['value'].apply(lambda x: re.sub(r'\\[|\\]|\\\\|\"','',str(x)))\n",
    "    # antena['match'].explode().value_counts()\n",
    "    print(antena['match'].str.get_dummies(',,').sum().reset_index()['index'].to_list())\n",
    "    print('###################################################')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wbm[wbm['attribute'].astype(str)=='thickness_mil']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antena=wbm[wbm['attribute'].astype(str)=='corded_cordless']\n",
    "antena['value'].explode().value_counts()#.reset_index()['index'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antena=wbm[wbm['attribute'].astype(str)=='contrast_ratio']\n",
    "antena['value'].explode().value_counts()#.reset_index()['index'].to_list()\n",
    "# trip=r'''( lb)|()'''                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antena=wbm[wbm['attribute'].astype(str)=='bond_lbs']\n",
    "antena['value'].explode().value_counts()#.reset_index()['index'].to_list()\n",
    "trip=r'''( lb)|()'''                                                              \n",
    "antena['match']=antena['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bond=antena[(antena['match'].astype(str)=='[]')&(antena['value'].astype(str)!='n/a')]\n",
    "bond['matches']=bond['value'].apply(lambda x: re.sub(r'''(?<=\\d)(?=')|(?<=\\d)(?=\")''',' lb',str(x))).apply(lambda x: re.sub(r'''(?<=(?<!\")\\d(?!\")(?! lb)(?!\\d))''',' lb',str(x)))\n",
    "bond['matches']=bond['matches'].apply(lambda x: re.sub(r'\\[\"100 lb\"\\,\"28 lb\"\\]','[\"28 lb\",\"100 lb\"]',str(x))).apply(lambda x: re.sub(r'\\[\"100 lb\"\\,\"32 lb\"\\]','[\"32 lb\",\"100 lb\"]',str(x))).apply(lambda x: re.sub(r'\\[\"110 lb\"\\,\"90 lb\"\\]','[\"90 lb\",\"110 lb\"]',str(x)))\n",
    "bond['matches'].explode().value_counts()\n",
    "bond['Q:bong_lbs']=bond['matches']\n",
    "match_bond=bond[['external_id','matches']]\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer,matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}-match_bond.csv',index=False) \n",
    "    \n",
    "looks_good('WBMason',match_bond) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bills Per minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antena=wbm[wbm['attribute'].astype(str)=='bills_per_minute']\n",
    "antena['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antena=wbm[wbm['attribute'].astype(str)=='bed_bedding_size']\n",
    "antena['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battery Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antena=wbm[wbm['attribute'].astype(str)=='battery_type']\n",
    "antena['value'].explode().value_counts()\n",
    "repalce=antena[antena['value'].astype(str)=='Replacement Cartridge']\n",
    "repalce['Q:battery_type']=''\n",
    "match_repalce=repalce[['external_id','Q:battery_type']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer,matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}-match_repalce.csv',index=False) \n",
    "    \n",
    "looks_good('WBMason',match_repalce) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battery Package Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antena=wbm[wbm['attribute'].astype(str)=='battery_package_count']\n",
    "\n",
    "trip=r'''((?<!Single )Count)|()'''                                                              \n",
    "antena['match']=antena['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "\n",
    "# # antena['value'].apply(lambda x: re.sub(r'Level 1','',str(x)))\n",
    "count=antena[(antena['match'].astype(str)!='[]')]\n",
    "print(len(count))\n",
    "count['Q:battery_package_count']=''\n",
    "match_count=count[['external_id','Q:battery_package_count']]\n",
    "\n",
    "# antena\n",
    "# antena['value'].explode().value_counts()\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer,matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}-ANSI_Count.csv',index=False) \n",
    "    \n",
    "looks_good('WBMason',match_count) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect Ratio ---is 16:9 the same as 16:09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antena=wbm[wbm['attribute'].astype(str)=='aspect_ratio']\n",
    "# antena['value'].apply(lambda x: re.sub(r'Level 1','',str(x)))\n",
    "antena[(antena['value'].astype(str)=='1024x768')|(antena['value'].astype(str)=='21:09')]\n",
    "antena['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antena Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antena=wbm[wbm['attribute'].astype(str)=='appliance_cubic_feet']\n",
    "antena\n",
    "# ansi['value'].apply(lambda x: re.sub(r'Level 1','',str(x)))\n",
    "t=antena[antena['value'].astype(str)=='12.0 cu ft']\n",
    "t['Q:appliance_cubic_feet']='12 cu ft'\n",
    "match_t=t[['external_id','Q:appliance_cubic_feet']]\n",
    "match_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer,matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}-ANSI_t.csv',index=False) \n",
    "    \n",
    "looks_good('WBMason',match_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-Antenna\n",
    "2-Antenna\n",
    "3-Antenna\n",
    "4-Antenna\n",
    "5+ Antenna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansi=wbm[wbm['attribute'].astype(str)=='ansi_cut_resistance']\n",
    "ansi['value'].apply(lambda x: re.sub(r'Level 1','',str(x)))\n",
    "ansi[ansi['value'].astype(str)=='Level 1']\n",
    "\n",
    "cut=r'''(cut)|()'''                                                              \n",
    "ansi['cut']=ansi['long_desc'].apply(lambda x: re_extract(cut,str(x)))\n",
    "\n",
    "trip=r'''((?<!\\w)A\\d)|()'''                                                              \n",
    "ansi['match']=ansi['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "type2=r'''(Level)|()'''\n",
    "ansi['values']=ansi['value'].apply(lambda x: re_extract(type2,str(x)))\n",
    "x=ansi[(ansi['values'].astype(str)!='[]')]#['value'].explode().value_counts()\n",
    "print(len(x))\n",
    "x['Q:ansi_cut_resistance']=''\n",
    "match_x=x[['external_id','Q:ansi_cut_resistance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer,matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}-ANSI.csv',index=False) \n",
    "    \n",
    "looks_good('WBMason',match_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['external_id'].explode().value_counts()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x[x['external_id'].astype(str)=='5637602405']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  combine attributes \"Tip Type\" and \"Point Type\" (keeping the name \"Point Type\") for bucket Writing/Design Implements \n",
    "\n",
    "# point=df[(df['buckets'].astype(str)=='Writing/Design Implements & Accessories')&(df['attribute'].astype(str)=='point_type')]\n",
    "# points=point[['external_id','value']]\n",
    "# tip=df[(df['buckets'].astype(str)=='Writing/Design Implements & Accessories')&(df['attribute'].astype(str)=='tip_type')]\n",
    "# tips=tip[['external_id','value']]\n",
    "# # df['attribute'].explode().value_counts()[0:500]\n",
    "\n",
    "# merged=points.merge(tips, on='external_id', how='left')\n",
    "# merged[0:500]\n",
    "# merged[merged['external_id'].astype(str)=='5637473349']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple=merged[merged['value_y'].astype(str)=='nan']\n",
    "# nexts=merged[merged['value_y'].astype(str)!='nan']\n",
    "\n",
    "# nexts['Q:point_type']=nexts['value_x']\n",
    "# simple['Q:point_type']=simple['value_x']\n",
    "# matchsimple=simple[['external_id','Q:point_type']]\n",
    "# matchnext=nexts[['external_id','Q:point_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "\n",
    "# def looks_good(customer, df, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "# #     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "# #     non_matches[curation_col] = r'n/a'\n",
    "# #     non_matches.to_csv(f'{drive_path}/ - {attribute} - na upload {buckets}.csv',index=False)\n",
    "#     matches.to_csv(f'{drive_path}/WBM --{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "# looks_good('WBMason', df, match) \n",
    "# looks_good('WBMason', df, matchsimple) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sally Beauty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '19'\n",
    "customer_name='%sallybeauty%'\n",
    "dateszs='2022-01-18'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "sb = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "print(len(sb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm=sb\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()\n",
    "# width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "# depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "# height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=df[df['attribute'].astype(str)=='benefit']\n",
    "# # x['value'].explode().value_counts()\n",
    "# # x[0:500]\n",
    "# # x[x['value'].astype(str)=='All Types']\n",
    "# # x[x['value'].str.contains('All', na = False)]\n",
    "# # x[x['value'].astype(str)=='Natural']['long_desc']\n",
    "# # x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kimball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '137'\n",
    "customer_name='%kimballmidwest%'\n",
    "dateszs='2001-12-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['HeadHeight']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst=df['attribute'].explode().value_counts().reset_index()['index'].to_list()\n",
    "# # dfz['custom_fields'].explode().value_counts()\n",
    "# lst.sort()\n",
    "# lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_height_sae=df[(df['attribute'].astype(str)=='head_height_sae')&(df['value'].astype(str)=='n/a')&(df['HeadHeight'].astype(str)!='nan')]\n",
    "trips=r'(?i)((?<=\\d)\")|()'\n",
    "head_height_sae['match']=head_height_sae['HeadHeight'].apply(lambda x: re_extract(trips,str(x)))\n",
    "head_height_saes=head_height_sae[head_height_sae['match'].astype(str)!='[]']\n",
    "head_height_saes['HeadHeight'].explode().value_counts()\n",
    "head_height_saes['Q:head_height_sae']=head_height_saes['HeadHeight']\n",
    "match_head_height_saes=head_height_saes[['external_id','Q:head_height_sae']]\n",
    "match_head_height_saes\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_head_height_saes.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_head_height_saes,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_height_metric=df[(df['attribute'].astype(str)=='head_height_metric')&(df['value'].astype(str)=='n/a')&(df['HeadHeight'].astype(str)!='nan')]\n",
    "trips=r'(?i)(mm)|()'\n",
    "head_height_metric['match']=head_height_metric['HeadHeight'].apply(lambda x: re_extract(trips,str(x)))\n",
    "head_height_metrics=head_height_metric[head_height_metric['match'].astype(str)!='[]']\n",
    "# head_height_metrics['HeadHeight'].explode().value_counts()\n",
    "head_height_metrics['Q:head_height_metric']=head_height_metrics['HeadHeight'].apply(lambda x: re.sub(r'(?i)((?<=\\d)mm)',' mm',str(x)))\n",
    "match_head_height_metric=head_height_metrics[['external_id','Q:head_height_metric']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_head_height_metric.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_head_height_metric,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter_USS=df[(df['attribute'].astype(str)=='diameter_uss')&(df['value'].astype(str)=='n/a')&(df['Diameter'].astype(str)!='nan')]\n",
    "trips=r'(?i)(USS)|()'\n",
    "diameter_USS['match']=diameter_USS['Diameter'].apply(lambda x: re_extract(trips,str(x)))\n",
    "diameter_USSs=diameter_USS[diameter_USS['match'].astype(str)!='[]']\n",
    "# diameter_USS['Diameter'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter_size=df[(df['attribute'].astype(str)=='diameter_size')&(df['value'].astype(str)=='n/a')&(df['Diameter'].astype(str)!='nan')]\n",
    "trips=r'(?i)((?<![A-z])[a-w](?![A-z])\\d*)|(#\\d+)|(assort)|()'\n",
    "diameter_size['match']=diameter_size['Diameter'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "diameter_sizes=diameter_size[diameter_size['match'].astype(str)!='[]']\n",
    "diameter_sizes['Q:diameter_size']=diameter_sizes['Diameter'].apply(lambda x: re.sub(r'(?i)(\\s?\\-\\s?\\d(?:\\.\\d+|\\/\\d+)\"?)|((?:\\-\\s?)?\\d+\\/\\d+\"?\\s?(?:\\-\\s?)?)|(\\()|(\\))','',str(x)))\n",
    "diameter_sizes['Q:diameter_size'].explode().value_counts()\n",
    "match_diameter_sizes=diameter_sizes[['external_id','Q:diameter_size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_diameter_sizes.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_diameter_sizes,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter_sae=df[(df['attribute'].astype(str)=='diameter_sae')&(df['value'].astype(str)=='n/a')&(df['Diameter'].astype(str)!='nan')]\n",
    "trips=r'(?i)(\\d(?:\"|#))|()'\n",
    "diameter_sae['match']=diameter_sae['Diameter'].apply(lambda x: re_extract(trips,str(x)))\n",
    "diameter_saes=diameter_sae[diameter_sae['match'].astype(str)!='[]']\n",
    "diameter_saes['Q:diameter_metric']=diameter_saes['Diameter'].apply(lambda x: re.sub(r'(?i)(\\s?\\(#\\d+\\)\\s?)','',str(x)))\n",
    "match_diameter_saes=diameter_saes[['external_id','Q:diameter_metric']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_diameter_saes.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_diameter_saes,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter_metric=df[(df['attribute'].astype(str)=='diameter_metric')&(df['value'].astype(str)=='n/a')&(df['Diameter'].astype(str)!='nan')]\n",
    "trips=r'(?i)(mm)|(assort)|()'\n",
    "diameter_metric['match']=diameter_metric['Diameter'].apply(lambda x: re_extract(trips,str(x)))\n",
    "diameter_metrics=diameter_metric[diameter_metric['match'].astype(str)!='[]']\n",
    "diameter_metrics['Q:diameter_metric']=diameter_metrics['Diameter'].apply(lambda x: re.sub(r'(?i)((?<=\\d)\\s?mm)',' mm',str(x)))\n",
    "diameter_metrics['Q:diameter_metric'].explode().value_counts()\n",
    "match_diameter_metrics=diameter_metrics[['external_id','Q:diameter_metric']]\n",
    "match_diameter_metrics\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_diameter_metrics.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_diameter_metrics,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter=df[(df['attribute'].astype(str)=='diameter')&(df['value'].astype(str)=='n/a')&(df['Diameter'].astype(str)!='nan')]\n",
    "diameter['match']=diameter['Diameter'].apply(lambda x: re.sub(r'(?i)((?<=\\d)mm)',' mm',str(x)))\n",
    "diameter['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter=df[(df['attribute'].astype(str)=='diameter')&(df['value'].astype(str)=='n/a')&(df['Diameter'].astype(str)!='nan')]\n",
    "diameter['match']=diameter['Diameter'].apply(lambda x: re.sub(r'(?i)((?<=\\d)mm)',' mm',str(x)))\n",
    "diameter['match'].explode().value_counts()\n",
    "\n",
    "# trips=r'(?i)((?<!\\()#\\d)|(M\\d)|(mm)|(assort)|()'\n",
    "# diameter['junk']=diameter['match'].apply(lambda x: re_extract(trips,str(x)))\n",
    "# diameters=diameter[diameter['junk'].astype(str)=='[]']\n",
    "diameters['match']=diameters['match'].apply(lambda x: re.sub(r'(?i)(.*(?<!\\d)\\-s?)|(.*x\\s?)|(\\s?\\(.+\\))|(\\s(?=\\d))','',str(x)))\n",
    "diameters['match']=diameters['match'].apply(lambda x: re.sub(r'(?i)(\\s?USS)','\"',str(x)))\n",
    "\n",
    "\n",
    "\n",
    "diameters['match'].explode().value_counts()\n",
    "# diameters['Q:diameter']=diameters['match']\n",
    "# match_diameters=diameters[['external_id','Q:diameter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=df[(df['attribute'].astype(str)=='count')]\n",
    "counts=count[count['value'].astype(str)=='n/a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "metric='lbs'\n",
    "range_string = \"\"\"\n",
    "1 - 12 Count\n",
    "13 - 24 Count\n",
    "25 - 50 Count\n",
    "51 - 100 Count\n",
    "101 - 150 Count\n",
    "151 - 200 Count\n",
    "201 - 250 Count\n",
    "251 - 300 Count\n",
    "Greater than 300 Count\n",
    " \"\"\"\n",
    "\n",
    "range_params = {}\n",
    "for range_entry in range_string.split('\\n'):\n",
    "    range_nums = re.findall('\\d+', range_entry)\n",
    "    if len(range_nums) > 0: \n",
    "        range_params[tuple(map(int, range_nums))] = range_entry.strip()\n",
    "\n",
    "\n",
    "def  range_app(num_lst):\n",
    "    updated_labels = []\n",
    "    for num in num_lst:\n",
    "        num = float(num)\n",
    "        for range_param, range_label in range_params.items():\n",
    "            if len(range_param) == 1:\n",
    "                if num >= range_param[0]:\n",
    "                    updated_labels.append(range_label)\n",
    "            else:\n",
    "                if num >= range_param[0] and num <= range_param[1]:\n",
    "                    updated_labels.append(range_label)\n",
    "    return updated_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts['match']=counts['packagequantity'].apply(lambda x: f'[\"{x}\"]').apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(range_app).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) \n",
    "# counts['match']=counts['match'].apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "# counts['match'].explode().value_counts()\n",
    "# counts[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final=counts[counts['buckets'].astype(str)=='None']\n",
    "# final['Q:count']=final['match']\n",
    "# match_count=final[['external_id','Q:count']]\n",
    "# match_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_count.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_count,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material=df[(df['attribute'].astype(str)=='material')&(df['buckets'].astype(str)=='Cables, Cords & Cord Management Replacement Parts & Accessories')]\n",
    "material['buckets'].explode().value_counts()\n",
    "print(len(material))\n",
    "# print(len(material))\n",
    "# material['Q:material']=''\n",
    "# match_material=material[['external_id','Q:material']]\n",
    "# match_material\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer, matches,today): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_material.csv',index=False) \n",
    "# # looks_good('Kimball Midwest',match_material,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material['value'].explode().value_counts()\n",
    "trips=r'(?i)(terminal)|()'\n",
    "material['matches']=material['product_name'].apply(lambda x: re_extract(trips,str(x)))\n",
    "material['match']=material['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "bur=material[(material['matches'].astype(str)!='[]')|(material['match'].astype(str)!='[]')]\n",
    "print(len(bur))\n",
    "bur['value'].explode().value_counts()\n",
    "# bur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads=df[df['attribute'].astype(str)=='head_diameter']\n",
    "dia=df[df['attribute'].astype(str)=='diameter']\n",
    "heads_list=heads['external_id'].to_list()\n",
    "diameter=dia[(dia['external_id'].isin(heads_list))]\n",
    "\n",
    "trips=r'(?i)(bur)|()'\n",
    "diameter['matches']=diameter['product_name'].apply(lambda x: re_extract(trips,str(x)))\n",
    "diameter['match']=diameter['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "bur=diameter[(diameter['matches'].astype(str)!='[]')|(diameter['match'].astype(str)!='[]')]\n",
    "# diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia=df[df['attribute'].astype(str)=='diameter']\n",
    "trips=r'(?i)(assor)|()'\n",
    "dia['matches']=dia['value'].apply(lambda x: re_extract(trips,str(x)))\n",
    "ass=dia[(dia['matches'].astype(str)!='[]')]\n",
    "ass\n",
    "\n",
    "\n",
    "# Please remove \"assortment\" value from Diameter on skus with a size range. Several Super Primalloy Tap assortments have this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum Operating Speed (RPM)\n",
    "rpm=df[(df['attribute'].astype(str)=='maximum_rpm')|(df['attribute'].astype(str)=='maximum_operating_speed_rpm')]\n",
    "print(len(rpm))\n",
    "rpm['match']=rpm['value'].apply(lambda x: re.sub(r'(?i)((?<=\\d)(?=\\d\\d\\d(?!\\d)))',',',str(x))).apply(lambda x: re.sub(r'(?i)(RPM\\s)','RPM',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\d)(?<!rpm)(?!\\d)(?!\\,)(?!.rpm))',' RPM',str(x))).apply(lambda x: re.sub(r'(?i)(\\s?rpm..rpm)',' RPM',str(x)))                             \n",
    "rpm['match']=rpm['match'].apply(lambda x: re.sub(r'\"000 RPM\",\"10 RPM\"','\"10,000 RPM\"',str(x))).apply(lambda x: f'[\"{x}\"]').apply(lambda x: re.sub(r'\\[\"\\[\"','[\"',str(x))).apply(lambda x: re.sub(r'\"\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x)))\n",
    "rpms=rpm[rpm['value'].astype(str)!='n/a']\n",
    "\n",
    "max_rpm=rpms[rpms['attribute'].astype(str)=='maximum_rpm']\n",
    "max_rpm['Q:maximum_rpm']=max_rpm['match']\n",
    "match_max_rpm=max_rpm[['external_id','Q:maximum_rpm']]\n",
    "\n",
    "max_operating=rpms[rpms['attribute'].astype(str)=='maximum_operating_speed_rpm']\n",
    "max_operating['Q:maximum_operating_speed_rpm']=max_operating['match']\n",
    "match_max_operating=max_operating[['external_id','Q:maximum_operating_speed_rpm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_max_operating['Q:maximum_operating_speed_rpm'].explode().value_counts()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_max_rpm.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_max_rpm,today)\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_max_operating.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_max_operating,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diameter-->Listed as two absolute values instead of end of range\n",
    "(Roto-Kut Frame Drill Cutter Sets, Reamer SEts, K7 Hole Saw Sets\n",
    "Diameter SAE Displays it correctly\n",
    "\n",
    "Delete values of Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripz='(?i)(roto.?kut)|(frame.?drill)|(reamer.?set)|(k7.?hole.?saw)|()'  \n",
    "diam=df[(df['attribute'].astype(str)=='diameter')]\n",
    "diam['match']=diam['long_desc'].apply(lambda x: re_extract(tripz,str(x)))\n",
    "diam['matches']=diam['customer_name'].apply(lambda x: re_extract(tripz,str(x)))\n",
    "diam[(diam['matches'].astype(str)!='[]')|(diam['match'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diam['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diam_blank=diam[(diam['value'].astype(str)=='[\"1/2 in\",\"3/4 in\"]')|(diam['value'].astype(str)=='[\"3/4 in\",\"3/8 in\"]')|(diam['value'].astype(str)=='[\"2 in\",\"3 in\"]')|(diam['value'].astype(str)=='[\"1 in\",\"1/2 in\"]')|(diam['value'].astype(str)=='[\"1 in\",\"3 in\"]')|(diam['value'].astype(str)=='[\"5/16 in\",\"7/8 in\"]')|(diam['value'].astype(str)=='[\"3 in\",\"4 in\"]')|(diam['value'].astype(str)=='[\"3/4 in\",\"4-1/2 in\"]')|(diam['value'].astype(str)=='[\"2-1/2 in\",\"3/4 in\"]')|(diam['value'].astype(str)=='[\"2-5/16 in\",\"4-1/2 in\"]')]\n",
    "diam_blank['Q:diameter']=''\n",
    "match_diam_blank=diam_blank[['external_id','Q:diameter']]\n",
    "diam_blank\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer, matches,today): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_diam_blank.csv',index=False) \n",
    "# looks_good('Kimball Midwest',match_diam_blank,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "From Client - Joyce fixed SKU 821073, but the rest need update\n",
    "Most Skus in Tap Extractor and their Replacement Fingers are missing the data from \"Tap Size / Drill Size\" Attribute. Please add these values to \"Size SAE\" Attribute, as was done with 821044 and 821082\n",
    "\n",
    "\n",
    "Size SAE--> Use Tap Size / Drill Size to curate size SAE (Fractions) as fraction-fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripz='(?i)(tap.?extractor)|(repalcement.?fing)|()'   \n",
    "df['match']=df['long_desc'].apply(lambda x: re_extract(tripz,str(x)))\n",
    "df['matches']=df['customer_name'].apply(lambda x: re_extract(tripz,str(x)))\n",
    "df[(df['attribute'].astype(str)=='size_sae')&(df['matches'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac=df[(df['attribute'].astype(str)=='size_sae')&(df['TapSize_DrillSize'].astype(str)!='nan')]\n",
    "\n",
    "tripz='(?i)(((?:\\d+\\s?\\-\\s?)?\\d+\\/\\d+\"\\s?\\-\\s?(?:\\d+\\s?\\-\\s?)?\\d+\\/\\d+\")|((?:\\d+\\s?\\-\\s?)?\\d+\\/\\d+\"))|()'   \n",
    "frac['matchz']=frac['TapSize_DrillSize'].apply(lambda x: re_extract(tripz,str(x)))\n",
    "frac['TapSize_DrillSize'].explode().value_counts()\n",
    "\n",
    "fractions=frac[frac['matchz'].astype(str)!='[]']\n",
    "fractions['Q:size_sae']=fractions['matchz'].apply(lambda x: re.sub(r\"(\\[)|(\\])|(')\",'',str(x))).apply(lambda x: re.sub(r'\\s\\-\\s','-',str(x)))\n",
    "match_fractions=fractions[['external_id','Q:size_sae']]\n",
    "match_fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches,today): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Kimball Midwest --{get_df_name(matches)}-{today}match_fractions.csv',index=False) \n",
    "looks_good('Kimball Midwest',match_fractions,today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripz='(?i)(\\bburs?\\.?)|()'   \n",
    "df['match']=df['long_desc'].apply(lambda x: re_extract(tripz,str(x)))\n",
    "df['matches']=df['customer_name'].apply(lambda x: re_extract(tripz,str(x)))\n",
    "df[(df['attribute'].astype(str)=='head_diameter')&(df['matches'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['attribute'].astype(str)=='head_diameter')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df#['custom_fields'].explode().value_counts()\n",
    "# # dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# dimensions=df[df['attribute'].astype(str)!='nan']#['attribute'].explode().value_counts()\n",
    "\n",
    "# dfz[dfz['external_id'].astype(str)=='823553']\n",
    "diam=df[df['attribute'].astype(str)=='diameter']\n",
    "diam\n",
    "\n",
    "trips=r'(?i)(\\bburs?\\b.{0,30})|()'\n",
    "diam['matches']=diam['customer_name'].apply(lambda x: re_extract(trips,str(x)))\n",
    "diam['match']=diam['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "wire=diam[((diam['matches'].astype(str)!='[]')|(diam['match'].astype(str)!='[]'))]\n",
    "print(len(wire))\n",
    "# wire[curation_col]=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head=df[df['attribute'].astype(str)=='head_diameter']\n",
    "\n",
    "trips=r'(?i)(\\bburs?\\b.{0,30})|()'\n",
    "head['matches']=head['customer_name'].apply(lambda x: re_extract(trips,str(x)))\n",
    "head['match']=head['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "wires=head[(head['matches'].astype(str)!='[]')|(head['match'].astype(str)!='[]')]\n",
    "print(len(wires))\n",
    "# wire[curation_col]=''\n",
    "wires['external_id'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head[head['buckets'].astype(str)=='Power Sanders & Grinders Accessories & Replacement Parts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['buckets'].astype(str)=='Tap Extractor and their Replacement Fingers']\n",
    "\n",
    "trips=r'(?i)(Tap.?Extractor)|(Replacement.?Fingers)|()'\n",
    "df['matches']=df['customer_name'].apply(lambda x: re_extract(trips,str(x)))\n",
    "df['match']=df['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "wire=df[((df['matches'].astype(str)!='[]')|(df['match'].astype(str)!='[]'))]\n",
    "print(len(wire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Conduit Fittings, Replacement Parts, & Accessories\n",
    "# #     29372 29370 29371\n",
    "# diams=kim[(kim['attribute'].astype(str)=='diameter')]\n",
    "# text=r'(?i)(Heavy Wall)|(Heat Shrink Tubing)|()'\n",
    "# diams['match']=diams['long_desc'].apply(lambda x: re_extract(text,str(x)))\n",
    "# diams[diams['match'].astype(str)!='[]']\n",
    "# diams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wbm=kim\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()\n",
    "# width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "# depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "# height=bracket[bracket['attribute'].astype(str)=='height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '137'\n",
    "customer_name='%kimballmidwest%'\n",
    "dateszs='2001-12-01'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "fields = ['shortdescription']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Shank Size and Shank Diameter appear to be duplicate attributes. Requesting the following:\n",
    "\n",
    "1.) Work with Jeff / (the client if needed) to determine which attribute to keep (I think Shank Diameter since there are 2 - metric / SAE)\n",
    "2.) Compare data to see overlap\n",
    "3.) Merge data from the removed attribute into the attribute(s) that is kept\n",
    "4.) Wipe old attribute / remove from strategy\n",
    "5.) Review remaining n/a's - update with values if available (title, description, standard, custom fields) - client noted Roto-Kut Ultra hole cutters, \"Several\" Metric Single End End Mills, Turning Bits, Speedbor Bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst=df[((df['attribute'].astype(str)=='shank_size')|(df['attribute'].astype(str)=='shank_diameter_sae')|(df['attribute'].astype(str)=='shank_diameter_metric'))]['external_id'].explode().value_counts().reset_index()\n",
    "# lsts=lst[lst['external_id'].astype(str)=='2']['index'].to_list()\n",
    "# print(len(lsts))\n",
    "# df[(df['external_id'].isin(lsts))&((df['attribute'].astype(str)=='shank_size')|(df['attribute'].astype(str)=='shank_diameter_sae')|(df['attribute'].astype(str)=='shank_diameter_metric'))].sort_values('external_id')[0:500]                                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Client reporting Count is missing from many SKUs - requesting to check strategy (bucket mapping) and curation (n/as) on the following\n",
    "Most Fastener Assortments are missing value in Count Attribute\n",
    "Count Value for several metric Stainless Steel Hex Head Cap Screws missing\n",
    "Count Value for Torque-Tension Hex Nuts missing.\n",
    "Count Value missing on most Prevailing Torque Lock Nuts\n",
    "Count Value missing from Stainless Steel Anti-Galling Locknuts (including Waxed variety)\n",
    "Count missing from many Metric Nylon Lock Nuts\n",
    "Count Missing from Coupling Nuts\n",
    "Count missing from Power-Thread Screws\n",
    "Count Missing from Several Flat Socket Head Cap Screws\n",
    "Count Missing for Grade 8 Threaded Rod\n",
    "\n",
    "Fasteners Assortments\n",
    "Stainless Steel Hex Head Cap Screws\n",
    "Torqure-Tension Hex Nut\n",
    "Prevailing Torque Lock Nuts\n",
    "Stainless Steel Anti-Galling Locknuts\n",
    "Metric Nylon Lock Nuts\n",
    "Coupling Nuts\n",
    "Power-THread Screws\n",
    "Several Flat Socket Head Cap Screws\n",
    "Grade 8 Threaded Rod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=df[df['attribute'].astype(str)=='hole_diameter']\n",
    "print(len(count))\n",
    "trip=r'''(?i)(Tubular)|()'''                                                              \n",
    "count['match']=count['customer_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "count['matches']=count['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "counts=count[(count['match'].astype(str)!='[]')|(count['matches'].astype(str)!='[]')]\n",
    "countz=counts[counts['value'].astype(str)!='n/a']\n",
    "print(len(countz))\n",
    "countz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

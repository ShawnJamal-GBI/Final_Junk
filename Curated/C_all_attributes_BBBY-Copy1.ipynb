{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "from ftfy import fix_text\n",
    "# from util import UnitConversion, mapping_list_values, perl_to_posix\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_rows = 500\n",
    "from flashtext import KeywordProcessor\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 500\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from natsort import natsorted\n",
    "def query_from_file(file_name, params):\n",
    "    with open(f'{file_name}', mode='r') as f:\n",
    "        text = f.read()\n",
    "        query = text.format(**params)\n",
    "        return enrich_db(query)\n",
    "def re_extract(pattern, txt):\n",
    "    matches = re.findall(pattern, txt)\n",
    "    tmp_matches = []\n",
    "    for match in matches:\n",
    "        for tup in match:\n",
    "            if tup != '':\n",
    "                tmp_matches.append(tup)\n",
    "    return list(set(tmp_matches))\n",
    "import time\n",
    "today = time.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "import ast\n",
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A\n",
    "\n",
    "# importing the sys module\n",
    "import sys        \n",
    " \n",
    "# appending the directory of mod.py\n",
    "# in the sys.path list\n",
    "sys.path.append('C:/Users/groupby/Documents/GitHub/SQL Extract And Apply') \n",
    "from enrich_dimensions.rounds import rounds, rounding_inch_feet,rounding_lbs,rounding_w,rounding_oz, rounding_lb,rounding_gal, re_extract, curate, round_string_float, clean_data,reg_ex,rounding_period_after_unit \n",
    "from enrich_dimensions.params import parameters, query_from_file\n",
    "from enrich_dimensions.query_file import query_from_file \n",
    "from enrich_dimensions.custom import custom_field \n",
    "\n",
    "def three(usa,reg):\n",
    "    trip=fr'''(?i){reg}|()''' \n",
    "    usa['m_name']=usa['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    usa['m_desc']=usa['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    usa['m_custom']=usa['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    imported=usa[(usa['m_name'].astype(str)!='[]')|(usa['m_desc'].astype(str)!='[]')|(usa['m_custom'].astype(str)!='[]')]\n",
    "    impor=usa[(usa['m_name'].astype(str)=='[]')&(usa['m_desc'].astype(str)=='[]')&(usa['m_custom'].astype(str)=='[]')]\n",
    "    print('values: '+str(len(imported)))\n",
    "    print('no values: '+str(len(impor)))\n",
    "    return imported,impor\n",
    "\n",
    "print('Done')\n",
    "# rounding(inside, 'Q:inside_diameter','a-eghj-lo-su-z*')\n",
    "\n",
    "# .apply(lambda x: re.sub(r'(\\s?(?<!\")(?=\\]))|(\"\")','\"',str(x))).apply(lambda x: re.sub(r'(\"\")','\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r'''(((?:\"|')?\\s?\\,\\s?(?!\")(?:')?))''','\",\"',str(x))).apply(lambda x: re.sub(r'''((?<=\\[)\\s?'\\s?)|(\\s?'\\s?(?=\\]))|(\\s?'\\s?(?=\\,))|((?<=\\,)\\s?'\\s?)''','\"',str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBBY Bed Bath and Beyond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbby\n"
     ]
    }
   ],
   "source": [
    "print('bbby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-2b4e84a38781>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-2b4e84a38781>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    Room Coverage\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "capacity (qt)\n",
    "Room Coverage\n",
    "Baby Food Volume\n",
    "Daily Ice Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x='capacity (qt)'\n",
    "x.replace(' ','_').replace('(','_').replace(')','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2002-08-11'\n",
    "attribut='set_size'\n",
    "curation_col = f'Q:{attribut}'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print(len(dfs))\n",
    "# dfz=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "# print(len(dfz))\n",
    "# dfh=dfz[dfz['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# print(len(dfh))\n",
    "custom_field_df=pd.json_normalize(dfh['custom_fields'])\n",
    "fields=['Set_Size']\n",
    "df = pd.concat([dfs.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na=dfs[dfs['value'].astype(str)=='n/a']\n",
    "print(len(df_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:\\d{1,2}(?!\\d).?piece.?set|(?<!near.)set.?of.?\\d{1,2}(?!\\d)(?:.?or.?\\d{1,2}(?!\\d))?|set.?size.?'\\:\\s?'\\d{1,2}(?!\\d)))|()'''\n",
    "df_na['m_name']=df_na['product_name'].apply(lambda x: re_extract(pat,str(x)))\n",
    "df_na['m_long']=df_na['long_desc'].apply(lambda x: re_extract(pat,str(x)))\n",
    "df_na['m_custom']=df_na['custom_fields'].apply(lambda x: re_extract(pat,str(x)))\n",
    "\n",
    "set_size_all=df_na[(df_na['m_name'].astype(str)!='[]')|(df_na['m_long'].astype(str)!='[]')|(df_na['m_custom'].astype(str)!='[]')]\n",
    "print(len(set_size_all))\n",
    "set_size_custom=df_na[(df_na['m_custom'].astype(str)!='[]')]\n",
    "print(len(set_size_custom))\n",
    "set_size=df_na[((df_na['m_name'].astype(str)!='[]')|(df_na['m_long'].astype(str)!='[]'))&(df_na['m_custom'].astype(str)!='[]')]\n",
    "print(len(set_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_size_custom['matches']=set_size_custom['m_custom'].apply(lambda x: re.sub(r\"(or)\",'\",\"',str(x))).apply(lambda x: re.sub(r\"((?<!\\[)(?<!\\,)(?<!\\,\\s)'(?!\\,)(?!\\s\\,)(?!\\]))\",'',str(x))).apply(lambda x: re.sub(r'''(?i)((?:set|size|\\_|of|piece|\\:|\\s?|\\-))''','',str(x))).apply(lambda x: re.sub(r\"((?<=\\[)\\s?')|('\\s?(?=\\,))|((?<=\\,)\\s?')|('\\s?(?=\\]))\",'\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: re.sub(r\"((?<=\\[)\\s?')|('\\s?(?=\\,))|((?<=\\,)\\s?')|('\\s?(?=\\]))\",'\"',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: re.sub(r\"((?<=\\[)\\s?')|('\\s?(?=\\,))|((?<=\\,)\\s?')|('\\s?(?=\\]))\",'\"',str(x)))\n",
    "# set_size_custom['matches'].explode().value_counts()\n",
    "# set_size_custom[set_size_custom['matches'].astype(str)=='[\"3\",\"1\",\"2\",\"3\"]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "metric=' Piece Set'\n",
    "range_string = \"\"\"\n",
    "10 Piece Set\n",
    "11 Piece Set\n",
    "12 Piece Set\n",
    "13 Piece Set\n",
    "14 Piece Set\n",
    "15 Piece Set\n",
    "16 Piece Set\n",
    "17 Piece Set\n",
    "18 Piece Set\n",
    "19 Piece Set\n",
    "1 Piece\n",
    "20+ Piece Set\n",
    "2 Piece Set\n",
    "3 Piece Set\n",
    "4 Piece Set\n",
    "5 Piece Set\n",
    "6 Piece Set\n",
    "7 Piece Set\n",
    "8 Piece Set\n",
    "9 Piece Set\n",
    " \"\"\"\n",
    "\n",
    "range_params = {}\n",
    "for range_entry in range_string.split('\\n'):\n",
    "    range_nums = re.findall('\\d+', range_entry)\n",
    "    if len(range_nums) > 0: \n",
    "        range_params[tuple(map(int, range_nums))] = range_entry.strip()\n",
    "\n",
    "\n",
    "def  range_app(num_lst):\n",
    "    updated_labels = []\n",
    "    for num in num_lst:\n",
    "        num = float(num)\n",
    "        for range_param, range_label in range_params.items():\n",
    "            if len(range_param) == 1:\n",
    "                if num >= range_param[0]:\n",
    "                    updated_labels.append(range_label)\n",
    "            else:\n",
    "                if num >= range_param[0] and num <= range_param[1]:\n",
    "                    updated_labels.append(range_label)\n",
    "    return updated_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_size_custom[curation_col]=set_size_custom['matches'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(range_app).apply(lambda x: re.sub(r\"((?<!\\[)(?<!\\,)(?<!\\,\\s)'(?!\\,)(?!\\s\\,)(?!\\]))\",'',str(x)))\n",
    "set_size_custom[curation_col]=set_size_custom[curation_col].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: re.sub(r\"((?<!\\[)(?<!\\,)(?<!\\,\\s)'(?!\\,)(?!\\s\\,)(?!\\]))\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)]))\n",
    "set_size_custom['matches'].explode().value_counts()\n",
    "# set_size_custom[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_size_custom[set_size_custom['matches'].astype(str)=='[\"12\",\"16\",\"24\"]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_size_custom[curation_col]=set_size_custom[curation_col].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: re.sub(r\"((?<!\\[)(?<!\\,)(?<!\\,\\s)'(?!\\,)(?!\\s\\,)(?!\\]))\",'',str(x)))\n",
    "# set_size_custom[curation_col].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_na=set_size_custom[set_size_custom['value'].astype(str)=='n/a']\n",
    "print(len(custom_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_size[curation_col]=set_size['']\n",
    "match_set_size=set_size[['external_id',curation_col]]\n",
    "match_set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported['Q:origin']=''\n",
    "# match_na_re_curates=imported[['external_id','Q:origin']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_set_size-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_set_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2002-08-11'\n",
    "attribut='size'\n",
    "curation_col = f'Q:{attribut}'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribut':attribut}\n",
    "\n",
    "print('start')\n",
    "bucket_value = query_from_file(file_name='../query/Bucket_Value_Strategy.sql', params=params)\n",
    "\n",
    "# lst=bucket_value['buckets'].explode().value_counts().reset_index()['index'].to_list()#.sort()\n",
    "# lst.sort()\n",
    "# lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2002-08-11'\n",
    "attribut='size'\n",
    "curation_col = f'Q:{attribut}'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print(len(dfs))\n",
    "# dfz=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "# print(len(dfz))\n",
    "# dfh=dfz[dfz['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# print(len(dfh))\n",
    "# custom_field_df=pd.json_normalize(dfh['custom_fields'])\n",
    "# df=pd.concat([dfs.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs['q:ml_size']=dfs['value']\n",
    "# print(len(dfs))\n",
    "# match_size_backup=dfs[['external_id','q:ml_size']]\n",
    "# print(len(match_size_backup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_size_backup-{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_size_backup) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pajama Pants\n",
    "# Baby Feeding Bottles & Accessories\n",
    "# Cardigans/Kimonos/Wraps\n",
    "# Sweaters\n",
    "# Pantyhose/Tights\n",
    "# Swim Variety Packs\n",
    "# Overalls\n",
    "\n",
    "\n",
    "# Pet Houses, Crates, & Kennels\n",
    "# Underwear\n",
    "# Braces/Slings/Splints/Supports & Accessories\n",
    "# Arm/Leg Sleeves\n",
    "# Full Brim Hats\n",
    "# Pet Bowls & Feeders\n",
    "# Pet Costumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dfs[(dfs['buckets'].astype(str)!='Pet Costumes')&(dfs['buckets'].astype(str)!='Pet Bowls & Feeders')&(dfs['buckets'].astype(str)!='Full Brim Hats')&(dfs['buckets'].astype(str)!='Arm/Leg Sleeves')&(dfs['buckets'].astype(str)!='Braces/Slings/Splints/Supports & Accessories')&(dfs['buckets'].astype(str)!='Underwear')&(dfs['buckets'].astype(str)!='Pet Houses, Crates, & Kennels')&(dfs['buckets'].astype(str)!='Overalls')&(dfs['buckets'].astype(str)!='Swim Variety Packs')&(dfs['buckets'].astype(str)!='Pantyhose/Tights')&(dfs['buckets'].astype(str)!='Sweaters')&(dfs['buckets'].astype(str)!='Cardigans/Kimonos/Wraps')&(dfs['buckets'].astype(str)!='Baby Feeding Bottles & Accessories')&(dfs['buckets'].astype(str)!='Pajama Pants')&(dfs['buckets'].astype(str)!='Clothing Sets & Variety Packs')&(dfs['buckets'].astype(str)!='Everyday/Dress Bodysuits')&(dfs['buckets'].astype(str)!='Pajama Jumpsuits')&(dfs['buckets'].astype(str)!='Everyday/Dress Jumpsuits')&(dfs['buckets'].astype(str)!='Clothing & Accessory Variety Packs')&(dfs['buckets'].astype(str)!='Dresses & Gowns')&(dfs['buckets'].astype(str)!='Everyday/Dress Footwear')&(dfs['buckets'].astype(str)!='T-Shirts')&(dfs['buckets'].astype(str)!='Slacks/Pants')&(dfs['buckets'].astype(str)!='Leggings')&(dfs['buckets'].astype(str)!='Socks')&(dfs['buckets'].astype(str)!='Jackets/Coats')&(dfs['buckets'].astype(str)!='Baby Bibs & Burp Cloths')&(dfs['buckets'].astype(str)!='Robes')&(dfs['buckets'].astype(str)!='Night Dresses & Shirts')&(dfs['buckets'].astype(str)!='Pet Beds & Cots')&(dfs['buckets'].astype(str)!='Bras')&(dfs['buckets'].astype(str)!='Everyday/Dress Shorts')&(dfs['buckets'].astype(str)!='Pet Protective Wear')&(dfs['buckets'].astype(str)!='Non-Brim Hats')&(dfs['buckets'].astype(str)!='Role Playing Toys')&(dfs['buckets'].astype(str)!='Accessories Variety Packs')&(dfs['buckets'].astype(str)!='Tops')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x))\n",
    "x['buckets'].explode().value_counts()\n",
    "a=x[(x['buckets'].astype(str)=='None')|(x['buckets'].astype(str)=='nan')]\n",
    "print(len(a))\n",
    "x['Q:size']=''\n",
    "match_wipe_size=x[['external_id','Q:size']]\n",
    "match_wipe_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_wipe_size-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_wipe_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dfs))\n",
    "# dfs['value'].explode().value_counts()[0:500]\n",
    "# dfs['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['0-3 Months', '12-18 Months', '18-24 Months', '2T', '2X-Large', '3-6 Months', '3T', '3X-Large', '4T', '5T', '6-9 Months', '6T', '9-12 Months', 'Large', 'Large (10-12)', 'Medium', 'Medium (8)', 'Newborn', 'One Size', 'Preemie', 'Small', 'Small (6/7)', 'X-Large', 'X-Large (14-16)', 'X-Small', 'X-Small (4/5)']\n",
    "Pajama Pants\n",
    "Baby Feeding Bottles & Accessories\n",
    "Cardigans/Kimonos/Wraps\n",
    "Sweaters\n",
    "Pantyhose/Tights\n",
    "Swim Variety Packs\n",
    "Overalls\n",
    "\n",
    "\n",
    "\n",
    "['2X-Large', '3X-Large', 'Large', 'Medium', 'Small', 'X-Large', 'X-Small']\n",
    "Pet Houses, Crates, & Kennels\n",
    "Underwear\n",
    "Braces/Slings/Splints/Supports & Accessories\n",
    "Arm/Leg Sleeves\n",
    "Full Brim Hats\n",
    "Pet Bowls & Feeders\n",
    "Pet Costumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_buck=x['buckets'].explode().value_counts().reset_index()['index'].to_list()\n",
    "for i in range(len(lst_buck[0:23])):\n",
    "    e=bucket_value[bucket_value['buckets'].astype(str)==lst_buck[i]]\n",
    "    e['buckets'].value_counts()\n",
    "    print(lst_buck[i])\n",
    "    print(e['values'].to_list())\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Everyday/Dress Jumpsuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Remove duplicates\n",
    "Double check curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dresses=dfs[dfs['buckets'].astype(str)=='Dresses & Gowns']\n",
    "print(len(dresses))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "dresses['match']=dresses['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "dress=dresses[dresses['match'].astype(str)!='[]']\n",
    "print(len(dress))\n",
    "\n",
    "dress['Q:size']=dress['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "dress['Q:size']=dress['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "dress['Q:size']=dress['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "dress['Q:size']=dress['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "dress['Q:size']=dress['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r'(\\s?-\\s?)|(\\s?to\\s?)','-',str(x)))\n",
    "dress['Q:size']=dress['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x))).apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r',','\",\"',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r\"'\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "match_dress=dress[['external_id','Q:size']]\n",
    "\n",
    "dress['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "dresses['match']=dresses['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "dresse=dresses[dresses['match'].astype(str)=='[]']\n",
    "print(len(dresse))\n",
    "\n",
    "dresse['Q:size']='n/a'\n",
    "match_dresse_na=dresse[['external_id','Q:size']]\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_dress-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_dress) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_dresse_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_dresse_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_variety=dfs[dfs['buckets'].astype(str)=='Clothing & Accessory Variety Packs']\n",
    "print(len(clothing_variety))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "clothing_variety['match']=clothing_variety['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "cloth_variety=clothing_variety[clothing_variety['match'].astype(str)!='[]']\n",
    "print(len(cloth_variety))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth_variety['Q:size']=cloth_variety['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "cloth_variety['Q:size']=cloth_variety['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "cloth_variety['Q:size']=cloth_variety['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "cloth_variety['Q:size']=cloth_variety['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "cloth_variety['Q:size']=cloth_variety['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "cloth_variety['Q:size']=cloth_variety['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_cloth_variety=cloth_variety[['external_id','Q:size']]\n",
    "\n",
    "cloth_variety['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "clothing_variety['match']=clothing_variety['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "cloth_varietys=clothing_variety[clothing_variety['match'].astype(str)=='[]']\n",
    "print(len(cloth_varietys))\n",
    "\n",
    "cloth_varietys['Q:size']='n/a'\n",
    "match_cloth_varietys_na=cloth_varietys[['external_id','Q:size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_cloth_variety-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_cloth_variety) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_cloth_varietys_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_cloth_varietys_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['0-3 Months', '12-18 Months', '18-24 Months', '2T', '2X-Large', '3-6 Months', '3T', '3X-Large', '4T', '5T', '6-9 Months', '6T', '9-12 Months', 'Large', 'Large (10-12)', 'Medium', 'Medium (8)', 'Newborn', 'One Size', 'Preemie', 'Small', 'Small (6/7)', 'X-Large', 'X-Large (14-16)', 'X-Small', 'X-Small (4/5)']\n",
    "# Everyday/Dress Jumpsuits\n",
    "# Slacks/Pants\n",
    "# Leggings\n",
    "# Jackets/Coats\n",
    "# Baby Bibs & Burp Cloths\n",
    "# Night Dresses & Shirts\n",
    "# Everyday/Dress Shorts\n",
    "# Non-Brim Hats\n",
    "# Role Playing Toys\n",
    "# Tops\n",
    "\n",
    "\n",
    "# Pajama Pants\n",
    "# Baby Feeding Bottles & Accessories\n",
    "# Cardigans/Kimonos/Wraps\n",
    "# Sweaters\n",
    "# Pantyhose/Tights\n",
    "# Swim Variety Packs\n",
    "# Overalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Overalls=dfs[dfs['buckets'].astype(str)=='Overalls']\n",
    "print(len(Overalls))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Overalls['match']=Overalls['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Overall=Overalls[Overalls['match'].astype(str)!='[]']\n",
    "print(len(Overall))\n",
    "\n",
    "Overall['Q:size']=Overall['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "Overall['Q:size']=Overall['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "Overall['Q:size']=Overall['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "Overall['Q:size']=Overall['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "Overall['Q:size']=Overall['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "Overall['Q:size']=Overall['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "Overall['Q:size']=Overall['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x))).apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r',','\",\"',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r\"'\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "\n",
    "match_Overall=Overall[['external_id','Q:size']]\n",
    "\n",
    "Overall['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Overalls['match']=Overalls['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Overallz=Overalls[Overalls['match'].astype(str)=='[]']\n",
    "print(len(Overallz))\n",
    "\n",
    "Overallz['Q:size']='n/a'\n",
    "match_Overallz_na=Overallz[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Overall-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Overall) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Overallz_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Overallz_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Swim=dfs[dfs['buckets'].astype(str)=='Swim Variety Packs']\n",
    "print(len(Swim))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Swim['match']=Swim['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Swi=Swim[Swim['match'].astype(str)!='[]']\n",
    "print(len(Swi))\n",
    "\n",
    "Swi['Q:size']=Swi['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "Swi['Q:size']=Swi['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "Swi['Q:size']=Swi['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "Swi['Q:size']=Swi['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "Swi['Q:size']=Swi['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "Swi['Q:size']=Swi['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "Swi['Q:size']=Swi['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x))).apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r',','\",\"',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r\"'\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "\n",
    "match_Swi=Swi[['external_id','Q:size']]\n",
    "\n",
    "Swi['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Swim['match']=Swim['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Swis=Swim[Swim['match'].astype(str)=='[]']\n",
    "print(len(Swis))\n",
    "\n",
    "Swis['Q:size']='n/a'\n",
    "match_Swis_na=Swis[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Swi-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Swi) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Swis_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Swis_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sweaters=dfs[dfs['buckets'].astype(str)=='Sweaters']\n",
    "print(len(Sweaters))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Sweaters['match']=Sweaters['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Sweat=Sweaters[Sweaters['match'].astype(str)!='[]']\n",
    "print(len(cardi))\n",
    "\n",
    "Sweat['Q:size']=Sweat['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "Sweat['Q:size']=Sweat['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "Sweat['Q:size']=Sweat['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "Sweat['Q:size']=Sweat['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "Sweat['Q:size']=Sweat['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "Sweat['Q:size']=Sweat['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "Sweat['Q:size']=Sweat['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x))).apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r',','\",\"',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r\"'\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "\n",
    "match_Sweat=Sweat[['external_id','Q:size']]\n",
    "\n",
    "Sweat['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Sweaters['match']=Sweaters['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Sweats=Sweaters[Sweaters['match'].astype(str)=='[]']\n",
    "print(len(cardis))\n",
    "\n",
    "Sweats['Q:size']='n/a'\n",
    "match_Sweats_na=Sweats[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Sweat-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Sweat) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Sweats_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Sweats_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cardigans=dfs[dfs['buckets'].astype(str)=='Cardigans/Kimonos/Wraps']\n",
    "print(len(Cardigans))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Cardigans['match']=Cardigans['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "cardi=Cardigans[Cardigans['match'].astype(str)!='[]']\n",
    "print(len(cardi))\n",
    "\n",
    "cardi['Q:size']=cardi['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "cardi['Q:size']=cardi['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "cardi['Q:size']=cardi['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "cardi['Q:size']=cardi['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "cardi['Q:size']=cardi['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "cardi['Q:size']=cardi['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "cardi['Q:size']=cardi['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x))).apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r',','\",\"',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r\"'\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "\n",
    "match_cardi=cardi[['external_id','Q:size']]\n",
    "\n",
    "cardi['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Cardigans['match']=Cardigans['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "cardis=Cardigans[Cardigans['match'].astype(str)=='[]']\n",
    "print(len(cardis))\n",
    "\n",
    "cardis['Q:size']='n/a'\n",
    "match_cardis_na=cardis[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_cardi-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_cardi) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_cardis_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_cardis_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_feeding_bottles=dfs[dfs['buckets'].astype(str)=='Baby Feeding Bottles & Accessories']\n",
    "print(len(baby_feeding_bottles))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "baby_feeding_bottles['match']=baby_feeding_bottles['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "baby_feeding=baby_feeding_bottles[baby_feeding_bottles['match'].astype(str)!='[]']\n",
    "print(len(baby_feeding))\n",
    "\n",
    "baby_feeding['Q:size']=baby_feeding['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "baby_feeding['Q:size']=baby_feeding['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "baby_feeding['Q:size']=baby_feeding['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "baby_feeding['Q:size']=baby_feeding['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "baby_feeding['Q:size']=baby_feeding['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "baby_feeding['Q:size']=baby_feeding['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "baby_feeding['Q:size']=baby_feeding['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x))).apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r',','\",\"',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r\"'\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "\n",
    "match_baby_feeding=baby_feeding[['external_id','Q:size']]\n",
    "\n",
    "baby_feeding['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "baby_feeding_bottles['match']=baby_feeding_bottles['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "baby_feedings=baby_feeding_bottles[baby_feeding_bottles['match'].astype(str)=='[]']\n",
    "print(len(baby_feedings))\n",
    "\n",
    "baby_feedings['Q:size']='n/a'\n",
    "match_baby_feedings_na=baby_feedings[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_baby_feeding-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_jama) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_baby_feedings_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_baby_feedings_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jama_pants=dfs[dfs['buckets'].astype(str)=='Pajama Pants']\n",
    "print(len(jama_pants))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "jama_pants['match']=jama_pants['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "jama=jama_pants[jama_pants['match'].astype(str)!='[]']\n",
    "print(len(jama))\n",
    "\n",
    "jama['Q:size']=jama['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "jama['Q:size']=jama['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "jama['Q:size']=jama['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "jama['Q:size']=jama['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "jama['Q:size']=jama['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "jama['Q:size']=jama['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "jama['Q:size']=jama['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x))).apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r',','\",\"',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r\"'\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "\n",
    "match_jama=jama[['external_id','Q:size']]\n",
    "\n",
    "jama['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "jama_pants['match']=jama_pants['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "jamas=jama_pants[jama_pants['match'].astype(str)=='[]']\n",
    "print(len(jamas))\n",
    "\n",
    "jamas['Q:size']='n/a'\n",
    "match_jamas_na=jamas[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_jama-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_jama) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_jamas_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_jamas_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops=dfs[dfs['buckets'].astype(str)=='Tops']\n",
    "print(len(tops))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "tops['match']=tops['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "top=tops[tops['match'].astype(str)!='[]']\n",
    "print(len(top))\n",
    "\n",
    "top['Q:size']=top['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "top['Q:size']=top['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "top['Q:size']=top['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "top['Q:size']=top['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "top['Q:size']=top['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "top['Q:size']=top['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "top['Q:size']=top['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x))).apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r',','\",\"',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r\"'\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x)).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "\n",
    "match_top=top[['external_id','Q:size']]\n",
    "\n",
    "top['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "tops['match']=tops['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "top_s=tops[tops['match'].astype(str)=='[]']\n",
    "print(len(top_s))\n",
    "\n",
    "top_s['Q:size']='n/a'\n",
    "match_top_s_na=top_s[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_top-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_top) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_top_s_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_top_s_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_playing_toys=dfs[dfs['buckets'].astype(str)=='Role Playing Toys']\n",
    "print(len(role_playing_toys))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "role_playing_toys['match']=role_playing_toys['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "role_playing=role_playing_toys[role_playing_toys['match'].astype(str)!='[]']\n",
    "print(len(role_playing))\n",
    "\n",
    "role_playing['Q:size']=role_playing['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "role_playing['Q:size']=role_playing['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "role_playing['Q:size']=role_playing['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "role_playing['Q:size']=role_playing['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "role_playing['Q:size']=role_playing['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "role_playing['Q:size']=role_playing['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_role_playing=role_playing[['external_id','Q:size']]\n",
    "\n",
    "role_playing['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "role_playing_toys['match']=role_playing_toys['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "role_playings=role_playing_toys[role_playing_toys['match'].astype(str)=='[]']\n",
    "print(len(role_playings))\n",
    "\n",
    "role_playings['Q:size']='n/a'\n",
    "match_role_playings_na=role_playings[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_role_playing-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_role_playing) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_role_playings_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_role_playings_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_brim_hats=dfs[dfs['buckets'].astype(str)=='Non-Brim Hats']\n",
    "print(len(non_brim_hats))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "non_brim_hats['match']=non_brim_hats['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "non_brim=non_brim_hats[non_brim_hats['match'].astype(str)!='[]']\n",
    "print(len(non_brim))\n",
    "\n",
    "non_brim['Q:size']=non_brim['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "non_brim['Q:size']=non_brim['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "non_brim['Q:size']=non_brim['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "non_brim['Q:size']=non_brim['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "non_brim['Q:size']=non_brim['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "non_brim['Q:size']=non_brim['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_non_brim_short=non_brim[['external_id','Q:size']]\n",
    "\n",
    "non_brim['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "non_brim_hats['match']=non_brim_hats['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "non_brims=non_brim_hats[non_brim_hats['match'].astype(str)=='[]']\n",
    "print(len(non_brims))\n",
    "\n",
    "non_brims['Q:size']='n/a'\n",
    "match_non_brims_na=non_brims[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_non_brim_short-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_non_brim_short) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_non_brims_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_non_brims_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everyday_shortss=dfs[dfs['buckets'].astype(str)=='Everyday/Dress Shorts']\n",
    "print(len(everyday_shortss))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "everyday_shortss['match']=everyday_shortss['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "everyday_short=everyday_shortss[everyday_shortss['match'].astype(str)!='[]']\n",
    "print(len(everyday_short))\n",
    "\n",
    "everyday_short['Q:size']=everyday_short['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "everyday_short['Q:size']=everyday_short['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "everyday_short['Q:size']=everyday_short['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "everyday_short['Q:size']=everyday_short['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "everyday_short['Q:size']=everyday_short['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:2) Months?)\",'0 to 3 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "everyday_short['Q:size']=everyday_short['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_everyday_short=everyday_short[['external_id','Q:size']]\n",
    "\n",
    "everyday_short['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "everyday_shortss['match']=everyday_shortss['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "everyday_shorts=everyday_shortss[everyday_shortss['match'].astype(str)=='[]']\n",
    "print(len(everyday_shorts))\n",
    "\n",
    "everyday_shorts['Q:size']='n/a'\n",
    "match_everyday_shorts_na=everyday_shorts[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_everyday_short-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_everyday_short) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_everyday_shorts_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_everyday_shorts_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "night_dress=dfs[dfs['buckets'].astype(str)=='Night Dresses & Shirts']\n",
    "print(len(night_dress))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "night_dress['match']=night_dress['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "night=night_dress[night_dress['match'].astype(str)!='[]']\n",
    "print(len(night))\n",
    "\n",
    "night['Q:size']=night['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "night['Q:size']=night['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "night['Q:size']=night['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "night['Q:size']=night['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "night['Q:size']=night['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "night['Q:size']=night['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_night=night[['external_id','Q:size']]\n",
    "\n",
    "night['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "night_dress['match']=night_dress['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "nights=night_dress[night_dress['match'].astype(str)=='[]']\n",
    "print(len(nights))\n",
    "\n",
    "nights['Q:size']='n/a'\n",
    "match_nights_na=nights[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_night-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_night) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_nights_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_nights_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babYburp_bib=dfs[dfs['buckets'].astype(str)=='Baby Bibs & Burp Cloths']\n",
    "print(len(babYburp_bib))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "babYburp_bib['match']=babYburp_bib['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "baby=babYburp_bib[babYburp_bib['match'].astype(str)!='[]']\n",
    "print(len(baby))\n",
    "\n",
    "baby['Q:size']=baby['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "baby['Q:size']=baby['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "baby['Q:size']=baby['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "baby['Q:size']=baby['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "baby['Q:size']=baby['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "baby['Q:size']=baby['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_baby=baby[['external_id','Q:size']]\n",
    "\n",
    "baby['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "babYburp_bib['match']=babYburp_bib['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "babys=babYburp_bib[babYburp_bib['match'].astype(str)=='[]']\n",
    "print(len(babys))\n",
    "\n",
    "babys['Q:size']='n/a'\n",
    "match_babys_na=babys[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_baby-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_baby) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_baby-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_baby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jackets_coats=dfs[dfs['buckets'].astype(str)=='Jackets/Coats']\n",
    "print(len(jackets_coats))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "jackets_coats['match']=jackets_coats['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "jack=jackets_coats[jackets_coats['match'].astype(str)!='[]']\n",
    "print(len(jack))\n",
    "\n",
    "jack['Q:size']=jack['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "jack['Q:size']=jack['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "jack['Q:size']=jack['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "jack['Q:size']=jack['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "jack['Q:size']=jack['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "jack['Q:size']=jack['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_jack=jack[['external_id','Q:size']]\n",
    "\n",
    "jack['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "jackets_coats['match']=jackets_coats['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "jacks=jackets_coats[jackets_coats['match'].astype(str)=='[]']\n",
    "print(len(jacks))\n",
    "\n",
    "jacks['Q:size']='n/a'\n",
    "match_jacks_na=jacks[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_jack-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_jack) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_jacks_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_jacks_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Leggings=dfs[dfs['buckets'].astype(str)=='Leggings']\n",
    "print(len(Leggings))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Leggings['match']=Leggings['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "legg=Leggings[Leggings['match'].astype(str)!='[]']\n",
    "print(len(legg))\n",
    "\n",
    "legg['Q:size']=legg['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "legg['Q:size']=legg['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "legg['Q:size']=legg['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "legg['Q:size']=legg['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "legg['Q:size']=legg['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "legg['Q:size']=legg['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_legg=legg[['external_id','Q:size']]\n",
    "\n",
    "legg['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "Leggings['match']=Leggings['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "leggs=Leggings[Leggings['match'].astype(str)=='[]']\n",
    "print(len(leggs))\n",
    "\n",
    "leggs['Q:size']='n/a'\n",
    "match_leggs_na=leggs[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_legg-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_legg) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_leggs_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_leggs_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slacks_pants=dfs[dfs['buckets'].astype(str)=='Slacks/Pants']\n",
    "print(len(slacks_pants))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "slacks_pants['match']=slacks_pants['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "slack=slacks_pants[slacks_pants['match'].astype(str)!='[]']\n",
    "print(len(slack))\n",
    "\n",
    "# jump['match']=jump['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))|((?<!X)XXX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x)))#.apply(lambda x: re.sub(r'( \\(4\\/5\\))','',str(x)))                                                        \n",
    "# jump['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack['Q:size']=slack['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "slack['Q:size']=slack['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "slack['Q:size']=slack['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "slack['Q:size']=slack['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "slack['Q:size']=slack['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "slack['Q:size']=slack['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_slack=slack[['external_id','Q:size']]\n",
    "\n",
    "slack['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "slacks_pants['match']=slacks_pants['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "slacks=slacks_pants[slacks_pants['match'].astype(str)=='[]']\n",
    "print(len(slacks))\n",
    "\n",
    "slacks['Q:size']='n/a'\n",
    "match_slacks_na=slacks[['external_id','Q:size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_slack-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_slack) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_slacks_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_slacks_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumpsuits=dfs[dfs['buckets'].astype(str)=='Everyday/Dress Jumpsuits']\n",
    "print(len(jumpsuits))\n",
    "\n",
    "\n",
    "\n",
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "jumpsuits['match']=jumpsuits['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "jump=jumpsuits[jumpsuits['match'].astype(str)!='[]']\n",
    "print(len(jump))\n",
    "\n",
    "# jump['match']=jump['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))|((?<!X)XXX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x)))#.apply(lambda x: re.sub(r'( \\(4\\/5\\))','',str(x)))                                                        \n",
    "# jump['match'].explode().value_counts()\n",
    "\n",
    "jump['Q:size']=jump['match'].apply(lambda x: re.sub(r'2Y','2T',str(x))).apply(lambda x: re.sub(r'3Y','3T',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "jump['Q:size']=jump['Q:size'].apply(lambda x: re.sub(r'((?:4\\s?(?:to|\\-)\\s?5)\\s?Years?)','[\"4T\",\"5T\"]',str(x))).apply(lambda x: re.sub(r'((?:2\\s?(?:to|\\-)\\s?3)\\s?Years?)','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'4Y','4T',str(x))).apply(lambda x: re.sub(r'5Y','5T',str(x))).apply(lambda x: re.sub(r'6Y','6T',str(x)))\n",
    "jump['Q:size']=jump['Q:size'].apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?6)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:12\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:6\\s?(?:to|\\-)\\s?12)\\s?Months?)','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'((?:0\\s?(?:to|\\-)\\s?24)\\s?Months?)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "jump['Q:size']=jump['Q:size'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(\"\\[)|(\\]\")|(\\s(?=\"))','',str(x)))\n",
    "jump['Q:size']=jump['Q:size'].apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:12) Months?)\",'12 to 18 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:18) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:6) Months?)\",'6 to 9 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:24) Months?)\",'18 to 24 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:9) Months?)\",'9 to 12 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:3) Months?)\",'3 to 6 Months',str(x))).apply(lambda x: re.sub(r\"((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?<!\\d)(?:4) Months?)\",'3 to 6 Months',str(x)))\n",
    "jump['Q:size']=jump['Q:size'].apply(lambda x: re.sub(r'(\\s?to\\s?)|(\\s?\\-\\s?)','-',str(x)))\n",
    "match_jumpsuit=jump[['external_id','Q:size']]\n",
    "\n",
    "jump['Q:size'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?<!to )(?<!\\- )(?<!to)(?<!\\-)(?:\\d+) Months?)|((?:[2-6]T)|Small\\s?\\(6\\/7\\)|Small|Large(?:\\s?\\(10\\-12\\))?|[23]?X\\-Large(?:\\s?\\(14\\-16\\))?|X\\-Small(?:\\s?\\(4\\/5\\))?|Medium(?:\\s?\\(8\\))?|Newborn|One.?Size|Preemie|(?:0\\s?(?:\\-|to)\\s?3|3\\s?(?:\\-|to)\\s?6|6\\s?(?:\\-|to)\\s?9|9\\s?(?:\\-|to)\\s?12|12\\s?(?:\\-|to)\\s?18|18\\s?(?:\\-|to)\\s?24)\\s?Months?)|((?:0\\s?(?:to|\\-)\\s?6|12\\s?(?:to|\\-)\\s?24|6\\s?(?:to|\\-)\\s?12|0\\s?(?:to|\\-)\\s?24)\\s?Months?)|(Infant|Toddler)|(5Y|6Y|4Y|(?:4\\s?(?:to|\\-)\\s?5|2\\s?(?:to|\\-)\\s?3)\\s?Years?)|()'''\n",
    "jumpsuits['match']=jumpsuits['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "jumps=jumpsuits[jumpsuits['match'].astype(str)=='[]']\n",
    "print(len(jumps))\n",
    "\n",
    "jumps['Q:size']='n/a'\n",
    "match_jumps_na=jumps[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_jumpsuit-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_jumpsuit) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_jumps_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_jumps_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "everyday_footwear=dfs[dfs['buckets'].astype(str)=='Everyday/Dress Footwear']\n",
    "print(len(everyday_footwear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everyday_footwear['Q:size']=''\n",
    "match_everyday_footwerar_na=everyday_footwear[['external_id','Q:size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_everyday_footwerar_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_everyday_footwerar_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['2X-Large', '3X-Large', 'Large', 'Medium', 'Small', 'X-Large', 'X-Small']\n",
    "# Socks\n",
    "# Robes\n",
    "# Pet Beds & Cots\n",
    "# Bras\n",
    "# Pet Protective Wear\n",
    "# Accessories Variety Packs\n",
    "\n",
    "\n",
    "\n",
    "# Pet Houses, Crates, & Kennels\n",
    "# Underwear\n",
    "# Braces/Slings/Splints/Supports & Accessories\n",
    "# Arm/Leg Sleeves\n",
    "# Full Brim Hats\n",
    "# Pet Bowls & Feeders\n",
    "# Pet Costumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_costume=dfs[dfs['buckets'].astype(str)=='Pet Costumes']\n",
    "print(len(pet_costume))\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_costume['match']=pet_costume['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pet_cost=pet_costume[pet_costume['match'].astype(str)!='[]']\n",
    "pet_cost['match']=pet_cost['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "pet_cost['Q:size']=pet_cost['match']\n",
    "match_pet_cost=pet_cost[['external_id','Q:size']]\n",
    "\n",
    "pet_cost['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_costume['match']=pet_costume['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pet_costs=pet_costume[pet_costume['match'].astype(str)=='[]']\n",
    "print(len(pet_costs))\n",
    "\n",
    "pet_costs['Q:size']='n/a'\n",
    "match_pet_costs_na=pet_costs[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pet_cost-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pet_cost) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pet_costs_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pet_costs_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_bowl_feeder=dfs[dfs['buckets'].astype(str)=='Pet Bowls & Feeders']\n",
    "print(len(pet_bowl_feeder))\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_bowl_feeder['match']=pet_bowl_feeder['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pet_bowl=pet_bowl_feeder[pet_bowl_feeder['match'].astype(str)!='[]']\n",
    "pet_bowl['match']=pet_bowl['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "pet_bowl['Q:size']=pet_bowl['match']\n",
    "match_pet_bowl=pet_bowl[['external_id','Q:size']]\n",
    "\n",
    "pet_bowl['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_bowl['match']=pet_bowl['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pet_bowls=pet_bowl[pet_bowl['match'].astype(str)=='[]']\n",
    "print(len(pet_bowls))\n",
    "\n",
    "pet_bowls['Q:size']='n/a'\n",
    "match_pet_bowls_na=pet_bowls[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pet_bowl-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pet_bowl) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pet_bowls_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pet_bowls_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_brim_hat=dfs[dfs['buckets'].astype(str)=='Full Brim Hats']\n",
    "print(len(full_brim_hat))\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "full_brim_hat['match']=full_brim_hat['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "full_brim=full_brim_hat[full_brim_hat['match'].astype(str)!='[]']\n",
    "full_brim['match']=full_brim['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "full_brim['Q:size']=full_brim['match']\n",
    "match_full_brim=full_brim[['external_id','Q:size']]\n",
    "\n",
    "full_brim['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "full_brim_hat['match']=full_brim_hat['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "full_brim_hats=full_brim_hat[full_brim_hat['match'].astype(str)=='[]']\n",
    "print(len(full_brim_hats))\n",
    "\n",
    "full_brim_hats['Q:size']='n/a'\n",
    "match_full_brim_hats_na=full_brim_hats[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_full_brim_hats_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_full_brim_hats_na) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_full_brim_hats_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_full_brim_hats_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_leg=dfs[dfs['buckets'].astype(str)=='Arm/Leg Sleeves']\n",
    "print(len(arm_leg))\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "arm_leg['match']=arm_leg['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "arm=arm_leg[arm_leg['match'].astype(str)!='[]']\n",
    "arm['match']=arm['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "arm['Q:size']=arm['match']\n",
    "match_arm=arm[['external_id','Q:size']]\n",
    "\n",
    "arm['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "arm_leg['match']=arm_leg['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "arm_legs=arm_leg[arm_leg['match'].astype(str)=='[]']\n",
    "print(len(arm_legs))\n",
    "\n",
    "arm_legs['Q:size']='n/a'\n",
    "match_arm_legs_na=arm_legs[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return namematch_arm\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_arm-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_arm) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_arm_legs_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_arm_legs_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Braces=dfs[dfs['buckets'].astype(str)=='Braces/Slings/Splints/Supports & Accessories']\n",
    "print(len(Braces))\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "Braces['match']=Braces['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Brace=Braces[Braces['match'].astype(str)!='[]']\n",
    "Brace['match']=Brace['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "Brace['Q:size']=Brace['match']\n",
    "match_Brace=Brace[['external_id','Q:size']]\n",
    "\n",
    "Brace['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "Braces['match']=Braces['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Bracez=Braces[Braces['match'].astype(str)=='[]']\n",
    "print(len(Bracez))\n",
    "\n",
    "Bracez['Q:size']='n/a'\n",
    "match_Bracez_na=Bracez[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Brace-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Brace) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Bracez_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Bracez_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Underwear=dfs[dfs['buckets'].astype(str)=='Underwear']\n",
    "print(len(Underwear))\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "Underwear['match']=Underwear['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Under=Underwear[Underwear['match'].astype(str)!='[]']\n",
    "Under['match']=Under['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "Under['Q:size']=Under['match']\n",
    "match_Under=Under[['external_id','Q:size']]\n",
    "\n",
    "Under['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "Underwear['match']=Underwear['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "Underwears=Underwear[Underwear['match'].astype(str)=='[]']\n",
    "print(len(Underwears))\n",
    "\n",
    "Underwears['Q:size']='n/a'\n",
    "match_Underwears_na=Underwears[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Underwears_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Underwears_na) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_Underwears_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_Underwears_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_houses=dfs[dfs['buckets'].astype(str)=='Pet Houses, Crates, & Kennels']\n",
    "print(len(pet_houses))\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_houses['match']=pet_houses['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pet_house=pet_houses[pet_houses['match'].astype(str)!='[]']\n",
    "pet_house['match']=pet_house['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "pet_house['Q:size']=pet_house['match']\n",
    "match_pet_house=pet_house[['external_id','Q:size']]\n",
    "\n",
    "pet_house['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_houses['match']=pet_houses['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pet_housz=pet_houses[pet_houses['match'].astype(str)=='[]']\n",
    "print(len(pet_housz))\n",
    "\n",
    "pet_housz['Q:size']='n/a'\n",
    "match_pet_housz_na=pet_housz[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pet_house-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pet_house) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pet_housz_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pet_housz_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accesspries=dfs[dfs['buckets'].astype(str)=='Accessories Variety Packs']\n",
    "print(len(accesspries))\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "accesspries['match']=accesspries['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "acc=accesspries[accesspries['match'].astype(str)!='[]']\n",
    "acc['match']=acc['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "acc['Q:size']=acc['match']\n",
    "match_acc=acc[['external_id','Q:size']]\n",
    "\n",
    "acc['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "accesspries['match']=accesspries['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "accs=accesspries[accesspries['match'].astype(str)=='[]']\n",
    "print(len(bras))\n",
    "\n",
    "accs['Q:size']='n/a'\n",
    "match_accs_na=accs[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_acc-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_acc) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_accs_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_accs_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_protective=dfs[dfs['buckets'].astype(str)=='Pet Protective Wear']\n",
    "print(len(pet_protective))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_protective['match']=pet_protective['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pet_prot=pet_protective[pet_protective['match'].astype(str)!='[]']\n",
    "pet_prot['match']=pet_prot['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "pet_prot['Q:size']=pet_prot['match']\n",
    "match_pet_prot=pet_prot[['external_id','Q:size']]\n",
    "\n",
    "pet_prot['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_protective['match']=pet_protective['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pet_prots=pet_protective[pet_protective['match'].astype(str)=='[]']\n",
    "print(len(bras))\n",
    "\n",
    "pet_prots['Q:size']='n/a'\n",
    "match_pet_prots_na=pet_prots[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pet_prot-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pet_prot) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pet_prots_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pet_prots_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bras_df=dfs[dfs['buckets'].astype(str)=='Bras']\n",
    "print(len(Bras_df))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "Bras_df['match']=Bras_df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "bra=Bras_df[Bras_df['match'].astype(str)!='[]']\n",
    "bra['match']=bra['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "bra['Q:size']=bra['match']\n",
    "match_bra=bra[['external_id','Q:size']]\n",
    "\n",
    "bra['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "Bras_df['match']=Bras_df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "bras=Bras_df[Bras_df['match'].astype(str)=='[]']\n",
    "print(len(bras))\n",
    "\n",
    "bras['Q:size']='n/a'\n",
    "match_bras_na=bras[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_bra-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_bra) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_bras_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_bras_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_bed=dfs[dfs['buckets'].astype(str)=='Pet Beds & Cots']\n",
    "print(len(pet_bed))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_bed['match']=pet_bed['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pet=pet_bed[pet_bed['match'].astype(str)!='[]']\n",
    "pet['match']=pet['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "pet['Q:size']=pet['match']\n",
    "match_pet=pet[['external_id','Q:size']]\n",
    "\n",
    "pet['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pet_bed['match']=pet_bed['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pets=pet_bed[pet_bed['match'].astype(str)=='[]']\n",
    "print(len(pets))\n",
    "\n",
    "pets['Q:size']='n/a'\n",
    "match_pets_na=pets[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pet-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pet) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pets_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pets_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robes_df=dfs[dfs['buckets'].astype(str)=='Robes']\n",
    "print(len(robes_df))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "robes_df['match']=robes_df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "robe=robes_df[robes_df['match'].astype(str)!='[]']\n",
    "robe['match']=robe['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "robe['Q:size']=robe['match']\n",
    "match_robe=robe[['external_id','Q:size']]\n",
    "\n",
    "robe['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "robes_df['match']=robes_df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "robes=robes_df[robes_df['match'].astype(str)=='[]']\n",
    "print(len(robes))\n",
    "\n",
    "robes['Q:size']='n/a'\n",
    "match_robes_na=robes[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_robe-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_robe) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_robes_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_robes_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "socks_df=dfs[dfs['buckets'].astype(str)=='Socks']\n",
    "print(len(socks_df))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "socks_df['match']=socks_df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "sock=socks_df[socks_df['match'].astype(str)!='[]']\n",
    "sock['match']=sock['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x))).apply(lambda x: re.sub(r'(\"13W\"\\,)','',str(x)))                                                        \n",
    "sock['Q:size']=sock['match']\n",
    "match_sock=sock[['external_id','Q:size']]\n",
    "\n",
    "sock['match'].explode().value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "socks_df['match']=socks_df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "socks=socks_df[socks_df['match'].astype(str)=='[]']\n",
    "print(len(socks))\n",
    "\n",
    "socks['Q:size']='n/a'\n",
    "match_socks_na=socks[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_sock-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_sock) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_socks_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_socks_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_shirt=dfs[dfs['buckets'].astype(str)=='T-Shirts']\n",
    "print(len(t_shirt))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "t_shirt['match']=t_shirt['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "t=t_shirt[t_shirt['match'].astype(str)!='[]']\n",
    "print(len(t))\n",
    "\n",
    "t['match']=t['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))|((?<!X)XXX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'( \\(4\\/5\\))','',str(x)))                                                        \n",
    "t['Q:size']=t['match']\n",
    "match_t_shirt=t[['external_id','Q:size']]\n",
    "\n",
    "t['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "t_shirt['match']=t_shirt['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "ts=t_shirt[t_shirt['match'].astype(str)=='[]']\n",
    "print(len(ts))\n",
    "\n",
    "ts['Q:size']='n/a'\n",
    "match_ts_na=ts[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_t_shirt-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_t_shirt) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_ts_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_ts_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pajama=dfs[dfs['buckets'].astype(str)=='Pajama Jumpsuits']\n",
    "print(len(pajama))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pajama['match']=pajama['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "paj=pajama[pajama['match'].astype(str)!='[]']\n",
    "print(len(paj))\n",
    "\n",
    "paj['match']=paj['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))|((?<!X)XXX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x)))#.apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "paj['Q:size']=paj['match']\n",
    "match_pajama=paj[['external_id','Q:size']]\n",
    "\n",
    "paj['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pajama=dfs[dfs['buckets'].astype(str)=='Pajama Jumpsuits']\n",
    "print(len(pajama))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "pajama['match']=pajama['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pajs=pajama[pajama['match'].astype(str)=='[]']\n",
    "print(len(paj))\n",
    "\n",
    "pajs['match']=pajs['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))|((?<!X)XXX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x)))#.apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "pajs['match'].explode().value_counts()\n",
    "\n",
    "\n",
    "pajs['Q:size']='n/a'\n",
    "match_pajama_na=pajs[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pajama-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pajama) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_pajama_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_pajama_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everyday=dfs[dfs['buckets'].astype(str)=='Everyday/Dress Bodysuits']\n",
    "print(len(everyday))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "everyday['match']=everyday['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "every=everyday[everyday['match'].astype(str)!='[]']\n",
    "print(len(every))\n",
    "\n",
    "every['match']=every['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))|((?<!X)XXX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x)))#.apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "every['match']=every['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "every['Q:size']=every['match']\n",
    "match_everyday=every[['external_id','Q:size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "everyday['match']=everyday['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "every=everyday[everyday['match'].astype(str)=='[]']\n",
    "print(len(every))\n",
    "\n",
    "every['Q:size']='n/a'\n",
    "match_everyday_na=every[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_everyday-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_everyday) \n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_everyday_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_everyday_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing=dfs[dfs['buckets'].astype(str)=='Clothing Sets & Variety Packs']\n",
    "print(len(clothing))\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "clothing['match']=clothing['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "cloth=clothing[clothing['match'].astype(str)!='[]']\n",
    "cloth['match']=cloth['value'].apply(lambda x: re.sub(r'((?<!X)XX(?!X))','2X',str(x))).apply(lambda x: re.sub(r'((?<!X)XXX(?!X))','3X',str(x))).apply(lambda x: re.sub(r'((?:\"24 Months\"\\,|\"0 to 8 Months\",|\"10\",\"11\",\"12\",))','',str(x)))                                                        \n",
    "cloth['Q:size']=cloth['match']\n",
    "match_clothing=cloth[['external_id','Q:size']]\n",
    "\n",
    "cloth['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:[234]?XX?X?[234]?|[234]).?(?:large|small))|((?:large|medium|small))|()'''\n",
    "clothing['match']=clothing['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "cloth=clothing[clothing['match'].astype(str)=='[]']\n",
    "print(len(cloth))\n",
    "\n",
    "cloth['Q:size']='n/a'\n",
    "match_clothing_na=cloth[['external_id','Q:size']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_clothing-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_clothing) \n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_clothing_na-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_clothing_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?:\\d+\\s?\\-\\s?)?\\d+[^\\w\\;]{0,3}(?:month|year|yr|day|Y(?!\\w)|T(?!\\w)))|(adult)|(infant)|(infant)|(large)|(Medium)|(newborn)|(one.?size)|(pre.?e.?mie)|(youth)|(baby)|(toddler)|(small)|(x{1,3}[^\\w]{0,3}(?:large|small))|((?:\\d+\\.)?\\d+[^\\w]?W(?!\\w))|(size.?\\d+)|()'''\n",
    "pat='''(?i)((?:\\d+\\s?\\-\\s?)?\\d+[^\\w\\;]{0,3}(?:month|year|yr|day|Y(?!\\w)|T(?!\\w)))|()'''\n",
    "\n",
    "df_na=dfs[dfs['value'].astype(str)=='n/a']\n",
    "df_na['m_name']=df_na['product_name'].apply(lambda x: re_extract(pat,str(x)))\n",
    "df_na['m_long']=df_na['long_desc'].apply(lambda x: re_extract(pat,str(x)))\n",
    "df_na['m_custom']=df_na['custom_fields'].apply(lambda x: re_extract(pat,str(x)))\n",
    "\n",
    "set_size_all=df_na[(df_na['m_name'].astype(str)!='[]')|(df_na['m_long'].astype(str)!='[]')|(df_na['m_custom'].astype(str)!='[]')]\n",
    "print(len(set_size_all))\n",
    "set_size_custom=df_na[(df_na['m_custom'].astype(str)!='[]')]\n",
    "print(len(set_size_custom))\n",
    "set_size=df_na[((df_na['m_name'].astype(str)!='[]')|(df_na['m_long'].astype(str)!='[]'))&(df_na['m_custom'].astype(str)!='[]')]\n",
    "print(len(set_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_size_all['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na=set_size_all[set_size_all['value'].astype(str)=='n/a']\n",
    "print(len(na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del na['curated_date']\n",
    "del na['resolution']\n",
    "del na['curation_tasks.curated_by']\n",
    "del na['bucket_id']\n",
    "del na['customer_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def junk(one,regex,na):\n",
    "    pat=f'''(?i){regex}|()'''\n",
    "    na[f'{one}_name']=na['product_name'].apply(lambda x: re_extract(pat,str(x)))\n",
    "    na[f'{one}_long']=na['long_desc'].apply(lambda x: re_extract(pat,str(x)))\n",
    "    na[f'{one}_custom']=na['custom_fields'].apply(lambda x: re_extract(pat,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del na['m_name']\n",
    "del na['m_long']\n",
    "del na['m_custom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:pre.?mie|up.?to.?5.?(?:lb|pound)s?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('premie',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:one.?size(?:.?fits?.?all|.?fits?.?most)?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('one_size',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:new.?born|layette|infant|0\\s?\\-\\s?1\\s?Month|[0123].?month.?old|(?:[0-9]|[1][0-2])\\s?w(?:ee)?ks?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('newborn',pat,na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### 2T ###########################################\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size\\s?(?:2)(?:\\s?\\-\\s?[34])?|24\\s?M(?:onths?)?(?:\\s?\\-\\s?2T)?|2T(?:\\s?\\-\\s?[3456]T)?|24\\s?\\-\\s?36\\s?Months?|toddler|[1234]\\s?years?|[123]\\s?\\-\\s?[234]\\s?Years?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('2T',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size\\s?[23](?:\\s?\\-\\s?[4])?|36\\s?M(?:onths?)?(?:\\s?\\-\\s?3T)?|2T(?:\\s?\\-\\s?[3456]T)?|24\\s?\\-\\s?36\\s?Months?|toddler|[1234]\\s?years?|[123]\\s?\\-\\s?[234]\\s?Years?|3T(?:\\s?\\-\\s?4T)?|3\\s?\\-\\s?4T)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('3T',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size\\s?[4](?:\\s?\\-\\s?[5])?|48\\s?M(?:onths?)?(?:\\s?\\-\\s?4T)?|2T(?:\\s?\\-\\s?[3456]T)?|[4]\\s?years?|[4]\\s?\\-\\s?[456]\\s?Years?|4T(?:\\s?\\-\\s?5T)?|3T(?:\\s?\\-\\s?4T)|3\\s?\\-\\s?4T|[23]\\s?\\-\\s?4\\s?Years?|4\\/6)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('4T',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size\\s?[5]|size\\s?[4]?:\\s?\\-\\s?[5]|60\\s?M(?:onths?)?(?:\\s?\\-\\s?5T)?|2T(?:\\s?\\-\\s?[3456]T)?|[5]\\s?years?|[4]\\s?\\-\\s?[56]\\s?Years?|5T(?:\\s?\\-\\s?6T)?|4T(?:\\s?\\-\\s?5T)|[5]\\s?\\-\\s?6\\s?Years?|[45]\\/6)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('5T',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size\\s?[6]|size\\s?[4]?:\\s?\\-\\s?[6]|72\\s?M(?:onths?)?(?:\\s?\\-\\s?6T)?|2T(?:\\s?\\-\\s?[3456]T)?|[6]\\s?years?|[4]\\s?\\-\\s?[6]\\s?Years?|5T(?:\\s?\\-\\s?6T)?|[5]\\s?\\-\\s?6\\s?Years?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('6T',pat,na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### Large #######################################3\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:(?:2x|(?<!x)xx(?!x)).?Large)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('2x',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:(?:3x|(?<!x)xxx(?!x)).?Large)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('3x',pat,na)\n",
    "\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:large)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('large',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:large|size[^\\w]1[012](?:\\/12)?|10\\/14|1[012][^\\w]years?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('large_ten_twelve',pat,na)\n",
    "\n",
    "\n",
    "#Includes air fryers with a capacity of 3.49QT (quarts) or less\n",
    "# Small_Air_Fryer\n",
    "pat='''(?i)((?:small.?air.?fry|(?:[0-2])(?:\\.\\d+)?(?:QT|quart)|(?:[0-3])(?:\\.[0-4]\\d*)?(?:QT|quart)))|()'''\n",
    "junk('Small_Air_Fryer',pat,na)\n",
    "\n",
    "# Small\n",
    "pat='''(?i)((?:(?<!x[^\\w])(?<!x)small))|()'''\n",
    "junk('Small',pat,na)\n",
    "\n",
    "# Small\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:(?<!x)(?<!x[^\\w])small|(?:5|4|6|7)(?:\\s?\\-\\s?6)?\\s?years?|size[^\\w]?(?:5\\/6|6\\/(?:8|7)|7(?:\\-8)?|6(?:\\-7|\\-6x)|6)|6\\/7)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('Small_6_7',pat,na)\n",
    "\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:(?:(?<!x)(?<!x[^\\w])large\\/)?x[^\\w]?large|size[^\\w]?14(?:\\/16)?|14[^\\w]years?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('xlarge_14',pat,na)\n",
    "\n",
    "\n",
    "# X_Small\n",
    "pat='''(?i)((?:(?<!\\w)X{1}[^\\w]?Small|Size[^\\w](?:4(?:\\s?\\-\\s?5)?|5(?:\\/6)?|4\\/6)|14[^\\w]?Y(?:ears?)?|[45](?:\\s?\\-\\s?[56][^\\w])?\\s?Y(?:ears?)?|4\\/6))|()'''\n",
    "junk('X_Small_14_16',pat,na)\n",
    "\n",
    "# X_Small\n",
    "pat='''(?i)((?:(?<!\\w)X{1}[^\\w]?Small))|()'''\n",
    "junk('X_Small',pat,na)\n",
    "\n",
    "#medium\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:medium|8[^\\w]years?|size[^\\w]?8(?:\\-9|\\/10)?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('medium',pat,na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################## Size ########################################\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?1)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_1',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?2)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_2',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?3)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_3',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?4)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_4',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?5)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_5',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?6)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_6',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?7)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_7',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?8)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_8',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?9)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_9',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?10)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_10',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?11)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_11',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?12)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_12',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:size.?13)(?!\\d)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr))|()'''\n",
    "junk('size_13',pat,na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################### \\d to \\d ###########################################\n",
    "\n",
    "\n",
    "\n",
    "##### Update these #######\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:3(?:[^\\w]?Months?)?(?:\\s?\\-\\s?6)?[^\\w]?Months?|[0-6](?:[^\\w]?Months?)?(?:\\s?\\-\\s?6)[^\\w]?Months?|[3-6][^\\w]?Months?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('3_6_month',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:6(?:[^\\w]?Months?)?(?:\\s?\\-\\s?12)?[^\\w]?Months?|(?:[6-9]|1[0-2])[^\\w]?Months?|[0-9](?:[^\\w]?Months?)?(?:\\s?\\-\\s?12)[^\\w]?Months?|[6-9](?:[^\\w]?Months?)?(?:\\s?\\-\\s?9)[^\\w]?Months?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('6_12_month',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:6(?:[^\\w]?Months?)?(?:\\s?\\-\\s?9)?[^\\w]?Months?|(?:[6-9])[^\\w]?Months?|[0-9](?:\\s?\\-\\s?12)[^\\w]?Months?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('6_9_month',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:9(?:\\s?\\-\\s?12)?[^\\w]?Months?|(?:[9]|1[0-2])[^\\w]?Months?|(?:[0-9]|1[0-2])(?:\\s?\\-\\s?12)[^\\w]?Months?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('9_12_month',pat,na)\n",
    "##### Update these #######\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:(?:[0-9]|1[1-2])\\s?We?e?ks?|[0-3]\\s?M(?:onths?)|0\\s?\\-\\s?(?:(?:[0-9]|1[1-2])\\s?We?e?ks?|[0-3]\\s?M(?:onths?))|infant|new.?born)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('0_3_month',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:(?:(?:[0-9]|[1][1-9]|2[0-4])\\s?We?e?ks?|[0-6]\\s?M(?:onths?))|0\\s?\\-\\s?(?:[0-9]|[1][1-9]|2[0-4])\\s?(?:We?e?ks?)|0\\s?\\-\\s?[0-6]\\s?(?:M(?:onths?))|infant)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('0_6_month',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:(?:4[8-9]|(?:5|6)[0-9]|7[0-2])\\s?We?e?ks?|1[2-8]\\s?M(?:onths?)|0\\s?\\-\\s?(?:(?:4[8-9]|(?:5|6)[0-9]|7[0-2])\\s?We?e?ks?|1[2-8]\\s?M(?:onths?))|1(?:\\.5)?\\s?Y(?:ears?)?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('12_18_month',pat,na)\n",
    "\n",
    "pat='''(?i)((?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?<!\\/)(?<!\\d)(?<!\\.)(?<!\\-)(?<!\\-\\s)(?:(?:7[2-9]|(?:8)[0-9]|9[0-6])\\s?We?e?ks?|(?:1[8-9]|2[0-4])\\s?M(?:onths?)|0\\s?\\-\\s?(?:(?:7[2-9]|(?:8)[0-9]|9[0-6])\\s?We?e?ks?|(?:1[8-9]|2[0-4])\\s?M(?:onths?))|(?:1(?:\\.[5-9])?|2)\\s?Y(?:ears?)?)(?!s)(?!ear)(?!.limited)(?!limited)(?!.manufa)(?!manufa)(?!warr)(?!\\swarr)(?!\\d))|()'''\n",
    "junk('18_24_month',pat,na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing=na[na['buckets'].astype(str)=='Clothing Sets & Variety Packs']\n",
    "print(len(clothing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth=clothing[(clothing['large_name'].astype(str)!='[]')|(clothing['large_long'].astype(str)!='[]')|(clothing['large_custom'].astype(str)!='[]')|(clothing['2x_name'].astype(str)!='[]')|(clothing['2x_long'].astype(str)!='[]')|(clothing['2x_custom'].astype(str)!='[]')|(clothing['2x_custom'].astype(str)!='[]')|(clothing['3x_name'].astype(str)!='[]')|(clothing['3x_long'].astype(str)!='[]')|(clothing['3x_custom'].astype(str)!='[]')|(clothing['Small_name'].astype(str)!='[]')|(clothing['Small_long'].astype(str)!='[]')|(clothing['Small_custom'].astype(str)!='[]')|(clothing['xlarge_14_name'].astype(str)!='[]')|(clothing['xlarge_14_long'].astype(str)!='[]')|(clothing['xlarge_14_custom'].astype(str)!='[]')|(clothing['X_Small_name'].astype(str)!='[]')|(clothing['X_Small_long'].astype(str)!='[]')|(clothing['X_Small_custom'].astype(str)!='[]')|(clothing['medium_name'].astype(str)!='[]')|(clothing['medium_long'].astype(str)!='[]')|(clothing['medium_custom'].astype(str)!='[]')]        \n",
    "print(len(cloth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloths=clothing[(clothing['large_name'].astype(str)=='[]')&(clothing['large_long'].astype(str)=='[]')&(clothing['large_custom'].astype(str)=='[]')&(clothing['2x_name'].astype(str)=='[]')&(clothing['2x_long'].astype(str)=='[]')&(clothing['2x_custom'].astype(str)=='[]')&(clothing['2x_custom'].astype(str)=='[]')&(clothing['3x_name'].astype(str)=='[]')&(clothing['3x_long'].astype(str)=='[]')&(clothing['3x_custom'].astype(str)=='[]')&(clothing['Small_name'].astype(str)=='[]')&(clothing['Small_long'].astype(str)=='[]')&(clothing['Small_custom'].astype(str)=='[]')&(clothing['xlarge_14_name'].astype(str)=='[]')&(clothing['xlarge_14_long'].astype(str)=='[]')&(clothing['xlarge_14_custom'].astype(str)=='[]')&(clothing['X_Small_name'].astype(str)=='[]')&(clothing['X_Small_long'].astype(str)=='[]')&(clothing['X_Small_custom'].astype(str)=='[]')&(clothing['medium_name'].astype(str)=='[]')&(clothing['medium_long'].astype(str)=='[]')&(clothing['medium_custom'].astype(str)=='[]')]        \n",
    "print(len(cloths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth_id=cloths['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "na_cloth=na[~na['external_id'].isin(cloth_id)]\n",
    "print(len(na))\n",
    "print(len(na_cloth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t__shirt=na[na['buckets'].astype(str)=='T-Shirts']\n",
    "print(len(t__shirt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_shirt=t__shirt[(t__shirt['large_name'].astype(str)!='[]')|(t__shirt['large_long'].astype(str)!='[]')|(t__shirt['large_custom'].astype(str)!='[]')|(t__shirt['2x_name'].astype(str)!='[]')|(t__shirt['2x_long'].astype(str)!='[]')|(t__shirt['2x_custom'].astype(str)!='[]')|(t__shirt['2x_custom'].astype(str)!='[]')|(t__shirt['3x_name'].astype(str)!='[]')|(t__shirt['3x_long'].astype(str)!='[]')|(t__shirt['3x_custom'].astype(str)!='[]')|(t__shirt['Small_name'].astype(str)!='[]')|(t__shirt['Small_long'].astype(str)!='[]')|(t__shirt['Small_custom'].astype(str)!='[]')|(t__shirt['xlarge_14_name'].astype(str)!='[]')|(t__shirt['xlarge_14_long'].astype(str)!='[]')|(t__shirt['xlarge_14_custom'].astype(str)!='[]')|(t__shirt['X_Small_name'].astype(str)!='[]')|(t__shirt['X_Small_long'].astype(str)!='[]')|(t__shirt['X_Small_custom'].astype(str)!='[]')|(t__shirt['medium_name'].astype(str)!='[]')|(t__shirt['medium_long'].astype(str)!='[]')|(t__shirt['medium_custom'].astype(str)!='[]')]        \n",
    "print(len(t_shirt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_shirts=t__shirt[(t__shirt['large_name'].astype(str)=='[]')&(t__shirt['large_long'].astype(str)=='[]')&(t__shirt['large_custom'].astype(str)=='[]')&(t__shirt['2x_name'].astype(str)=='[]')&(t__shirt['2x_long'].astype(str)=='[]')&(t__shirt['2x_custom'].astype(str)=='[]')&(t__shirt['2x_custom'].astype(str)=='[]')&(t__shirt['3x_name'].astype(str)=='[]')&(t__shirt['3x_long'].astype(str)=='[]')&(t__shirt['3x_custom'].astype(str)=='[]')&(t__shirt['Small_name'].astype(str)=='[]')&(t__shirt['Small_long'].astype(str)=='[]')&(t__shirt['Small_custom'].astype(str)=='[]')&(t__shirt['xlarge_14_name'].astype(str)=='[]')&(t__shirt['xlarge_14_long'].astype(str)=='[]')&(t__shirt['xlarge_14_custom'].astype(str)=='[]')&(t__shirt['X_Small_name'].astype(str)=='[]')&(t__shirt['X_Small_long'].astype(str)=='[]')&(t__shirt['X_Small_custom'].astype(str)=='[]')&(t__shirt['medium_name'].astype(str)=='[]')&(t__shirt['medium_long'].astype(str)=='[]')&(t__shirt['medium_custom'].astype(str)=='[]')]        \n",
    "print(len(t_shirts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_shirts_id=t_shirts['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "na_cloth_shirt=na_cloth[~na_cloth['external_id'].isin(t_shirts_id)]\n",
    "print(len(na))\n",
    "print(len(na_cloth_shirt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pajama=na[na['buckets'].astype(str)=='Pajama Jumpsuits']\n",
    "print(len(pajama))\n",
    "\n",
    "pajama_j=pajama[(pajama['large_name'].astype(str)!='[]')|(pajama['large_long'].astype(str)!='[]')|(pajama['large_custom'].astype(str)!='[]')|(pajama['2x_name'].astype(str)!='[]')|(pajama['2x_long'].astype(str)!='[]')|(pajama['2x_custom'].astype(str)!='[]')|(pajama['2x_custom'].astype(str)!='[]')|(pajama['3x_name'].astype(str)!='[]')|(pajama['3x_long'].astype(str)!='[]')|(pajama['3x_custom'].astype(str)!='[]')|(pajama['Small_name'].astype(str)!='[]')|(pajama['Small_long'].astype(str)!='[]')|(pajama['Small_custom'].astype(str)!='[]')|(pajama['xlarge_14_name'].astype(str)!='[]')|(pajama['xlarge_14_long'].astype(str)!='[]')|(pajama['xlarge_14_custom'].astype(str)!='[]')|(pajama['X_Small_name'].astype(str)!='[]')|(pajama['X_Small_long'].astype(str)!='[]')|(pajama['X_Small_custom'].astype(str)!='[]')|(pajama['medium_name'].astype(str)!='[]')|(pajama['medium_long'].astype(str)!='[]')|(pajama['medium_custom'].astype(str)!='[]')]        \n",
    "print(len(pajama_j))\n",
    "\n",
    "pajama_js=pajama[(pajama['large_name'].astype(str)=='[]')&(pajama['large_long'].astype(str)=='[]')&(pajama['large_custom'].astype(str)=='[]')&(pajama['2x_name'].astype(str)=='[]')&(pajama['2x_long'].astype(str)=='[]')&(pajama['2x_custom'].astype(str)=='[]')&(pajama['2x_custom'].astype(str)=='[]')&(pajama['3x_name'].astype(str)=='[]')&(pajama['3x_long'].astype(str)=='[]')&(pajama['3x_custom'].astype(str)=='[]')&(pajama['Small_name'].astype(str)=='[]')&(pajama['Small_long'].astype(str)=='[]')&(pajama['Small_custom'].astype(str)=='[]')&(pajama['xlarge_14_name'].astype(str)=='[]')&(pajama['xlarge_14_long'].astype(str)=='[]')&(pajama['xlarge_14_custom'].astype(str)=='[]')&(pajama['X_Small_name'].astype(str)=='[]')&(pajama['X_Small_long'].astype(str)=='[]')&(pajama['X_Small_custom'].astype(str)=='[]')&(pajama['medium_name'].astype(str)=='[]')&(pajama['medium_long'].astype(str)=='[]')&(pajama['medium_custom'].astype(str)=='[]')]        \n",
    "print(len(pajama_js))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pajama_js_id=pajama_js['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "na_cloth_shirt_pajama=na_cloth_shirt[~na_cloth_shirt['external_id'].isin(pajama_js_id)]\n",
    "print(len(na))\n",
    "print(len(na_cloth_shirt_pajama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_cloth_shirt_pajama['Q:size']='[]'\n",
    "match_size_wipe=na_cloth_shirt_pajama[['external_id','Q:size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_size_wipe-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_size_wipe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_shirts_id=t_shirts['external_id'].explode().value_counts().reset_index()['index'].to_list()\n",
    "na_cloth_shirt=na_cloth[~na_cloth['external_id'].isin(t_shirts_id)]\n",
    "print(len(na))\n",
    "print(len(na_cloth_shirt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_value[bucket_value['buckets'].astype(str)=='Pajama Jumpsuits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2002-08-11'\n",
    "attribut='size'\n",
    "curation_col = f'Q:{attribut}'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribut':attribut}\n",
    "\n",
    "print('start')\n",
    "bucket_value = query_from_file(file_name='../query/Bucket_Value_Strategy.sql', params=params)\n",
    "\n",
    "lst=bucket_value['buckets'].explode().value_counts().reset_index()['index'].to_list()#.sort()\n",
    "lst.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(na))\n",
    "buck=na[(na['buckets'].astype(str)!='nan')&(na['buckets'].astype(str)!='[]')&(na['buckets'].astype(str)!='None')]\n",
    "bucks=na[(na['buckets'].astype(str)=='nan')|(na['buckets'].astype(str)=='[]')|(na['buckets'].astype(str)=='None')]\n",
    "print(len(bucks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bucks['Q:size']='[]'\n",
    "# match_buck_wipe=bucks[['external_id','Q:size']]\n",
    "# print(len(match_buck_wipe))\n",
    "\n",
    "\n",
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][0]\n",
    "#     return name\n",
    "# def looks_good(customer, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_buck_wipe-{today}.csv',index=False) \n",
    "# looks_good('Bed Bath & Beyond',match_buck_wipe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=buck['buckets'].explode().value_counts().reset_index()['index'].to_list()\n",
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[]\n",
    "for i in range(len(a)):\n",
    "    c.append(b[i].replace(', & ','_').replace(' & ','_').replace(', ','_').replace('/','_').replace(' ','_').replace('__','_').replace('-','_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c:\n",
    "     exec('{} = pd.DataFrame()'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessories_variety_packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(c)):\n",
    "    c[i]=na[na['attribute']==b[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a)):\n",
    "    c[i]=na[na['buckets'].astype(str)==a[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_list=na['buckets'].explode().value_counts().reset_index()['index'].to_list()\n",
    "bucket_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=[]\n",
    "for i in range(len(bucket_list)):\n",
    "    c.append(bucket_list[i].replace(', & ','_').replace(' & ','_').replace(', ','_').replace('/','_').replace(' ','_').replace('__','_').replace('-','_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dict(list(na.groupby('buckets'))) \n",
    "# then access by name: out['one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bucket_list)):\n",
    "    c[i]=pd.DataFrame(out[bucket_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_one(*args):\n",
    "    for stuff in args:\n",
    "        print(stuff)\n",
    "        \n",
    "my_list=['Honda','BMW','Toyota','Ford','Chevy']\n",
    "arg_one(*my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_three(one,two,*args):\n",
    "    print(one)\n",
    "    print(two)\n",
    "    for stuff in args:\n",
    "        print(stuff)\n",
    "        \n",
    "my_list=['Honda','BMW','Toyota','Ford','Chevy']\n",
    "arg_three('Requirement 1','Requirement 2',*my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "# double stars is for dictionaries\n",
    "def kward_one(**kwards):\n",
    "    for key,value in kwards.items():\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "d_example={'Key1':'value1','key2':'value2','key3':'value3'}\n",
    "kward_one(**d_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kward_two(**kwards):\n",
    "    for key,value in kwards.items():\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "d_example={'Key1':'value1','key2':'value2','key3':'value3'}\n",
    "kward_two(Keye1='Value1e',Keye2='Value2e',Keye3='Value3e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''((?:in[A-z]|in[in\\w]|\\d\"|\\d'|\\d[^']\\]|\\d+\\.\\d\\d\\d)|\\.0(?!\\d)|\\.\\d0|xa|\\\\|\\d\\d\\d\\d|\\d\\.(?!\\d)|(?<!\\d)\\.\\d|  |\\d\"|a-eghj-lo-z)|(\\d\\/\\d)|(i(?!n))|('')|(’)|('\")|(mm)|(\\d\\s?w)|(\\d(?!\\sin)(?!\\d)(?!\\.)(?! ft)(?! ))|(\\-)|(?:â|³)|(\\d\\,\\d)|(\\d\\s\\d+\\s)|((?:IN|In|iN|FT|Ft|fT))|([^0-9inft\\s\"\\]\\[,\\.])|((?<!\\d)0 in)|((?<!\\d)(?<!\\.)0(?!\\.))'''\n",
    "dfs['match']=dfs['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "length=dfs[(dfs['match'].astype(str)!='[]')&(dfs['value'].astype(str)!='n/a')]\n",
    "print(len(dfs))\n",
    "print(len(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dfs['value'].explode().value_counts().reset_index()['index'].to_list()\n",
    "print(len(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length['value'].explode().value_counts()\n",
    "length[length['curated_date'].astype(str)=='2023-01-10']\n",
    "length[curation_col]=''\n",
    "match_length=length[['external_id',curation_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length[curation_col]=length['value'].apply(lambda x: re.sub(r'''()''','',str(x))).apply(lambda x: re.sub(r'''()''','',str(x))).apply(lambda x: re.sub(r'''()''','',str(x))).apply(lambda x: re.sub(r'''()''','',str(x))).apply(lambda x: re.sub(r'''()''','',str(x)))\n",
    "length[curation_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length[curation_col]=''\n",
    "match_length=length[['external_id',curation_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported['Q:origin']=''\n",
    "# match_na_re_curates=imported[['external_id','Q:origin']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_length-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'].explode().value_counts()\n",
    "# print(len(df[df['value'].astype(str)!='n/a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "pat='''(?i)((?<=\\w)(?<!st)(?<!\\d)\\.)'''\n",
    "df['match']=df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "qt=df[df['match'].astype(str)!='[]']\n",
    "print(len(qt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt['value'].explode().value_counts()\n",
    "df[curation_col]=df['value'].apply(lambda x: re.sub(r'(?i)((?<=\\w)(?<!st)(?<!\\d)\\.)','',str(x)))\n",
    "df[curation_col].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match=df[(df['value'].astype(str)!='nan')&(df['value'].astype(str)!='n/a')]\n",
    "match[curation_col].explode().value_counts()\n",
    "match_qt=match[['external_id',curation_col]]\n",
    "match_qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported['Q:origin']=''\n",
    "# match_na_re_curates=imported[['external_id','Q:origin']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_qt-{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_qt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2022-11-01'\n",
    "dateszsz='2022-11-30'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'dateszsz':dateszsz}\n",
    "print('start')\n",
    "# dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_dates.sql', params=params)\n",
    "print(len(dfs))\n",
    "\n",
    "# custom_field_df=pd.json_normalize(dfs['custom_fields'])\n",
    "# df=pd.concat([dfs.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs[dfs['resolution'].astype(str)=='standard']\n",
    "\n",
    "def three(usa,reg):\n",
    "    print('Start')\n",
    "    trip=fr'''(?i){reg}|()''' \n",
    "    \n",
    "    usa['m_name']=usa['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    usa['m_desc']=usa['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    usa['m_custom']=usa['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "    main=usa[(usa['m_name'].astype(str)!='[]')]\n",
    "    middle=usa[(usa['m_name'].astype(str)=='[]')&((usa['m_desc'].astype(str)!='[]')|(usa['m_custom'].astype(str)!='[]'))]\n",
    "    na=usa[(usa['m_name'].astype(str)=='[]')&(usa['m_desc'].astype(str)=='[]')&(usa['m_custom'].astype(str)=='[]')]\n",
    "    \n",
    "    print('')\n",
    "    print('values: '+str(len(main)))\n",
    "    print('No name but call outs: '+str(len(middle)))\n",
    "    print('no values: '+str(len(na)))\n",
    "    print('')\n",
    "    return main,middle,na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not indoor/outdoor, occasion, setsize, size, \n",
    "df=dfs[(dfs['attribute'].astype(str)!='keywords')&(dfs['resolution'].astype(str)!='rules')]\n",
    "print(len(df))\n",
    "df['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets=df[df['attribute'].astype(str)=='drop_length']\n",
    "na=sets[sets['value'].astype(str)=='n/a']\n",
    "print(len(sets))\n",
    "print(len(na))\n",
    "size=sets[sets['value'].astype(str)!='n/a']\n",
    "print(len(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)(drop)'''\n",
    "x,y,z=three(sets,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(z['value'].explode().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(sets[sets['value'].astype(str)!='n/a']))\n",
    "# sets[sets['value'].astype(str)!='n/a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2002-08-11'\n",
    "attribut='shelf_weight_capacity'\n",
    "curation_col = f'Q:{attribut}'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print(len(dfs))\n",
    "dfz=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "print(len(dfz))\n",
    "dfh=dfz[dfz['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "print(len(dfh))\n",
    "custom_field_df=pd.json_normalize(dfh['custom_fields'])\n",
    "df=pd.concat([dfh.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfs))\n",
    "na=df[df['value'].astype(str)=='n/a']\n",
    "print(len(na))\n",
    "df=df[df['value'].astype(str)!='n/a']\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)(\\-)|(and)'''\n",
    "df['match']=df['value'].apply(lambda x: re_extract(pat,str(x)))\n",
    "val=df[(df['match'].astype(str)=='[]')&(df['external_id'].astype(str)!='nan')]\n",
    "val['val']=val['value'].apply(lambda x: re.sub(r'(?i)(\\s?lb)|(\\,)|(\\s?in)|(\\.\\d+)','',str(x)))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "metric='lbs'\n",
    "range_string = \"\"\"\n",
    "100 lbs and Greater\n",
    "1 - 24 lbs\n",
    "25 - 49 lbs\n",
    "50 - 74 lbs\n",
    "75 - 99 lbs\n",
    " \"\"\"\n",
    "\n",
    "range_params = {}\n",
    "for range_entry in range_string.split('\\n'):\n",
    "    range_nums = re.findall('\\d+', range_entry)\n",
    "    if len(range_nums) > 0: \n",
    "        range_params[tuple(map(int, range_nums))] = range_entry.strip()\n",
    "\n",
    "\n",
    "def  range_app(num_lst):\n",
    "    updated_labels = []\n",
    "    for num in num_lst:\n",
    "        num = float(num)\n",
    "        for range_param, range_label in range_params.items():\n",
    "            if len(range_param) == 1:\n",
    "                if num >= range_param[0]:\n",
    "                    updated_labels.append(range_label)\n",
    "            else:\n",
    "                if num >= range_param[0] and num <= range_param[1]:\n",
    "                    updated_labels.append(range_label)\n",
    "    return updated_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val[curation_col]=val['val'].apply(lambda x: f\"['{x}']\").apply(lambda x: re.sub(r'\\[','[\"',str(x))).apply(lambda x: re.sub(r'\\]','\"]',str(x))).apply(lambda x: re.sub(r',','\",\"',str(x))).apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r\"'\",'',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(range_app).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x))).apply(lambda x: re.sub(r'\\,\\s',',',str(x))).apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])) .apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"'\\s?,\\s?'\",'\",\"',str(x))).apply(lambda x: re.sub(r\"'\\[\",'[',str(x))).apply(lambda x: re.sub(r\"\\]'\",']',str(x)))\n",
    "val[['external_id','value',curation_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_shelf=val[['external_id',curation_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_shelf{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_shelf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf=df[df['attribute'].astype(str)=='shelf_weight_capacity']\n",
    "print(len(shelf))\n",
    "na=shelf[shelf['value'].astype(str)=='n/a']\n",
    "print(len(na))\n",
    "val=shelf[shelf['value'].astype(str)!='n/a']\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "care=df[(df['attribute'].astype(str)=='rug_size')]\n",
    "print(len(care))\n",
    "print(len(care[care['value'].astype(str)=='n/a']))\n",
    "# pat='''(.{0,10}(?:\\d\\'\\s?x\\s?\\d+\\'|\\d+\\'\\s?round|\\d+\\'\\s?rug.?runner|\\d+\\'\\s?square|\\d+\\'\\s?runner).{0,10})'''\n",
    "# x,y=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by\n",
    "((?<!\\d)(?:2)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?\\s?x\\s?(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:2)?)|((?:18|24)(?:\\\\?\")?[^\\w]x[^\\w](?:36)(?:\\\\?\")?)|\n",
    "((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:[45])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?)|((?<!\\d)42\\\\?\"\\s?x\\s?66\\\\?\")|\n",
    "((?<!\\d)(?:[7])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:[8])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:1[0-1])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:[7])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:1[0-1])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:[8])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|                      \n",
    "((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6|9)?)|((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|\n",
    "((?<!\\d)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11|7)?)|    \n",
    "((?<!\\d)(?:6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|\n",
    "((?<!\\d)(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|\n",
    "((?<!\\d)(?:10)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|\n",
    "((?<!\\d)(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round\n",
    "((?<!\\d)(?:3)\\'?[^\\w]?x[^\\w]?(?:3)\\'?)|((?:3)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)3'?\\s?[0-7][^\\w]?x[^\\w]?3'?\\s?[0-7])|(3'?\\s?x\\s?(?:round|square))|\n",
    "((?<!\\d)(?:4)\\'?[^\\w]?x[^\\w]?(?:4)\\'?)|((?:4)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)4'?\\s?[0-7][^\\w]?x[^\\w]?4'?\\s?[0-7])|(4'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'4'')|\n",
    "((?<!\\d)(?:5)\\'?[^\\w]?x[^\\w]?(?:5)\\'?)|((?:5)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)5'?\\s?[0-7][^\\w]?x[^\\w]?5'?\\s?[0-7])|(5'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'5'')|\n",
    "((?<!\\d)(?:6)\\'?[^\\w]?x[^\\w]?(?:6)\\'?)|((?:6)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)6'?\\s?[0-7][^\\w]?x[^\\w]?6'?\\s?[0-7])|(6'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'6'')|\n",
    "((?<!\\d)(?:7)\\'?[^\\w]?x[^\\w]?(?:7)\\'?)|((?:7)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)7'?\\s?[0-7][^\\w]?x[^\\w]?7'?\\s?[0-7])|(7'?\\s?x\\s?(?:round|square))(sku.?size\\'\\:\\s?\\'7'')|\n",
    "((?<!\\d)(?:8)\\'?[^\\w]?x[^\\w]?(?:8)\\'?)|((?:8)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)8'?\\s?[0-7][^\\w]?x[^\\w]?8'?\\s?[0-7])|(8'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'8'')|\n",
    "((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'9'')|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner\n",
    "((?<!\\d)(?:4)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:4)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:4)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:5)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:5)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:5)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:6)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:6)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:6)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:7)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:7)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:7)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:8)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:8)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:8)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:9)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:9)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:9)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:10)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:10)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:10)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:11)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:11)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:11)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:12)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:12)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:12)\\'?\\s?(?:2)?)|\n",
    "((?<!\\d)(?:1[3-9])\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:1[3-9])\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:1[3-9])\\'?\\s?(?:2)?)|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N/A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (?i)((?<!\\d)(?:3)\\'?[^\\w]?x[^\\w]?(?:3)\\'?)|((?:3)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)3'?\\s?[0-7][^\\w]?x[^\\w]?3'?\\s?[0-7])|(3'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:4)\\'?[^\\w]?x[^\\w]?(?:4)\\'?)|((?:4)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)4'?\\s?[0-7][^\\w]?x[^\\w]?4'?\\s?[0-7])|(4'?\\s?x\\s?(?:round|square))((?<!\\d)(?:5)\\'?[^\\w]?x[^\\w]?(?:5)\\'?)|((?:5)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)5'?\\s?[0-7][^\\w]?x[^\\w]?5'?\\s?[0-7])|(5'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:6)\\'?[^\\w]?x[^\\w]?(?:6)\\'?)|((?:6)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)6'?\\s?[0-7][^\\w]?x[^\\w]?6'?\\s?[0-7])|(6'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:7)\\'?[^\\w]?x[^\\w]?(?:7)\\'?)|((?:7)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)7'?\\s?[0-7][^\\w]?x[^\\w]?7'?\\s?[0-7])|(7'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:8)\\'?[^\\w]?x[^\\w]?(?:8)\\'?)|((?:8)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)8'?\\s?[0-7][^\\w]?x[^\\w]?8'?\\s?[0-7])|(8'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:2)\\'?(?:\\s)?(?:[0-6])?\\s?x\\s?(?:3)\\'?(?:\\s)?(?:2)?)|((?<!\\d)(?:3)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:[45])\\'?(?:\\s)?(?:6)?)|((?<!\\d)42\\\\?\"\\s?x\\s?66\\\\?\")|((?<!\\d)(?:[7])\\'?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:9)\\'?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:[8])\\'?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:1[0-1])\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:[7])\\'?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:1[0-1])\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:[8])\\'?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:9)\\'?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:5)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)\\'?(?:\\s)?(?:6|9)?)|((?<!\\d)(?:5)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:4)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)\\'?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:3)\\'?(?:\\s)?(?:6)?(?:\\d)?\\s?x\\s?(?:5)\\'?(?:\\s)?(?:6)?)|((?<!\\d)(?:3)\\'?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:5)\\'?(?:\\s)?(?:11|7)?)|((?<!\\d)(?:6)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:5)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)\\'?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:4)\\'?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:7)\\'?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:7)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)\\'?(?:\\s)?(?:0)?)|((?<!\\d)(?:9)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:12|13)\\'?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?:10)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)\\'?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?:12)\\'?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)\\'?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?:4)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:4)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:4)\\'?\\s?(?:2)?)|((?<!\\d)(?:5)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:5)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:5)\\'?\\s?(?:2)?)|((?<!\\d)(?:6)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:6)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:6)\\'?\\s?(?:2)?)|((?<!\\d)(?:7)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:7)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:7)\\'?\\s?(?:2)?)|((?<!\\d)(?:8)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:8)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:8)\\'?\\s?(?:2)?)|((?<!\\d)(?:9)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:9)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:9)\\'?\\s?(?:2)?)|((?<!\\d)(?:10)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:10)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:10)\\'?\\s?(?:2)?)|((?<!\\d)(?:11)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:11)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:11)\\'?\\s?(?:2)?)|((?<!\\d)(?:12)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:12)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:12)\\'?\\s?(?:2)?)|((?<!\\d)(?:1[3-9])\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:1[3-9])\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:1[3-9])\\'?\\s?(?:2)?)   \n",
    "trip=r'''(?i)((?<!\\d)(?:4)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:4)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:4)\\'?\\s?(?:2)?)|((?<!\\d)(?:5)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:5)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:5)\\'?\\s?(?:2)?)|((?<!\\d)(?:6)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:6)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:6)\\'?\\s?(?:2)?)|((?<!\\d)(?:7)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:7)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:7)\\'?\\s?(?:2)?)|((?<!\\d)(?:8)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:8)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:8)\\'?\\s?(?:2)?)|((?<!\\d)(?:9)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:9)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:9)\\'?\\s?(?:2)?)|((?<!\\d)(?:10)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:10)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:10)\\'?\\s?(?:2)?)|((?<!\\d)(?:11)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:11)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:11)\\'?\\s?(?:2)?)|((?<!\\d)(?:12)\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:12)\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:12)\\'?\\s?(?:2)?)|((?<!\\d)(?:1[3-9])\\'\\s?\\d{0,2}\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?:2)\\'?[^\\w]?x[^\\w]?(?:1[3-9])\\'?(?:.{0,10}\\s?[A-z\\/\\s]{0,20}\\s?(?:indoor)?\\s?rug)?)|((?:2)\\'?\\s?(?:7)?[^\\w]?x[^\\w]?(?:1[3-9])\\'?\\s?(?:2)?)|((?<!\\d)(?:3)\\'?[^\\w]?x[^\\w]?(?:3)\\'?)|((?:3)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)3'?\\s?[0-7][^\\w]?x[^\\w]?3'?\\s?[0-7])|(3'?\\s?x\\s?(?:round|square))|((?<!\\d)(?:4)\\'?[^\\w]?x[^\\w]?(?:4)\\'?)|((?:4)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)4'?\\s?[0-7][^\\w]?x[^\\w]?4'?\\s?[0-7])|(4'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'4'')|((?<!\\d)(?:5)\\'?[^\\w]?x[^\\w]?(?:5)\\'?)|((?:5)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)5'?\\s?[0-7][^\\w]?x[^\\w]?5'?\\s?[0-7])|(5'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'5'')|((?<!\\d)(?:6)\\'?[^\\w]?x[^\\w]?(?:6)\\'?)|((?:6)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)6'?\\s?[0-7][^\\w]?x[^\\w]?6'?\\s?[0-7])|(6'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'6'')|((?<!\\d)(?:7)\\'?[^\\w]?x[^\\w]?(?:7)\\'?)|((?:7)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)7'?\\s?[0-7][^\\w]?x[^\\w]?7'?\\s?[0-7])|(7'?\\s?x\\s?(?:round|square))(sku.?size\\'\\:\\s?\\'7'')|((?<!\\d)(?:8)\\'?[^\\w]?x[^\\w]?(?:8)\\'?)|((?:8)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)8'?\\s?[0-7][^\\w]?x[^\\w]?8'?\\s?[0-7])|(8'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'8'')|((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'9'')|((?<!\\d)(?:2)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?\\s?x\\s?(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:2)?)|((?:18|24)(?:\\\\?\")?[^\\w]x[^\\w](?:36)(?:\\\\?\")?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:[45])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?)|((?<!\\d)42\\\\?\"\\s?x\\s?66\\\\?\")|((?<!\\d)(?:[7])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:[8])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:1[0-1])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:[7])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9]|1[0-1])?(?:\\d)?\\s?x\\s?(?:1[0-1])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:[8])(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6|9)?)|((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6)?)|((?<!\\d)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11|7)?)|((?<!\\d)(?:6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)|((?<!\\d)(?:10)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|((?<!\\d)(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)|()'''\n",
    "x,y,na=three(care,trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val=x[x['value'].astype(str)=='n/a']\n",
    "print(len(val))\n",
    "na=y[y['value'].astype(str)!='n/a']\n",
    "print(len(na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na[(na['value'].astype(str)!=\"5' Round/Square\")]['product_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eight_by_ten=care[care['value'].astype(str)==\"4' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\d)(?:2|2\\.25)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?:2|2\\.25)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\d)7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2))?)|((?<!\\.)(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?)?[^\\w]?x[^\\w]?(?<!\\d)(?:2|2\\.25)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|(2\\'\\s?x\\s?7\\')'''                            \n",
    "four_runner,middle,na=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(care[care['value'].astype(str)==\"4' Runner\"]))\n",
    "# print(na['value'].value_counts())\n",
    "print(len(na[(na['value'].astype(str)=='n/a')]))\n",
    "na[(na['value'].astype(str)=='n/a')&((na['m_name'].astype(str)!='''[]''')|(na['m_desc'].astype(str)!='''[]''')|(na['m_custom'].astype(str)!='''[]'''))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(care[care['value'].astype(str)==\"4' Runner\"]))\n",
    "# print(middle['value'].value_counts())\n",
    "# middle[(middle['value'].astype(str)=='n/a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(care[care['value'].astype(str)==\"4' Runner\"]))\n",
    "# print(four_runner['value'].value_counts())\n",
    "# four_runner[(four_runner['value'].astype(str)=='n/a')&(four_runner['value'].astype(str)!='''6' Runner''')]['product_name'].value_counts()\n",
    "# four_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(num_one,num_two):        \n",
    "    pat=fr'''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:{num_one})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:{num_two})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:{num_one})(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:{num_two})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:{num_two}))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:{num_one})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:{num_two})(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:{num_two})|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:{num_two})'?\\s?x\\s?{num_one}\\'?)'''                        \n",
    "    print(pat)\n",
    "\n",
    "run('4','''2|2\\.25|2'?\\s?0\"?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run('4',2)\n",
    "print(\"4' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"4' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:4)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?4\\'?)'''                            \n",
    "four_first,four_mid,four_na=three(care,pat)\n",
    "\n",
    "print(\"5' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"5' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:5)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?5\\'?)'''                            \n",
    "five_first,five_mid,five_na=three(care,pat)\n",
    "\n",
    "print(\"6' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"6' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:6)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?6\\'?)'''                            \n",
    "six_first,six_mid,six_na=three(care,pat)\n",
    "\n",
    "print(\"7' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"7' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:7)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?7\\'?)'''                            \n",
    "seven_first,seven_mid,seven_na=three(care,pat)\n",
    "\n",
    "print(\"8' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"8' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:8)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?8\\'?)'''\n",
    "eight_first,eight_mid,eight_na=three(care,pat)\n",
    "\n",
    "print(\"9' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"9' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:9)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?9\\'?)'''                            \n",
    "nine_first,nine_mid,nine_na=three(care,pat)\n",
    "\n",
    "print(\"10' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"10' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?10\\'?)'''                            \n",
    "ten_first,ten_mid,ten_na=three(care,pat)\n",
    "\n",
    "print(\"11' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"11' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:11)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?11\\'?)'''                            \n",
    "el_first,el_mid,el_na=three(care,pat)\n",
    "\n",
    "print(\"12' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"12' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:12)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?12\\'?)'''                            \n",
    "tw_first,tw_mid,tw_na=three(care,pat)\n",
    "\n",
    "print(\"13' Runner\")\n",
    "eight_by_ten=x[x['value'].astype(str)==\"13' Runner\"]\n",
    "pat='''((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?\\d(0, 2))?\\s?(?:indoor\\/outdoor|hand.?crafted|hand.?woven|rag|Multicolor.?Rag|rug)?\\s?[^\\w]Runner)|((?<!\\.)(?<!\\')(?<!\\' )(?<!\\d)(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|'[^\\w]foot|'\\s?0\"?))?(?:.(0, 10)\\s?[A-z\\/\\s](0, 20)\\s?(?:indoor)?\\s?rug)?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?[^\\w]?x[^\\w]?(?:(?<!\\')(?<!\\' )(?<!\\d)10)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:2|2\\.25|2'?\\s?0\"?))?)|((?<!\\.)(?<!\\')(?<!\\d)(?<!\\' )(?:1[3-9])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:7)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?)?[^\\w]?x[^\\w]?(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)\\s?(?:2|2\\.25|2'?\\s?0\"?)|(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot))?)|((?<!\\.)(?<!\\d)(?<!\\')(?<!\\' )(?:2|2\\.25|2'?\\s?0\"?)'?\\s?x\\s?1[3-9]\\'?)'''                            \n",
    "th_first,th_mid,th_na=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four_mid#['m_name'].explode().value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def un(num_one,num_two,num_three,num_four):\n",
    "    pat=f'''(?i)((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})((?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)\\s?(?:{num_two}))?\\[^\\w\\]?x[^\\w]?(?:{num_three}((?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)\\s?(?:{num_four}))?)|()'''\n",
    "    print(pat)\n",
    "    \n",
    "un(2,'[0-6]',3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2x3\")\n",
    "#un(2,'[0-6]',3,2)\n",
    "eight_by_ten=x[x['value'].astype(str)==\"2' x 3'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9]|1[0-1])?[^\\w]?x[^\\w]?(?:{num_two})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:{num_two})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9]|1[0-1])?[^\\w]?x[^\\w]?(?:{num_two})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:{num_two})(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)'''                            \n",
    "by_tt_first,by_tt_mid,by_tt_na=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_tt_mid['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by_tt_mid[by_tt_mid['value'].astype(str)==\"3' x 5'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2x3\")\n",
    "# good\n",
    "eight_by_ten=x[x['value'].astype(str)==\"2' x 3'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:2)((?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)\\s?(?:[0-6]))?\\s?x\\s?(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot|'\\s?0\"?)?\\s?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:18|24)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:36)(?:\\\\?\\s?\"|\".?inch)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:36)(?:\\\\?\\s?\"|\".?inch)?[^\\w]?x[^\\w]?(?:18|24)(?:\\\\?\"|\"|.?inch)?[^\\w])|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)2\\s?(?:\\'|\\\\?\")?\\s?x\\s?3\\s?(?:\\'|\\\\?\")?)'''                            \n",
    "by_tt_first,by_tt_mid,by_tt_na=three(care,pat)\n",
    "\n",
    "print(\"3x5\")\n",
    "#un(3,'[0-6]','[45]',6)\n",
    "eight_by_ten=x[x['value'].astype(str)==\"3' x 5'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?(?:\\s[0-6])?)?[^\\w]?x[^\\w]?(?:[45])(?:(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s?[0-6])?))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)3\\s?(?:\\'|\\\\?\")?\\s?x\\s?5\\s?(?:\\'|\\\\?\")?)|((?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w]?x[^\\w]?(?:66)(?:\\\\?\\s?\"|\".?inch)?)|([^\\w](?:66)(?:\\\\?\\s?\"|\".?inch)?^\\w]?x[^\\w]?(?:42)(?:\\\\?\\s?\"|\"|.?inch)?[^\\w])'''                            \n",
    "by_tf_first,by_tf_mid,by_tf_na=three(care,pat)\n",
    "\n",
    "print(\"4x6\")\n",
    "# un(4,'[0-6]','5|6','[6-9]')\n",
    "# un(3,'6','5','6')\n",
    "# un(3,'11','5','11|7')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"4' x 6'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:5|6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:6)\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:[6-9|1[0-6]]))|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:3)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11)(?:\\d)?\\s?x\\s?(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?\\s?(?:11|7))'''                            \n",
    "by_fx_first,by_fx_mid,by_fx_na=three(care,pat)\n",
    "\n",
    "\n",
    "# print(\"5x7\")\n",
    "# # un(5,'[0-6]','7','6|9')\n",
    "# eight_by_ten=x[x['value'].astype(str)==\"5' x 8'\"]\n",
    "# pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:6|9)?)'''                            \n",
    "# by_fe_first,by_two_mid,by_two_na=three(care,pat)\n",
    "\n",
    "print(\"5x7\")\n",
    "#un('5','[0-6]','7','0|10')\n",
    "# un('4','11','7','0|10')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"5' x 7'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)|((?<!\\d)(?:4)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:11)?(?:\\d)?\\s?x\\s?(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0|10)?)'''                            \n",
    "by_fs_first,by_fs_mid,by_fs_na=three(care,pat)\n",
    "\n",
    "\n",
    "print(\"5x8\")\n",
    "# un(5,'[0-6]','8','0')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"5' x 8'\"]\n",
    "pat='''((?<!\\d)(?:5)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)'''                            \n",
    "by_fe_first,by_two_mid,by_two_na=three(care,pat)\n",
    "\n",
    "\n",
    "print(\"6x9\")\n",
    "# un(6,'[0-6]','9|8','0')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"6' x 9'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:6)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9|8)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)'''                            \n",
    "by_xn_first,by_xn_mid,by_xn_na=three(care,pat)\n",
    "\n",
    "# print(\"7x9\")\n",
    "# #un('[7]','[6-9]|1[0-1]','9','[6-9]')\n",
    "# # un('[7]','[6-9]|1[0-1]','1[0-1]','0')\n",
    "# eight_by_ten=x[x['value'].astype(str)==\"8' x 10'\"]\n",
    "# pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[7])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9]|1[0-1])?[^\\w]?x[^\\w]?(?:9)(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[7])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9]|1[0-1])?[^\\w]?x[^\\w]?(?:1[0-1])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)'''                                \n",
    "# by_et_first,by_et_mid,by_et_na=three(care,pat)\n",
    "\n",
    "print(\"7x9\")\n",
    "#un('7','[0-6]','9','0')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"7' x 9'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:7)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)'''                            \n",
    "by_sn_first,by_sn_mid,by_sn_na=three(care,pat)\n",
    "\n",
    "print(\"8x10\")\n",
    "# un('[8]','0','1[0-1]','0')\n",
    "# un('[8]','0','9','[6-9]')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"8' x 10'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:1[0-1])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:[8])(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:0)?[^\\w]?x[^\\w]?(?:9)(?:\\\\?\\s?'|\\s?ft\\.?|\\\\?\\s?\"|[^\\w]foot)?\\s?(?:[6-9])?)'''                                \n",
    "by_et_first,by_et_mid,by_et_na=three(care,pat)\n",
    "\n",
    "print(\"9x12\")\n",
    "# un('9','[0-6]','12|13','[0-5]')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"9' x 12'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:9)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:0)?)'''                            \n",
    "by_nt_first,by_nt_mid,by_nt_na=three(care,pat)\n",
    "\n",
    "print(\"10x14\")\n",
    "#un('10','[0-6]','14|13','[0-5]')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"10' x 14'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:10)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:14|13)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)'''                            \n",
    "by_tfou_first,by_tfou_mid,by_tfou_na=three(care,pat)\n",
    "\n",
    "print(\"12x15\")\n",
    "#un('12','[0-6]','15','[0-5]')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"12' x 15'\"]\n",
    "pat='''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:12)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-6])?(?:\\d)?\\s?x\\s?(?:15)(?:\\\\?'|\\s?ft\\.?|\\\\?\"|[^\\w]foot)?(?:\\s)?(?:[0-5])?)'''                            \n",
    "by_twfif_first,by_twfif_mid,by_twfif_na=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_tfou_first['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_et_first[by_et_first['value'].astype(str)==\"3' x 5'\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round/Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roun(num_one,num_two):\n",
    "    pat=f'''((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})\\s?\\'?[^\\w]?x[^\\w]?(?:{num_one})\\s?\\'?)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})\\s?\\'?\\s?(?:{num_two})?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})\\s?\\'?\\s?{num_two}[^\\w]?x[^\\w]?(?:{num_one})\\s?'?\\s?{num_two})|((?<!\\d)(?<!\\')(?<!'\\s)(?<!\\.)(?:{num_one})\\s?'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'(?:{num_one})'')|(SKU_SIZE[^\\w]{0,4}(?:{num_one})\\s?\\'?(?:{num_two})?\"?\\s?(?:round|square)'''       \n",
    "    print(pat)\n",
    "    \n",
    "roun(8,'[0-7]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('three')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"3' Round/Square\"]\n",
    "pat='''(?i)((?<!\\d)(?:3)\\'?[^\\w]?x[^\\w]?(?:3)\\'?)|((?:3)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)3'?\\s?[0-7][^\\w]?x[^\\w]?3'?\\s?[0-7])|(3'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'3'')|()'''                            \n",
    "three_round,na_three=three(eight_by_ten,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('three')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"3' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?[^\\w]?x[^\\w]?(?:3)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:3)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:3)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:3)'')|(SKU_SIZE[^\\w](0, 4)(?:3)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "three_round_first,three_round_mid,na_three=three(care,pat)\n",
    "\n",
    "print('four')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"4' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?[^\\w]?x[^\\w]?(?:4)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:4)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:4)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:4)'')|(SKU_SIZE[^\\w](0, 4)(?:4)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "four_round,four_round_mid,na_four=three(care,pat)\n",
    "\n",
    "print('five')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"5' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?[^\\w]?x[^\\w]?(?:5)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:5)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:5)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:5)'')|(SKU_SIZE[^\\w](0, 4)(?:5)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "five_round,five_round_mid,na_five=three(care,pat)\n",
    "\n",
    "print('six')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"6' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?[^\\w]?x[^\\w]?(?:6)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:6)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:6)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:6)'')|(SKU_SIZE[^\\w](0, 4)(?:6)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "six_round,six_round_mid,na_six=three(care,pat)\n",
    "\n",
    "print('seven')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"7' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?[^\\w]?x[^\\w]?(?:7)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:7)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:7)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:7)'')|(SKU_SIZE[^\\w](0, 4)(?:7)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "seven_round,seven_round_mid,na_seven=three(care,pat)\n",
    "\n",
    "print('eight')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"8' Round/Square\"]\n",
    "pat='''((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?[^\\w]?x[^\\w]?(?:8)\\s?'?)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?[0-7][^\\w]?x[^\\w]?(?:8)\\s?'?\\s?[0-7])|((?<!\\d)(?<!')(?<!'\\s)(?<!\\.)(?:8)\\s?'?\\s?x\\s?(?:round|square))|(sku.?size'\\:\\s?'(?:8)'')|(SKU_SIZE[^\\w](0, 4)(?:8)\\s?'?(?:[0-7])?\"?\\s?(?:round|square))'''                            \n",
    "eight_round,eight_round_mid,na_eight=three(care,pat)\n",
    "\n",
    "print('nine')\n",
    "eight_by_ten=x[x['value'].astype(str)==\"9' Round/Square\"]\n",
    "pat='''((?<!\\d)(?:9)\\'?[^\\w]?x[^\\w]?(?:9)\\'?)|((?:9)\\'?\\s?(?:[0-7])?[^\\w]?(?:\\s?half\\s?)?round)|((?<!\\d)9'?\\s?[0-7][^\\w]?x[^\\w]?9'?\\s?[0-7])|(9'?\\s?x\\s?(?:round|square))|(sku.?size\\'\\:\\s?\\'9'')'''                            \n",
    "nine_round,nine_round_mid,na_nine=three(care,pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin=df[df['attribute'].astype(str)=='origin']\n",
    "print(len(origin))\n",
    "origin['curated_date']=pd.to_datetime(origin['curated_date'])\n",
    "no=origin[(origin['curated_date']>='11-01-2022')&(origin['curated_date']<='11-30-2022')]\n",
    "nov=no[no['resolution'].astype(str)=='standard']\n",
    "print(len(nov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(n\\/a)|()''' \n",
    "nov['values']=nov['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "mach=nov[nov['values'].astype(str)!='[]']\n",
    "print(len(mach))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=three(mach,'''(\\b(?:united.?states|united.?states.?of.?america|USA(?!.glass)(?!opoly)|AMerica|made.?in.?(?:us|u\\.s\\.))\\b)|(imported)|(made.?in.?(?:canada|turkey|china|france|india|germany|italy|the.?uk|poland|malaysia|belgium|vienna|pakistan))|(.{0,10}(?<!hand.)(?<!hand)made(?!.for)(?!.out)(?!.by)(?!.of)(?!.with)(?!.from).{0,10})|(.{0,10}\\busa(?!.glass)\\b.{0,10})''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=nov[nov['value'].astype(str)=='Imported']\n",
    "print(len(imp))\n",
    "na=nov[nov['value'].astype(str)=='n/a']\n",
    "print(len(na))\n",
    "usa=nov[nov['value'].astype(str)=='Made in the USA']\n",
    "print(len(usa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nov['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip=r'''(?i)(imported)|(made in Canada)|(euro.?sham)|(made.?in)|()''' \n",
    "trip=r'''(?i)(\\b(?:united.?states|united.?states.?of.?america|USA(?!.glass)(?!opoly)|AMerica|made.?in.?(?:us|u\\.s\\.))\\b)|(imported)|(made.?in.?(?:canada|turkey|china|france|india|germany|italy|the.?uk|poland|malaysia|belgium|vienna|pakistan))|(.{0,10}(?<!hand.)(?<!hand)made(?!.for)(?!.out)(?!.by)(?!.of)(?!.with)(?!.from).{0,10})|(.{0,10}\\busa(?!.glass)\\b.{0,10})|()''' \n",
    "usa['m_name']=usa['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "usa['m_desc']=usa['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "usa['m_custom']=usa['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "imported=usa[(usa['m_name'].astype(str)!='[]')|(usa['m_desc'].astype(str)!='[]')|(usa['m_custom'].astype(str)!='[]')]\n",
    "print(len(imported))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported#[['external_id','m_name','m_desc','m_custom']][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impor=na[(na['m_name'].astype(str)=='[]')&(na['m_desc'].astype(str)=='[]')&(na['m_custom'].astype(str)=='[]')]\n",
    "print(len(impor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impor['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trip=r'''(?i)((.{0,10}(?<!hand.)(?<!hand)made(?!.for)(?!.out)(?!.by)(?!.of)(?!.with)(?!.from).{0,10})|(.{0,10}\\busa(?!.glass)\\b.{0,10}))|()''' \n",
    "impor['m_name']=impor['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print('one')\n",
    "impor['m_desc']=impor['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print('two')\n",
    "impor['m_custom']=impor['custom_fields'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print('three')\n",
    "im=impor[(impor['m_name'].astype(str)!='[]')|(impor['m_desc'].astype(str)!='[]')|(impor['m_custom'].astype(str)!='[]')]\n",
    "print(len(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(im))\n",
    "im[['external_id','m_name','m_desc','m_custom']][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported['Q:origin']=''\n",
    "match_na_re_curates=imported[['external_id','Q:origin']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_na_re_curates{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_na_re_curates) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na=dfs[(dfs['attribute'].astype(str)=='nan')|(dfs['attribute'].astype(str)=='None')]\n",
    "print(len(na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2022-08-11'\n",
    "attribut='size'\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs,\n",
    "         'attribute':attribut}\n",
    "print('start')\n",
    "dfs = query_from_file(file_name='../query/curated_all_attributes_date_one_attribute.sql', params=params)\n",
    "print('continuing')\n",
    "dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "print('dfs')\n",
    "dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "print('customs')\n",
    "custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "df=pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material=df[['attribute','buckets','value','external_id','product_name','long_desc','LONG_DESCRIPTION','gbi_exp_product_type','gbi_syn_product_type','gbi_syn_size','gbi_product_type_affinity','Fill_Material','s_f_Fill_Material','s_f_binFill_Material']]\n",
    "print(len(material))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=\"(?i)(duvet)|()\"\n",
    "material['d']=material['gbi_exp_product_type'].apply(lambda x: re_extract(trips,str(x)))\n",
    "material['u']=material['gbi_syn_product_type'].apply(lambda x: re_extract(trips,str(x)))\n",
    "material['v']=material['gbi_syn_size'].apply(lambda x: re_extract(trips,str(x)))\n",
    "material['match']=material['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "material['matches']=material['LONG_DESCRIPTION'].apply(lambda x: re_extract(trips,str(x)))\n",
    "\n",
    "\n",
    "duvet=material[(material['d'].astype(str)!='[]')|(material['u'].astype(str)!='[]')|(material['v'].astype(str)!='[]')|(material['match'].astype(str)!='[]')|(material['matches'].astype(str)!='[]')]\n",
    "print(len(duvet))\n",
    "print(duvet['buckets'].explode().value_counts().reset_index()['index'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del duvet['d']\n",
    "del duvet['u']\n",
    "del duvet['v']\n",
    "# del duvet['e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill=duvet[(duvet['external_id'].astype(str)!='nan')&((duvet['Fill_Material'].astype(str)!='nan')|(duvet['s_f_Fill_Material'].astype(str)!='nan')|(duvet['s_f_binFill_Material'].astype(str)!='nan'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=\"(?i)(.{0,10}fill.?material.{0,10})|()\"\n",
    "duvet['fill']=duvet['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "duvet['fills']=duvet['LONG_DESCRIPTION'].apply(lambda x: re_extract(trips,str(x)))\n",
    "x=duvet[(duvet['fill'].astype(str)!='[]')|(duvet['fills'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=\"(?i)(.{0,10}(?:duvet).{0,10})|()\"\n",
    "mat['match']=mat['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "mat['matches']=mat['product_name'].apply(lambda x: re_extract(trips,str(x)))\n",
    "duvet=mat[(mat['match'].astype(str)!='[]')|(mat['matches'].astype(str)!='[]')]\n",
    "duvet=duvet[duvet['value'].astype(str)=='n/a']\n",
    "print(len(duvet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_id = '5'\n",
    "# customer_name='%bedbathandbeyond%'\n",
    "# dateszs='2022-08-11'\n",
    "# params = {'customer_id': customer_id,\n",
    "#           'customer_name':customer_name,\n",
    "#          'dateszs':dateszs}\n",
    "# print('start')\n",
    "# dfs = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "# print('continuing')\n",
    "# dfs=dfs[dfs['resolution'].astype(str)!='rules']\n",
    "# print('dfs')\n",
    "# dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# print('customs')\n",
    "# custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# # dfz=dfs[dfs['custom_fields'].astype(str)!='None']\n",
    "# # # dfz=dfz[dfz['buckets'].astype(str)=='Conduit Fittings, Replacement Parts, & Accessories']\n",
    "# # custom_field_df=pd.json_normalize(dfz['custom_fields'])\n",
    "# # fields = ['Set_Size']\n",
    "# # df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "# # print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips=\"(?i)(.{0,10}(?:comforter|duvet|sheets).{0,10})|()\"\n",
    "df['match']=df['long_desc'].apply(lambda x: re_extract(trips,str(x)))\n",
    "df['matches']=df['product_name'].apply(lambda x: re_extract(trips,str(x)))\n",
    "duvet=df[(df['match'].astype(str)!='[]')|(df['matches'].astype(str)!='[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(duvet))\n",
    "duvet_na=duvet[duvet['value'].astype(str)=='n/a']\n",
    "print(len(duvet_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=duvet_na[(duvet_na['Fill_Material'].astype(str)!='nan')|(duvet_na['s_f_Fill_Material'].astype(str)!='nan')|(duvet_na['s_f_binFill_Material'].astype(str)!='nan')|(duvet_na['s_f_binMaterial'].astype(str)!='nan')]\n",
    "print(len(x))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Fill_Material','s_f_Fill_Material','s_f_binFill_Material','s_f_binMaterial']\n",
    "df = pd.concat([dfz.drop('custom_fields', axis=1), custom_field_df[fields]], axis = 1)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill=df[(df['Fill_Material'].astype(str)!='nan')&(df['s_f_Fill_Material'].astype(str)=='nan')&(df['s_f_binFill_Material'].astype(str)=='nan')&(df['s_f_binMaterial'].astype(str)=='nan')]\n",
    "print(len(fill))\n",
    "\n",
    "fills=df[(df['Fill_Material'].astype(str)=='nan')&(df['s_f_Fill_Material'].astype(str)!='nan')&(df['s_f_binFill_Material'].astype(str)=='nan')&(df['s_f_binMaterial'].astype(str)=='nan')]\n",
    "print(len(fills))\n",
    "\n",
    "fillz=df[(df['Fill_Material'].astype(str)=='nan')&(df['s_f_Fill_Material'].astype(str)=='nan')&(df['s_f_binFill_Material'].astype(str)!='nan')&(df['s_f_binMaterial'].astype(str)=='nan')]\n",
    "print(len(fillz))\n",
    "\n",
    "filling=df[(df['Fill_Material'].astype(str)=='nan')&(df['s_f_Fill_Material'].astype(str)=='nan')&(df['s_f_binFill_Material'].astype(str)=='nan')&(df['s_f_binMaterial'].astype(str)!='nan')]\n",
    "print(len(filling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillings=df[((df['Fill_Material'].astype(str)!='nan')|(df['s_f_Fill_Material'].astype(str)!='nan')|(df['s_f_binFill_Material'].astype(str)!='nan'))&(df['s_f_binMaterial'].astype(str)=='nan')&(df['external_id'].astype(str)!='nan')]\n",
    "# print(len(fillings))\n",
    "# fillings\n",
    "# filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling['buckets'].explode().value_counts()\n",
    "# x=filling[filling['buckets'].astype(str)!='nan']\n",
    "# print(len(x))\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(?i)(.{0,20}duvet.{0,20})|(.{0,20}fill.{0,20})|()'''                                                              \n",
    "fill['matches']=fill['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "duvet=fill[fill['matches'].astype(str)!='[]']\n",
    "duvet#[duvet['s_f_binMaterial'].astype(str)=='''['Cotton Blend']''']\n",
    "print(len(duvet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duvet[duvet['value'].astype(str)=='n/a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_material=df[(df['attribute'].astype(str)=='fill_material')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_materials=fill_material[(fill_material['Fill_Material'].astype(str)!='nan')|(fill_material['s_f_Fill_Material'].astype(str)!='nan')|(fill_material['s_f_binFill_Material'].astype(str)!='nan')|(fill_material['s_f_binMaterial'].astype(str)!='nan')|(fill_material['Fill_Material'].astype(str)!='nan')]\n",
    "# del fill_materials ['buckets']\n",
    "# del fill_materials ['bucket_id']\n",
    "del fill_materials ['customer_name']\n",
    "del fill_materials ['curated_date']\n",
    "del fill_materials ['resolution']\n",
    "del fill_materials ['curation_tasks.curated_by']\n",
    "\n",
    "fill_materials#['value'].explode().value_counts()\n",
    "\n",
    "trip=r'''(?i)(duvet)|()'''                                                              \n",
    "fill_materials['matches']=fill_materials['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "duvet=fill_materials[fill_materials['matches'].astype(str)!='[]']\n",
    "duvet#[duvet['s_f_binMaterial'].astype(str)=='''['Cotton Blend']''']\n",
    "\n",
    "duvets=duvet[(duvet['s_f_binMaterial'].astype(str)!='nan')&(duvet['s_f_binMaterial'].astype(str)!=\"['Other']\")&(duvet['s_f_binMaterial'].astype(str)!=\"['Modal']\")&(duvet['s_f_binMaterial'].astype(str)!=\"['Cotton Blend']\")]\n",
    "duvets['Q:fill_material']=duvets['s_f_binMaterial']\n",
    "\n",
    "match_duvets=duvets[['external_id','Q:fill_material']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/Bed Bath & Beyond --{get_df_name(matches)}-match_duvets{today}.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond',match_duvets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

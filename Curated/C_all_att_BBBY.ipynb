{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "from ftfy import fix_text\n",
    "# from util import UnitConversion, mapping_list_values, perl_to_posix\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_rows = 500\n",
    "from flashtext import KeywordProcessor\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from natsort import natsorted\n",
    "def query_from_file(file_name, params):\n",
    "    with open(f'{file_name}', mode='r') as f:\n",
    "        text = f.read()\n",
    "        query = text.format(**params)\n",
    "        return enrich_db(query)\n",
    "def re_extract(pattern, txt):\n",
    "    matches = re.findall(pattern, txt)\n",
    "    tmp_matches = []\n",
    "    for match in matches:\n",
    "        for tup in match:\n",
    "            if tup != '':\n",
    "                tmp_matches.append(tup)\n",
    "    return list(set(tmp_matches))\n",
    "\n",
    "# from enrich_dimensions.rounds import rounds, rounding, re_extract, curate, round_string_float, clean_data,reg_ex     \n",
    "# from enrich_dimensions.params import parameters, query_from_file\n",
    "# from enrich_dimensions.query_file import query_from_file \n",
    "# from enrich_dimensions.custom import custom_field "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBBY All Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94398\n"
     ]
    }
   ],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2022-06-20'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "bbby = query_from_file(file_name='../query/curated_all_attributes_all_customers_brackets.sql', params=params)\n",
    "print(len(bbby))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_06_21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>external_id</th>\n",
       "      <th>Curated Date</th>\n",
       "      <th>Updated Date</th>\n",
       "      <th>match</th>\n",
       "      <th>matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [value, customer_name, external_id, Curated Date, Updated Date, match, matches]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "today = time.strftime(\"%Y_%m_%d\")\n",
    "print(today)\n",
    "\n",
    "wbm=bbby\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['external_id'].explode().value_counts()\n",
    "bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12502889\n"
     ]
    }
   ],
   "source": [
    "customer_id = '5'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "dateszs='2001-02-05'\n",
    "\n",
    "params = {'customer_id': customer_id,\n",
    "          'customer_name':customer_name,\n",
    "         'dateszs':dateszs}\n",
    "bbby = query_from_file(file_name='../query/curated_all_attributes_date.sql', params=params)\n",
    "print(len(bbby))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "height    4\n",
       "depth     2\n",
       "Name: attribute, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbm=bbby\n",
    "trip=r'''(?i)(\\{)|(\\})|()'''                                                              \n",
    "wbm['match']=wbm['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "bracket=wbm[wbm['match'].astype(str)!='[]']#['value'].explode().value_counts()[0:500]\n",
    "bracket['matches']=bracket['value'].apply(lambda x: re.sub(r'\\{','[',str(x))).apply(lambda x: re.sub(r'\\}',']',str(x)))\n",
    "bracket['attribute'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=bracket[bracket['attribute'].astype(str)=='width']\n",
    "depth=bracket[bracket['attribute'].astype(str)=='depth']\n",
    "diameter=bracket[bracket['attribute'].astype(str)=='diameter']\n",
    "height=bracket[bracket['attribute'].astype(str)=='height']\n",
    "length=bracket[bracket['attribute'].astype(str)=='length']\n",
    "cookware_size=bracket[bracket['attribute'].astype(str)=='cookware_size']\n",
    "\n",
    "height['Q:height']=height['matches']\n",
    "width['Q:width']=width['matches']\n",
    "depth['Q:depth']=depth['matches']\n",
    "diameter['Q:diameter']=diameter['matches']\n",
    "length['Q:length']=length['matches']\n",
    "cookware_size['Q:cookware_size']=cookware_size['matches']\n",
    "\n",
    "match_height=height[['external_id','Q:height']]\n",
    "match_width=width[['external_id','Q:width']]\n",
    "match_depth=depth[['external_id','Q:depth']]\n",
    "match_diameter=diameter[['external_id','Q:diameter']]\n",
    "match_length=length[['external_id','Q:length']]\n",
    "match_cookware_size=cookware_size[['external_id','Q:cookware_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "def looks_good(customer, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}_bracket.csv',index=False) \n",
    "looks_good('Bed Bath & Beyond', match_height) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n"
     ]
    }
   ],
   "source": [
    "car_seat=df[df['attribute'].astype(str)=='infant_car_seat_brand_model_compatibility']\n",
    "trip=r'''(?i)(Graco)|(Nuna.?turtle)|(Chicco)|(UPPAbaby)|()'''                                                              \n",
    "car_seat['match']=car_seat['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "car_seat['matches']=car_seat['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "x=car_seat[(car_seat['match'].astype(str)!='[]')|(car_seat['matches'].astype(str)!='[]')]\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70259\n"
     ]
    }
   ],
   "source": [
    "size=df[df['attribute'].astype(str)=='size']\n",
    "print(len(size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "size['buckets'].explode().value_counts().reset_index().rename(columns={'index':'Buckets','buckets':'Number of SKUs'}).to_csv('size_bucket_numbers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size[size['value'].astype(str)=='0 to 12 Months']['buckets'].explode().value_counts()\n",
    "\n",
    "size[size['value'].astype(str)=='0 to 24 Months']['buckets'].explode().value_counts()\n",
    "\n",
    "size[size['value'].astype(str)=='0 to 3 Years']['buckets'].explode().value_counts()\n",
    "\n",
    "size[size['value'].astype(str)=='0 to 4 Years']['buckets'].explode().value_counts()\n",
    "\n",
    "size[size['value'].astype(str)=='12 to 36 Months']['buckets'].explode().value_counts()\n",
    "\n",
    "size[size['value'].astype(str)=='0 to 24 Months']['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A\n",
    "\n",
    "size['clean']=size['value'].apply(lambda x: re.sub(r'\"\\\\\"','',str(x))).apply(lambda x: re.sub(r'(?<=)\\s?\\-\\s?(?=\\d)',' to ',str(x)))\n",
    "size['cleans']=size['clean'].apply(lambda x: f'[\"{x}\"]')\n",
    "size['cleans']=size['cleans'].apply(lambda x: re.sub(r'\"?\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\\[\"\\[\"?','[\"',str(x))).apply(lambda x: re.sub(r'\"\\,(?!\")','\",\"',str(x)))\n",
    "size['match']=size['cleans'].apply(lambda x: re.sub(r'(?<!\\d)(?:0 to )?3 Months','0 to 3 Months',str(x))).apply(lambda x: re.sub(r'(?<!to )(?<!\\d)6 Months','3 to 6 Months',str(x))).apply(lambda x: re.sub(r'0 to 4 Months','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'(?<!to )(18 Months?)','12 to 18 Months',str(x)))\n",
    "size['match']=size['match'].apply(lambda x: re.sub(r'(?<!to )(?:9|10|11|12) Months','[\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'(0 to [789] Months)','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\"]',str(x))).apply(lambda x: re.sub(r'(?<!\\d)(?<!to )[456] Months','[\"3 to 6 Months\"]',str(x))).apply(lambda x: re.sub(r'0 to 6 Months','[\"0 to 3 Months\",\"3 to 6 Months\"]',str(x)))\n",
    "size['match']=size['match'].apply(lambda x: re.sub(r'0 to 12 Months','[\"0 to 3 Months\",\"3 to 6 Months\",\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'12 to 24 months','[\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "size['match']=size['match'].apply(lambda x: re.sub(r'(?<!to )24 months','18 to 24 Months',str(x))).apply(lambda x: re.sub(r'6 to 12 Months','[\"6 to 9 Months\",\"9 to 12 Months\"]',str(x))).apply(lambda x: re.sub(r'6 to 24 Months','[\"6 to 9 Months\",\"9 to 12 Months\",\"12 to 18 Months\",\"18 to 24 Months\"]',str(x)))\n",
    "size['match']=size['match'].apply(lambda x: re.sub(r'12 to 36 months','[\"12 to 18 Months\",\"18 to 24 Months\",\"2 to 3 Years\"]',str(x)))\n",
    "\n",
    "size['match']=size['match'].apply(lambda x: re.sub(r'(?<!\\d)1(?:Y|T)','1 Years',str(x))).apply(lambda x: re.sub(r'(?<!\\d)2(?:Y|T)','2 Years',str(x))).apply(lambda x: re.sub(r'(?<!\\d)3(?:Y|T)','3 Years',str(x))).apply(lambda x: re.sub(r'(?<!\\d)4(?:Y|T)','4 Years',str(x))).apply(lambda x: re.sub(r'(?<!\\d)5(?:Y|T)','5 Years',str(x)))\n",
    "size['match']=size['match'].apply(lambda x: re.sub(r'(?<!\\d)6(?:Y|T)','6 Years',str(x))).apply(lambda x: re.sub(r'(?<!\\d)7(?:Y|T)','7 Years',str(x))).apply(lambda x: re.sub(r'(?<!\\d)8(?:Y|T)','8 Years',str(x))).apply(lambda x: re.sub(r'(?<!\\d)9(?:Y|T)','9 Years',str(x))).apply(lambda x: re.sub(r'(?<!\\d)10(?:Y|T)','10 Years',str(x))).apply(lambda x: re.sub(r'(?<!\\d)11(?:Y|T)','11 Years',str(x)))\n",
    "\n",
    "\n",
    "size['match']=size['match'].apply(lambda x: f'[\"{x}\"]').apply(lambda x: re.sub(r'\\[\"\\[\"','[\"',str(x))).apply(lambda x: re.sub(r'\"\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'(?:\"\\])?\"\\,\"(?:\\[\")?','\",\"',str(x))).apply(lambda x: re.sub(r'\"\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\\[\"\\[\"','[\"',str(x)))\n",
    "size['cleaned']=size['match'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_index=size['cleaned'].explode().value_counts().reset_index().sort_values('index',ascending=True)\n",
    "# pattern=r'''(?i)(to)|(month(?!s And))|(toddler)|(Preemie)|(new.?born)|(infant)|(year)|(\\dT)|(\\dY)|()'''                                                              \n",
    "# size_index['match']=size_index['index'].apply(lambda x: re_extract(pattern,str(x)))\n",
    "# sized=size_index[size_index['match'].astype(str)!='[]']\n",
    "# del sized['match']\n",
    "# sized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip=r'''(?i)(\\d+T)|()'''                                                              \n",
    "# size['t']=size['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# print('SKUs with T: '+str(len(size[size['t'].astype(str)!='[]'])))\n",
    "# print('Buckets with T: '+str(size[size['t'].astype(str)!='[]']['buckets'].explode().value_counts().reset_index()['index'].to_list()))\n",
    "\n",
    "# print('')\n",
    "# print('######################################')\n",
    "# print('')\n",
    "\n",
    "# trip=r'''(?i)(\\d+Y)|()'''                                                              \n",
    "# size['y']=size['value'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# print('SKUs with Y: '+str(len(size[size['y'].astype(str)!='[]'])))\n",
    "# print('Buckets with Y: '+str(size[size['y'].astype(str)!='[]']['buckets'].explode().value_counts().reset_index()['index'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size['t'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size['y'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size['buckets'].explode().value_counts().reset_index()['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size[size['buckets'].astype(str)=='Baby Bibs & Burp Cloths']['value'].explode().value_counts()\n",
    "# size[(size['buckets'].astype(str)=='Protective/Active Bibs')&((size['value'].astype(str)=='Small')|(size['value'].astype(str)=='X-Small')|(size['value'].astype(str)=='X-Large')|(size['value'].astype(str)=='Large')|(size['value'].astype(str)=='Medium'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip=r'''(\\d+\\-\\d+(?:T|Y)(?![A-z]))|(\\d+M\\-\\d+M)|(\\d+\\s?M?\\-\\d+\\s?M(?:onths))|(\\d+(?:\\s?to\\s?|\\s?\\-\\s?)\\d+\\s?(?:m(?:onths?)?|years?))|((?:1[0-8]|(?<!\\d)[1-9])(?:\\.5)?(?:W|Y))|(\\d+\\s?Months?(?: and up)?)|([1-9]T)|(1[0-9]T)|(adult)|(infant)|((?:X.)?large)|(medium)|(newborn)|(one.?size)|(preemie)|(small)|(toddler)|(youth)|((?!<\\w)X{1,4}(?:L|S))|(Size.?(?:[1-9]|1[0-9])M)|(Carhartt.?.?Shortall)|(extra.?small)|(\\dX.?L)|()'''                                                              \n",
    "size['match']=size['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "print(len(size[size['match'].astype(str)!='[]']))\n",
    "uncurated=size[size['match'].astype(str)!='[]']\n",
    "uncurated=uncurated[uncurated['value'].astype(str)=='n/a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncurated['clean']=uncurated['match'].apply(lambda x: f'[\"{x}\"]')\n",
    "uncurated['clean']=uncurated['clean'].apply(lambda x: re.sub(r'\"?\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\\[\"\\[\"?','[\"',str(x))).apply(lambda x: re.sub(r'\"\\,(?!\")','\",\"',str(x)))\n",
    "\n",
    "uncurated['matchesss']=uncurated['clean'].apply(lambda x: re.sub(r'(12M-18M)','12 Months to 18 Months',str(x))).apply(lambda x: re.sub(r'\\[\"2T?\\-4T\"\\]','[\"2T\",\"3T\",\"4T\"]',str(x))).apply(lambda x: re.sub(r'\\[\"2\\-3Y\"\\]','[\"2T\",\"3T\"]',str(x))).apply(lambda x: re.sub(r'(\\[\"3\\-4T\"\\])','[\"3T\",\"4T\"]',str(x))).apply(lambda x: re.sub(r'2XL','XX-Large',str(x))).apply(lambda x: re.sub(r'3XL','XXX-Large',str(x))).apply(lambda x: re.sub(r'4XL','XXXX-Large',str(x))).apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r'','',str(x))).apply(lambda x: re.sub(r'','',str(x)))\n",
    "\n",
    "uncurated['matchesss']=uncurated['matchesss'].apply(lambda x: re.sub(r'2\\-4T','[\"2T\",\"3T\",\"4T\"]',str(x))).apply(lambda x: re.sub(r'(?<![A-z])\\s?(?<![A-z])\\-\\s?(?!\\dT)(?!\\dY)',' to ',str(x))).apply(lambda x: re.sub(r'2\\-4Y','[\"2Y\",\"3Y\",\"4Y\"]',str(x))).apply(lambda x: re.sub(r'newborn','Newborn',str(x))).apply(lambda x: re.sub(r'large','Large',str(x))).apply(lambda x: re.sub(r'medium','Medium',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\d)M)|(Month(?!s))',' Months',str(x))).apply(lambda x: re.sub(r'(?i)(size\\s?)|(\\d+\\-)','',str(x))).apply(lambda x: re.sub(r\"(\\s?\\'\\s?)\",'\"',str(x))).apply(lambda x: re.sub(r'Carhartt\\® Shortall','',str(x))).apply(lambda x: re.sub(r'(?<=)Mns',' Months',str(x))).apply(lambda x: re.sub(r'\\[\"\\[\"','[\"',str(x))).apply(lambda x: re.sub(r'\"\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\"?(?:\\])?\",\"(?:\\[)\"?','',str(x)))                                                                       \n",
    "\n",
    "uncurated['matchesss']=uncurated['matchesss'].apply(lambda x: re.sub(r'\"\"','\"',str(x))).apply(lambda x: re.sub(r'\"?\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\\[\"\\[\"?','[\"',str(x))).apply(lambda x: re.sub(r'\"\\,(?!\")','\",\"',str(x)))\n",
    "\n",
    "import ast\n",
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A\n",
    "uncurated['matchez']=uncurated['matchesss'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x))\n",
    "uncurated['matchez']=uncurated['matchez'].apply(lambda x: re.sub(r\"XL\",'X-Large',str(x))).apply(lambda x: re.sub(r\"\\s?'\\s?\",'\"',str(x))).apply(lambda x: re.sub(r'\\[\"\"\\]','',str(x))).apply(lambda x: re.sub(r'one','One Size',str(x))).apply(lambda x: re.sub(r'  ',' ',str(x)))\n",
    "uncurated['matchez']=uncurated['matchez'].apply(lambda x: re.sub(r'18 Months\",\"18 Months','18 Months',str(x))).apply(lambda x: re.sub(r'6 Months\",\"6 to 9 Months','6 to 9 Months',str(x))).apply(lambda x: re.sub(r'(9 to 12 Months\",\"12 Months)|(9 Months\",\"9 to 12 Months)','9 to 12 Months',str(x))).apply(lambda x: re.sub(r'9 to 12 Months\",\"12 Months','9 to 12 Months',str(x)))\n",
    "\n",
    "\n",
    "uncurated['matchez'].explode().value_counts()\n",
    "uncurated[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncurated['clean']=uncurated['value'].apply(lambda x: f'[\"{x}\"]')\n",
    "# uncurated['clean']=uncurated['clean'].apply(lambda x: re.sub(r'\"?\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\\[\"\\[\"?','[\"',str(x))).apply(lambda x: re.sub(r'\"\\,(?!\")','\",\"',str(x)))\n",
    "\n",
    "# uncurated['matchesss']=uncurated['clean'].apply(lambda x: re.sub(r'(?<![A-z])\\s?(?<![A-z])\\-\\s?',' to ',str(x))).apply(lambda x: re.sub(r'2\\-4T','[\"2T\",\"3T\",\"4T\"]',str(x))).apply(lambda x: re.sub(r'2\\-4Y','[\"2Y\",\"3Y\",\"4Y\"]',str(x))).apply(lambda x: re.sub(r'newborn','Newborn',str(x))).apply(lambda x: re.sub(r'large','Large',str(x))).apply(lambda x: re.sub(r'medium','Medium',str(x))).apply(lambda x: re.sub(r'(?i)((?<=\\d)M)|(Month(?!s))',' Months',str(x))).apply(lambda x: re.sub(r'(?i)(size\\s?)|(\\d+\\-)','',str(x))).apply(lambda x: re.sub(r\"(\\s?\\'\\s?)\",'\"',str(x))).apply(lambda x: re.sub(r'Carhartt\\® Shortall','',str(x))).apply(lambda x: re.sub(r'(?<=)Mns',' Months',str(x))).apply(lambda x: re.sub(r'\\[\"\\[\"','[\"',str(x))).apply(lambda x: re.sub(r'\"\\]\"\\]','\"]',str(x))).apply(lambda x: re.sub(r'\"?(?:\\])?\",\"(?:\\[)\"?','',str(x)))                                                                       \n",
    "# import ast\n",
    "# def remove_duplicates(A):\n",
    "#     [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "#     return A\n",
    "# uncurated['matchez']=uncurated['matchesss'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x))\n",
    "# uncurated['matchez']=uncurated['matchez'].apply(lambda x: re.sub(r\"XL\",'X-Large',str(x))).apply(lambda x: re.sub(r\"\\s?'\\s?\",'\"',str(x))).apply(lambda x: re.sub(r'\\[\"\"\\]','',str(x))).apply(lambda x: re.sub(r'one','One Size',str(x))).apply(lambda x: re.sub(r'  ',' ',str(x)))\n",
    "# uncurated['matchez']=uncurated['matchez'].apply(lambda x: re.sub(r'18 Months\",\"18 Months','18 Months',str(x))).apply(lambda x: re.sub(r'6 Months\",\"6 to 9 Months','6 to 9 Months',str(x))).apply(lambda x: re.sub(r'(9 to 12 Months\",\"12 Months)|(9 Months\",\"9 to 12 Months)','9 to 12 Months',str(x))).apply(lambda x: re.sub(r'9 to 12 Months\",\"12 Months','9 to 12 Months',str(x)))\n",
    "# # uncurated[uncurated['matchez'].astype(str)=='[\"12 Months\"]']['buckets'].explode().value_counts()\n",
    "# uncurated=uncurated[uncurated['value'].astype(str)!='n/a']\n",
    "# uncurated['matchez'].explode().value_counts()\n",
    "# # uncurated[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncurated['Q:size']=uncurated['matchesss'].apply(lambda x: re.sub(r'\"\\\\\"','\"',str(x)))\n",
    "match_uncurated=uncurated[['external_id','Q:size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}_AI_size_curated.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_uncurated) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Everyday/Dress Bodysuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_na=size[size['value'].astype(str)=='n/a']\n",
    "# everyday=size_na[(size_na['buckets'].astype(str)=='Everyday/Dress Bodysuits')]#&(size_na['buckets'].astype(str)=='Baby Bibs & Burp Cloths')&(size_na['buckets'].astype(str)=='T-Shirts')][0:500]\n",
    "# trip=r'''(?i)(\\d+(?: to |\\s?\\-\\s?)\\d+ (?:months?|years?))|((?:1[0-8]|(?<!\\d)[1-9])(?:\\.5)?(?:W|Y))|(\\d+\\s?Months?(?: and up)?)|([1-9]T)|(1[0-9]T)|(adult)|(infant)|((?:X.)?large)|(medium)|(newborn)|(one.?size)|(preemie)|(small)|(toddler)|(youth)|(X?X(?:L|S))|(Size.?(?:[1-9]|1[0-9])M)|(Size 6-12M)|(Carhartt.?.?Shortall)|(extra.?small)|()'''                                                              \n",
    "# everyday['pajama']=everyday['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# everyday[everyday['pajama'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pajama Jumpsuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_na=size[size['value'].astype(str)=='n/a']\n",
    "# everyday=size_na[(size_na['buckets'].astype(str)=='Pajama Jumpsuits')]#&(size_na['buckets'].astype(str)=='Baby Bibs & Burp Cloths')&(size_na['buckets'].astype(str)=='T-Shirts')][0:500]\n",
    "# trip=r'''(?i)(\\d+(?: to |\\s?\\-\\s?)\\d+ (?:months?|years?))|((?:1[0-8]|(?<!\\d)[1-9])(?:\\.5)?(?:W|Y))|(\\d+\\s?Months?(?: and up)?)|([1-9]T)|(1[0-9]T)|(adult)|(infant)|((?:X.)?large)|(medium)|(newborn)|(one.?size)|(preemie)|(small)|(toddler)|(youth)|(X?X(?:L|S))|(Size.?(?:[1-9]|1[0-9])M)|(Size 6-12M)|(Carhartt.?.?Shortall)|(extra.?small)|()'''                                                              \n",
    "# everyday['pajama']=everyday['product_name'].apply(lambda x: re_extract(trip,str(x)))\n",
    "# everyday[everyday['pajama'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clothing & Accessory Variety Packs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_na=size[size['value'].astype(str)=='n/a']\n",
    "clothing=size_na[(size_na['buckets'].astype(str)=='Clothing & Accessory Variety Packs')]#&(size_na['buckets'].astype(str)=='Baby Bibs & Burp Cloths')&(size_na['buckets'].astype(str)=='T-Shirts')][0:500]\n",
    "trip=r'''(?i)(\\d+(?: to |\\s?\\-\\s?)\\d+ (?:months?|years?))|((?:1[0-8]|(?<!\\d)[1-9])(?:\\.5)?(?:W|Y))|(\\d+\\s?Months?(?: and up)?)|([1-9]T)|(1[0-9]T)|(adult)|(infant)|((?:X.)?large)|(medium)|(newborn)|(one.?size)|(preemie)|(small)|(toddler)|(youth)|(X?X(?:L|S))|(Size.?(?:[1-9]|1[0-9])M)|(Size 6-12M)|(Carhartt.?.?Shortall)|(extra.?small)|()'''                                                              \n",
    "clothing['pajama']=clothing['product_name'].apply(lambda x: re_extract(trip,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clothing[clothing['pajama'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size[size['buckets'].astype(str)=='Clothing Sets & Variety Packs']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size[size['buckets'].astype(str)=='Pajama Pants']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size[size['buckets'].astype(str)=='Everyday/Dress Bodysuits']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size[size['buckets'].astype(str)=='Pajama Jumpsuits']['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Lumens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumen=df[df['attribute'].astype(str)=='lumens']\n",
    "# parameters\n",
    "customer_id = '5'\n",
    "formatted_attribute = 'Lumens'\n",
    "customer_name='%bedbathandbeyond%'\n",
    "buckets = \"\"\"Office Chairs\"\"\"\n",
    "\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_')\n",
    "value='%n/a%'\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "          'buckets': str(buckets.split('\\t'))[1:-1],\n",
    "          'value':value,\n",
    "          'customer_name':customer_name\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 - 449', '1000 - 1599', '1600+', '450 - 799', '800 - 999']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use KewWordProcessor to find a list of values for a single bucket \n",
    "df_strategy = query_from_file(file_name='../asset/easy.sql', params=params) #create query\n",
    "list_values=df_strategy['value'].to_list()\n",
    "\n",
    "kwp=KeywordProcessor()\n",
    "## JUNK\n",
    "# print(kwp.add_keywords_from_list(list_values))\n",
    "# # Extract Key Words\n",
    "# df['long_desc'].apply(lambda x: kwp.extract_keywords(x)) #\n",
    "\n",
    "# df['matches'] = df['long_desc'].apply(lambda x: kwp.extract_keywords(x))\n",
    "# df['matches'].explode().value_counts() \n",
    "list_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric='lbs'\n",
    "range_string = \"\"\"\n",
    "0 - 449\n",
    "1000 - 1599\n",
    "1600+\n",
    "450 - 799\n",
    "800 - 999\n",
    " \"\"\"\n",
    "\n",
    "range_params = {}\n",
    "for range_entry in range_string.split('\\n'):\n",
    "    range_nums = re.findall('\\d+', range_entry)\n",
    "    if len(range_nums) > 0: \n",
    "        range_params[tuple(map(int, range_nums))] = range_entry.strip()\n",
    "\n",
    "\n",
    "def  range_app(num_lst):\n",
    "    updated_labels = []\n",
    "    for num in num_lst:\n",
    "        num = float(num)\n",
    "        for range_param, range_label in range_params.items():\n",
    "            if len(range_param) == 1:\n",
    "                if num >= range_param[0]:\n",
    "                    updated_labels.append(range_label)\n",
    "            else:\n",
    "                if num >= range_param[0] and num <= range_param[1]:\n",
    "                    updated_labels.append(range_label)\n",
    "    return updated_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumens=lumen[lumen['value'].astype(str)!='n/a']\n",
    "lumens['match']=lumens['value'].apply(lambda x: re.sub(r'','',str(x)))\n",
    "pat=r'''(?i)(0\\s?.\\s?499)|(1000\\s?.\\s?1599)|(1600.)|(450\\s?.\\s?799)|(800\\s?.\\s?999)|(450\\s?.\\s?799)|((?<!\\d)\\d(?!\\d))|()'''\n",
    "lumens['matches']=lumens['match'].apply(lambda x: re_extract(pat,str(x)))\n",
    "lumenz=lumens[(lumens['matches'].astype(str)=='[]')&(lumens['external_id'].astype(str)!='69805198')]\n",
    "match=lumens[(lumens['matches'].astype(str)!='[]')&(lumens['external_id'].astype(str)!='69805198')]\n",
    "match['Q:lumens']=''\n",
    "match_match=match[['external_id','Q:lumens']]\n",
    "\n",
    "lumenz['match']=lumenz['match'].apply(lambda x: re.sub(r'\\,\\s?','',str(x))).apply(lambda x: f\"['{x}']\")#.apply(lambda x: re.sub(r'\\.\\d+|\\[|\\]','',str(x)))\n",
    "lumenz['match']=lumenz['match'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(range_app).apply(lambda x: re.sub(r\"'\",'\"',str(x)))\n",
    "lumenz['match'].explode().value_counts()\n",
    "lumenz['Q:lumens']=lumenz['match']\n",
    "match_lumenz=lumenz[['external_id','Q:lumens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>Q:lumens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1565380</th>\n",
       "      <td>67131389</td>\n",
       "      <td>[\"0 - 449\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565381</th>\n",
       "      <td>67131402</td>\n",
       "      <td>[\"0 - 449\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565382</th>\n",
       "      <td>65724705</td>\n",
       "      <td>[\"0 - 449\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565383</th>\n",
       "      <td>47101609</td>\n",
       "      <td>[\"1000 - 1599\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565384</th>\n",
       "      <td>45597435</td>\n",
       "      <td>[\"0 - 449\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9425751</th>\n",
       "      <td>65724439</td>\n",
       "      <td>[\"450 - 799\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9425752</th>\n",
       "      <td>47504691</td>\n",
       "      <td>[\"450 - 799\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9425753</th>\n",
       "      <td>47506336</td>\n",
       "      <td>[\"450 - 799\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9425755</th>\n",
       "      <td>65724637</td>\n",
       "      <td>[\"800 - 999\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9425756</th>\n",
       "      <td>47507647</td>\n",
       "      <td>[\"800 - 999\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        external_id         Q:lumens\n",
       "1565380    67131389      [\"0 - 449\"]\n",
       "1565381    67131402      [\"0 - 449\"]\n",
       "1565382    65724705      [\"0 - 449\"]\n",
       "1565383    47101609  [\"1000 - 1599\"]\n",
       "1565384    45597435      [\"0 - 449\"]\n",
       "...             ...              ...\n",
       "9425751    65724439    [\"450 - 799\"]\n",
       "9425752    47504691    [\"450 - 799\"]\n",
       "9425753    47506336    [\"450 - 799\"]\n",
       "9425755    65724637    [\"800 - 999\"]\n",
       "9425756    47507647    [\"800 - 999\"]\n",
       "\n",
       "[548 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_lumenz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-lumens.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_lumenz) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3269\n"
     ]
    }
   ],
   "source": [
    "feats=df[(df['attribute'].astype(str)=='features')&((df['buckets'].astype(str)=='Dining Chairs')|(df['buckets'].astype(str)=='Benches')|(df['buckets'].astype(str)=='Coffee Tables')|(df['buckets'].astype(str)=='Dining Tables'))]\n",
    "print(len(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='''(?i)|(non.marketing)|(floor.?protector)|(stain.?resistant)|(removable.?cushion)|(removable.?cover)|(swivel)|(tuft(ed|ing))|(nailhead.?trim)|(leveler)|(adjustable)|()'''\n",
    "feats['match']=feats['long_desc'].apply(lambda x: re_extract(pat,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "1532\n"
     ]
    }
   ],
   "source": [
    "x=feats[(feats['match'].astype(str)!='[]')]\n",
    "y=feats[(feats['value'].astype(str)=='n/a')]\n",
    "print(len(x))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Q:features']=''\n",
    "y['Q:features']=''\n",
    "match_features_x=x[['external_id','Q:features']]\n",
    "match_features_y=y[['external_id','Q:features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-Features_AI432_y.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_features_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Bed/Bedding Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed=df[df['attribute'].astype(str)=='bed_bedding_size']\n",
    "pat='''(?i)(futon)|(pull.?out)|(sleeper.?sofa)|()'''\n",
    "bed['match']=bed['long_desc'].apply(lambda x: re_extract(pat,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Futon    156\n",
       "Sofa      66\n",
       "Name: match, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beds=bed[(bed['match'].astype(str)!='[]')&(bed['value'].astype(str)=='n/a')]\n",
    "beds['match']=beds['match'].apply(lambda x: str(x).title()).apply(lambda x: re.sub(r'\\-',' ',str(x))).apply(lambda x: re.sub(r'Pullout','Pull Out',str(x))).apply(lambda x: re.sub(r'(Pull Out)|(Sleeper Sofa)','Sofa',str(x)))\n",
    "import ast\n",
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A\n",
    "beds['match']=beds['match'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)]))\n",
    "beds['match'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "beds['Q:bed_bedding_size']=beds['match'].apply(lambda x: re.sub(r\"'\",'\"',str(x)))\n",
    "match_beds=beds[['external_id','Q:bed_bedding_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-bed.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_beds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Light Bulbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulbs=df[(df['buckets'].astype(str)=='Light Bulbs')&((df['attribute'].astype(str)=='bulb_color')|(df['attribute'].astype(str)=='bulb_type')|(df['attribute'].astype(str)=='certifications')|(df['attribute'].astype(str)=='recommended_use')|(df['attribute'].astype(str)=='wattage'))]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "bulb_color=bulbs[(bulbs['attribute'].astype(str)=='bulb_color')&(bulbs['value'].astype(str)=='n/a')]\n",
    "certs='''(?i)(day.?light)|(warm.?white)|(cool.?white)|(amber)|(soft.?white)|(bright white light)|()'''\n",
    "bulb_color['match']=bulb_color['long_desc'].apply(lambda x: re_extract(certs,str(x)))\n",
    "bulb_color['match']=bulb_color['match'].apply(lambda x: str(x).title())\n",
    "import ast\n",
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A\n",
    "bulb_color['match']=bulb_color['match'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)]))\n",
    "bulb_color['match']=bulb_color['match'].apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: re.sub(r'(?i)(bright.?white.?light)','Warm White',str(x))).apply(lambda x: re.sub(r'(?i)(Amber)','Daylight',str(x))).apply(lambda x: re.sub(r'(?i)(soft.?white(?:.light)?)','Cool White',str(x)))\n",
    "bulbz=bulb_color[bulb_color['match'].astype(str)!='[]']\n",
    "print(len(bulbz))\n",
    "bulbz['Q:bulb_color']=bulbz['match']\n",
    "match_bulbz=bulbz[['external_id','Q:bulb_color']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-recommended_use.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_bulbz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>buckets</th>\n",
       "      <th>bucket_id</th>\n",
       "      <th>value</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>external_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>long_desc</th>\n",
       "      <th>curated_date</th>\n",
       "      <th>resolution</th>\n",
       "      <th>curation_tasks.curated_by</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [attribute, buckets, bucket_id, value, customer_name, external_id, product_name, long_desc, curated_date, resolution, curation_tasks.curated_by, match]\n",
       "Index: []"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulb_type=bulbs[(bulbs['attribute'].astype(str)=='bulb_type')&(bulbs['value'].astype(str)=='n/a')]\n",
    "certs='''(?i)(fluorescent)|(halogen)|(incandescent)|(\\bled\\b)|()'''\n",
    "bulb_type['match']=bulb_type['long_desc'].apply(lambda x: re_extract(certs,str(x)))\n",
    "# types=bulb_type[bulb_type['match'].astype(str)!='[]']\n",
    "# types['Q:bulb_type']=''\n",
    "# match_bulbs=types[['external_id','Q:bulb_type']]\n",
    "\n",
    "bulb_type[bulb_type['match'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cert=bulbs[bulbs['attribute'].astype(str)=='certifications']\n",
    "# certs='''(?i)(ce.?marketing)|(dlc)|(energy.?star)|(etl)|(fcc)|(rohs)|(\\bUL\\b)|()'''\n",
    "# cert['match']=cert['long_desc'].apply(lambda x: re_extract(certs,str(x)))\n",
    "# certs=cert[cert['match'].astype(str)!='[]']\n",
    "# certs['Q:certifications']='' \n",
    "# match_cert=certs[['external_id','Q:certifications']]\n",
    "# match_cert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-recommended_use.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_cert) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.209150326797386\n",
      "67.83216783216784\n",
      "18.627450980392158\n",
      "83.56164383561644\n",
      "62.12624584717608\n"
     ]
    }
   ],
   "source": [
    "wat=bulbs[bulbs['attribute'].astype(str)=='wattage']                                                   \n",
    "wat_na=bulbs[(bulbs['attribute'].astype(str)=='wattage')&(bulbs['value'].astype(str)=='n/a')]\n",
    "\n",
    "rec=bulbs[bulbs['attribute'].astype(str)=='recommended_use']\n",
    "rec_na=bulbs[(bulbs['attribute'].astype(str)=='recommended_use')&(bulbs['value'].astype(str)=='n/a')]\n",
    "\n",
    "cert=bulbs[bulbs['attribute'].astype(str)=='certifications']\n",
    "cert_na=bulbs[(bulbs['attribute'].astype(str)=='certifications')&(bulbs['value'].astype(str)=='n/a')]\n",
    "\n",
    "types=bulbs[bulbs['attribute'].astype(str)=='bulb_type']\n",
    "types_na=bulbs[(bulbs['attribute'].astype(str)=='bulb_type')&(bulbs['value'].astype(str)=='n/a')]\n",
    "\n",
    "colors=bulbs[bulbs['attribute'].astype(str)=='bulb_color']\n",
    "colors_na=bulbs[(bulbs['attribute'].astype(str)=='bulb_color')&(bulbs['value'].astype(str)=='n/a')]\n",
    "\n",
    "print(len(wat_na)/len(wat)*100) # Not a lot of N/A values\n",
    "print(len(cert_na)/len(cert)*100)  # Wipe/Rules\n",
    "print(len(types_na)/len(types)*100) # Low # N/A-good\n",
    "print(len(rec_na)/len(rec)*100)   # Wipe/Rules\n",
    "print(len(colors_na)/len(colors)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_id</th>\n",
       "      <th>Q:recommended_use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [external_id, Q:recommended_use]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# light='''(?i)(lamp)|(pendant.?lighting)|(track.{0,10}light)|(recessed.?lights)|(night lights)|(under cabinet.?lights)|(flush.{0,7}light)|(semi.?flush.{0,7}light)|(rope.?light)|(string.?light)|(sconces)|(vanity.?light)|()'''   \n",
    "# rec['match']=rec['long_desc'].apply(lambda x: re_extract(light,str(x)))\n",
    "# rec_df=rec[rec['match'].astype(str)!='[]']\n",
    "# rec_df['Q:recommended_use']=''\n",
    "# match_rec=rec_df[['external_id','Q:recommended_use']]\n",
    "# match_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-recommended_use.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_rec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiting on Ross #477 or 478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat=df[(df['attribute'].astype(str)=='features')&((df['buckets'].astype(str)=='Coffee Tables')|(df['buckets'].astype(str)=='Dining tables')|(df['buckets'].astype(str)=='Chairs')|(df['buckets'].astype(str)=='Furniture variety packs')|(df['buckets'].astype(str)=='Serving/Rolling carts'))]\n",
    "feat['Q:features']=''\n",
    "match_feat=feat[['external_id','Q:features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiting on Ross #477 or 478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat=df[(df['attribute'].astype(str)=='material')&(df['value'].astype(str)=='Fabric')]\n",
    "mat['value'].explode().value_counts()\n",
    "mat['Q:material']=''\n",
    "match_mat=mat[['external_id','Q:material']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-features.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_feat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiting on Jeff to approve adding value Futon and Pull Out to values AI 455\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197\n"
     ]
    }
   ],
   "source": [
    "bed=df[(df['attribute'].astype(str)=='bed_bedding_size')&(df['buckets'].astype(str)=='Sleeper Sofas/Sofa Beds/Futons')&(bed['value'].astype(str)=='n/a')]\n",
    "print(len(bed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bed['value'].explode().value_counts()\n",
    "# bed[bed['value'].astype(str)=='n/a']\n",
    "\n",
    "# sofa=r'''((?:standard|twin(?:.?xl)?|split(?!.back)|\\bfull\\b|queen|(?:California.?)?\\bKing).{0,7}bed)|(futon)|()|()'''                                                              \n",
    "# bed['match']=bed['long_desc'].apply(lambda x: re_extract(sofa,str(x)))\n",
    "# sofa=bed[bed['match'].astype(str)=='[]']\n",
    "# print(len(sofa))\n",
    "# sofa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiting on Ross and Jeff to meet with client and get OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clothing Sets & Variety Packs-Pajamas/Kids --> one size fits all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clothing Sets & Variety Packs',\n",
       " 'Baby Bibs & Burp Cloths',\n",
       " 'T-Shirts',\n",
       " 'Clothing & Accessory Variety Packs',\n",
       " 'Pajama Jumpsuits',\n",
       " 'Role Playing Toys',\n",
       " 'Full Brim Hats',\n",
       " 'Baby Feeding Bottles & Accessories',\n",
       " 'Slacks/Pants',\n",
       " 'Bras',\n",
       " 'Feminine Hygiene',\n",
       " 'Leggings',\n",
       " 'Non-Brim Hats',\n",
       " 'Socks',\n",
       " 'Everyday/Dress Bodysuits',\n",
       " 'Robes',\n",
       " 'Baby Food',\n",
       " 'Jackets/Coats',\n",
       " 'Swim Variety Packs',\n",
       " 'Tops',\n",
       " 'Dresses & Gowns',\n",
       " 'Pet Bowls & Feeders',\n",
       " 'Baby Jumpers, Swings, & Rockers',\n",
       " 'Everyday/Dress Jumpsuits',\n",
       " 'Bassinets & Cradles',\n",
       " 'Button-Downs',\n",
       " 'Sweatshirts/Fleece Pullovers',\n",
       " 'Pantyhose/Tights',\n",
       " 'Everyday/Dress Shorts',\n",
       " 'Baby Safety Monitors',\n",
       " 'Swim Bottoms',\n",
       " 'Headbands',\n",
       " 'Protective Full Body Swim',\n",
       " 'Pet Houses, Crates, & Kennels',\n",
       " 'Pet Car Accessories',\n",
       " 'One-Piece Swimsuits',\n",
       " 'Accessories Variety Packs',\n",
       " 'Overalls',\n",
       " 'Everyday/Dress Footwear',\n",
       " 'Helmets',\n",
       " 'Sweaters',\n",
       " 'Underwear',\n",
       " 'Night Dresses & Shirts',\n",
       " 'Protective/Active Bodysuits',\n",
       " 'Pet Beds & Cots',\n",
       " 'Corsets/Basques/Waist Cinchers',\n",
       " 'Protective Swim Tops',\n",
       " 'Pet Collars, Leashes & Harnesses',\n",
       " 'Baby Bathtubs',\n",
       " 'Life Vests & Personal Flotation Devices',\n",
       " 'Protective/Active Jumpsuits',\n",
       " 'Bracelets & Anklets',\n",
       " 'Polos',\n",
       " 'Camis/Strapless Tops',\n",
       " 'Jeans',\n",
       " 'Everyday/Dress Vests',\n",
       " 'Pet Clothing Accessories',\n",
       " 'Pet General Wear',\n",
       " 'Protective/Active Shorts',\n",
       " 'Swim Cover Ups',\n",
       " 'Protective/Active Bibs',\n",
       " 'Cardigans/Kimonos/Wraps',\n",
       " 'Clothing & Footwear Variety Packs',\n",
       " 'Pajama Pants',\n",
       " 'Skirts',\n",
       " 'Braces/Slings/Splints/Supports & Accessories',\n",
       " 'Lumbar Support Belts',\n",
       " 'Disposable Gloves',\n",
       " 'Protective Footwear',\n",
       " 'Active/Athletic Footwear',\n",
       " 'Lower Body Swim',\n",
       " 'Clothing Variety Packs',\n",
       " 'Belts',\n",
       " 'Pajama Shorts',\n",
       " 'Specialty Sport Footwear',\n",
       " 'Pet Boots',\n",
       " 'Specialty Sports Gloves']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_na=df[(df['attribute'].astype(str)=='size')&(df['value'].astype(str)=='n/a')]\n",
    "size_na['buckets'].explode().value_counts().reset_index()['index'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing=size_na[(size_na['buckets'].astype(str)=='Clothing & Accessory Variety Packs')]#&(size_na['buckets'].astype(str)=='Baby Bibs & Burp Cloths')&(size_na['buckets'].astype(str)=='T-Shirts')][0:500]\n",
    "trip=r'''(?i)(\\d+(?: to |\\s?\\-\\s?)\\d+ (?:months?|years?))|((?:1[0-8]|(?<!\\d)[1-9])(?:\\.5)?(?:W|Y))|(\\d+\\s?Months?(?: and up)?)|([1-9]T)|(1[0-9]T)|(adult)|(infant)|((?:X.)?large)|(medium)|(newborn)|(one.?size)|(preemie)|(small)|(toddler)|(youth)|(X?X(?:L|S))|(Size.?(?:[1-9]|1[0-9])M)|(Size 6-12M)|(Carhartt.?.?Shortall)|()'''                                                              \n",
    "clothing['pajama']=clothing['product_name'].apply(lambda x: re_extract(trip,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clothing['pajama'].explode().value_counts()\n",
    "\n",
    "# # 2T, 3T, 4T, 5T, 6T,  8T, Toddler, Small, Infant, XS, Newborn, Medium, Large, XXL, X-Large, Adult,  4Y, 5Y, 6Y, 7Y, 8Y, 9Y, 10Y, 12Y, 14Y,        4M, 3M, 9M, 6M, 18M, 24M, 12M, Pajamas, Carhart Shorttall, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('No Matches: '+str(len(clothing[clothing['pajama'].astype(str)=='[]'])))\n",
    "# print('Matches: '+str(len(clothing[clothing['pajama'].astype(str)!='[]'])))\n",
    "# clothing[clothing['pajama'].astype(str)!='[]'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395797\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "feature_na=df[(df['attribute'].astype(str)=='features')&(df['value'].astype(str)=='n/a')]\n",
    "print(len(feature_na))\n",
    "sofa=feature_na[(feature_na['buckets'].astype(str)=='Sleeper Sofas/Sofa Beds/Futons')|(feature_na['buckets'].astype(str)=='Sofas/Couches/Loveseats/Settees ')]\n",
    "print(len(sofa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth (Sheets) Length: 34430\n",
      "Number N/A: 24932\n"
     ]
    }
   ],
   "source": [
    "depth_sheets=df[(df['attribute'].astype(str)=='depth_sheets')&(df['buckets'].astype(str)=='Bedding Variety Packs')]\n",
    "print('Depth (Sheets) Length: '+str(len(depth_sheets)))\n",
    "depth_na=depth_sheets[depth_sheets['value'].astype(str)=='n/a']\n",
    "print('Number N/A: '+str(len(depth_na)))\n",
    "# depth_na[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "pat=r'''(?i)(?i)(fitted sheets? fits? mattresses up to \\d+\\\\?\"?)|((?<!\\/)\\d+\\\\\"\\s?D(?:eep|epth)?\\b)|()'''\n",
    "trip=r'''(?i)((?:\\d+(?:(?:\\-?\\s?\\d+\\/\\d+)?(?:\\.\\d+)?)?|\\d+\\/\\d+)\\\\{0,2}(?:(?:\")?(?:”)?(?:'{0,2})?(?:\\W?inc?h?e?s?)?(?:\\W?fo?o?e?e?t)?(?:yds)?(?:\\s?[lwhd]?))\\\\{0,2}(?:(?:\")?(?:”)?(?:'{0,2})?(?:\\W?inc?h?e?s?)?(?:\\W?fo?o?e?e?t)?(?:yds)?(?:\\s?[lwhd]?)).?x.?(?:\\d+(?:(?:\\-?\\s?\\d+\\/\\d+)?(?:\\.\\d+)?)?|(\\d+\\/\\d+))\\\\{0,2}(?:(?:\")?(?:”)?(?:'{0,2})?(?:\\W?inc?h?e?s?)?(?:\\W?fo?o?e?e?t)?(?:yds)?(?:\\s?[lwhd]?))\\\\{0,2}(?:(?:\")?(?:”)?(?:'{0,2})?(?:\\W?inc?h?e?s?)?(?:\\W?fo?o?e?e?t)?(?:yds)?(?:\\s?[lwhd]?)).?x.?(?:\\d+(?:(?:\\-?\\s?\\d+\\/\\d+)?(?:\\.\\d+)?)?|(\\d+\\/\\d+))\\\\{0,2}(?:(?:\")?(?:”)?(?:'{0,2})?(?:\\W?inc?h?e?s?)?(?:\\W?fo?o?e?e?t)?(?:yds)?(?:\\s?[lwhd]?))\\\\{0,2}(?:(?:\")?(?:”)?(?:'{0,2})?(?:\\W?inc?h?e?s?)?(?:\\W?fo?o?e?e?t)?(?:yds)?(?:\\s?[lwhd]?)))|()'''\n",
    "fitted_sheet='fitted.?sheet'\n",
    "depth_na['fitted']=depth_na['long_desc'].apply(lambda x: re_extract(pat,str(x)))\n",
    "depth_na['fitted_sheet']=depth_na['long_desc'].apply(lambda x: re_extract(fitted_sheet,str(x)))\n",
    "fitted=depth_na[(depth_na['fitted'].astype(str)!='[]')&(depth_na['fitted_sheet'].astype(str)!='[]')]\n",
    "print(len(fitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted['Q:depth_sheets']=fitted['fitted'].apply(lambda x: re.sub(r'[A-z]|\\s','',str(x))).apply(lambda x: re.sub(r'\\\\?\"',' in',str(x))).apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: f'[{x}]').apply(lambda x: re.sub(r'(?<=\\d)\"]',' in\"]',str(x)))\n",
    "fitted['Q:depth_sheets'].explode().value_counts()\n",
    "match_fitted=fitted[['external_id','Q:depth_sheets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-AI_match_fitted.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_fitted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_na['trip']=depth_na['long_desc'].apply(lambda x: re_extract(trip,str(x)))\n",
    "trips=fitted[fitted['trip'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern='(?i)((?:\\d+\\.)?\\d+\\\\?\"\\s?D)|((?<=\\d\\d\\\\\" \\w \\d\\d\\\\\" \\w )(?<=)(?:0\\.)?\\d+\\\\?\")|((?<=\\d\\d\\\\\" \\w x \\d\\d\\\\\" \\w x )(?:0\\.)?\\d+\\\\?\"(?! H))|(\\d+\\\\?\"\\s?D)|()'\n",
    "trips['trips']=trips['trip'].apply(lambda x: re_extract(pattern,str(x)))\n",
    "# trips['trips'].explode().value_counts()\n",
    "trips['Q:depth_sheets']=''\n",
    "match_trips=trips[['external_id','Q:depth_sheets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-AI_match_trips.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_trips) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['trips'].apply(lambda x: re.sub(r'\\\\?\"\\s?D',' in',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features=df[(df['attribute'].astype(str)=='features')]\n",
    "# pat=r'(?i)(sofa)|(couch)|()'\n",
    "# features['pillow']=features['product_name'].apply(lambda x: re_extract(pat,str(x)))\n",
    "\n",
    "\n",
    "# na=features[(features['pillow'].astype(str)=='[]')]\n",
    "# na['Q:features']=''\n",
    "# matchna=na[['external_id','Q:features']]\n",
    "# na[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rugs=r'''(3'6\\\\?\"? x 5'6\\\\?\"?)|()'''\n",
    "# df['rugs']=df['product_name'].apply(lambda x: re_extract(rugs,str(x)))\n",
    "# three=df[(df['rugs'].astype(str)!='[]')&(df['value'].astype(str)=='n/a')&(df['attribute'].astype(str)=='rug_size')]\n",
    "# three['Q:rug_size']=\"4' x 6'\"\n",
    "# three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_three=three[['external_id','Q:rug_size']]\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-AI.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_three) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=r'(?i)(from.{0,20}solid)|(add color.{0,20}solid)|()'\n",
    "shade=r'(?i)(shade)|(blind|)|(Curtain)|(shutter)|(blockout)|()'\n",
    "solid_name=r'(?i)(solid.{0,20}flannel)|()'\n",
    "\n",
    "pattern=df[(df['attribute'].astype(str)=='pattern')&(df['value'].astype(str)=='Solid')&(df['resolution'].astype(str)=='rules')]\n",
    "pattern['pat']=pattern['long_desc'].apply(lambda x: re_extract(pat,str(x)))\n",
    "pattern['shade']=pattern['product_name'].apply(lambda x: re_extract(solid_name,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pattern[(pattern['shade'].astype(str)=='[]')&(pattern['buckets'].astype(str)!='Curtains')&(pattern['buckets'].astype(str)!='Towels Variety Packs')&(pattern['buckets'].astype(str)!='Washcloths')&(pattern['value'].astype(str)!='n/a')]\n",
    "a=x[x['buckets'].astype(str)=='Throw/Decorative Pillows']\n",
    "print(len(a))\n",
    "a[0:500]\n",
    "a['Q:pattern']=''\n",
    "match=a[['external_id','Q:pattern']]\n",
    "print(len(match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-AI.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weave=df[(df['attribute'].astype(str)=='weave')&(df['value'].astype(str)=='n/a')]\n",
    "print(len(weave))\n",
    "pat=r'(?i)((?:Two|Single).?Ply)|(Twill)|(Tufted)|(Shag)|(Satin)|(Sateen)|(Quilt(?:ed)?)|(Pinpoint)|(Percale)|(Oxford)|(Microfiber)|(Machine.?(?:Made|woven))|(Knotted)|(Jersey)|(Jacquard)|(Interlock)|(Hooked)|(Flatweave)|(Flannel)|(Dobby)|(Damask)|()'\n",
    "weave['match']=weave['long_desc'].apply(lambda x: re_extract(pat,str(x)))\n",
    "weave['match_name']=weave['product_name'].apply(lambda x: re_extract(pat,str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curate=weave[(weave['match'].astype(str)!='[]')]\n",
    "print(len(curate))\n",
    "curate['matches']=curate['match'].astype(str).apply(lambda x: re.sub(r'(?i)Quilt(?:ed)?','Quilted',str(x))).apply(lambda x: re.sub(r'(?i)(Machine.?(?:Made|woven))','Machine Made',str(x))).apply(lambda x: re.sub(r\"'\",'\"',str(x))).apply(lambda x: x.title())\n",
    "curate['matches']=curate['matches'].apply(lambda x: re.sub(r'(?i)\\-Ply',' Ply',str(x)))\n",
    "# curate['matches'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A\n",
    "curate['matchez']=curate['matches'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)])).apply(lambda x: natsorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curate['Q:weave']=curate['matchez'].apply(lambda x: re.sub(r\"'\",'\"',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curate['Q:weave']=curate['Q:weave'].apply(lambda x: re.sub(r'\\\\|Xa0',' ',str(x))).apply(lambda x: re.sub(r'\\, \"',',\"',str(x)))\n",
    "curate['Q:weave'].explode().value_counts()\n",
    "match=curate[['external_id','Q:weave']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-AI.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc=df[df['attribute'].astype(str)=='thread_count']\n",
    "pat=r'(?i)(sheet)|()'\n",
    "tc['sheet']=tc['product_name'].apply(lambda x: re_extract(pat, str(x)))\n",
    "sheet=tc[(tc['sheet'].astype(str)!='[]')&(tc['value'].astype(str)=='n/a')]\n",
    "\n",
    "pat=r'(?i)(thread.?count)|(\\d+TC)|()'\n",
    "sheet['thread_count']=sheet['long_desc'].apply(lambda x: re_extract(pat, str(x)))\n",
    "print(len(sheet[sheet['thread_count'].astype(str)!='[]']))\n",
    "na=sheet[sheet['thread_count'].astype(str)!='[]']\n",
    "na['Q:thread_count']=''\n",
    "match_na=na[['external_id','Q:thread_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY-{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=r'(?i)(flannel)|(jersey)|()'\n",
    "sheet['match']=sheet['long_desc'].apply(lambda x: re_extract(pat, str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tc[(tc['sheet'].astype(str)!='[]')&(tc['value'].astype(str)!='n/a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=sheet[(sheet['thread_count'].astype(str)=='[]')&(sheet['match'].astype(str)=='[]')]#['buckets'].explode().value_counts()\n",
    "y=x[(x['buckets'].astype(str)!='Pillowcases & Pillow Protectors')&(x['buckets'].astype(str)!='Mattress Accessories & Specialty Protectors')&(x['buckets'].astype(str)!='Comforters')]\n",
    "print(len(y))\n",
    "y['buckets'].explode().value_counts()\n",
    "# y[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tc_na=tc[tc['value'].astype(str)=='n/a']\n",
    "\n",
    "pat=r'(?i)(flannel)|(jersey)|()'\n",
    "tc_na['match']=tc_na['long_desc'].apply(lambda x: re_extract(pat, str(x)))\n",
    "\n",
    "pat=r'(?i)(pillow)|()'\n",
    "tc_na['name']=tc_na['product_name'].apply(lambda x: re_extract(pat, str(x)))\n",
    "\n",
    "count=tc_na[(tc_na['match'].astype(str)=='[]')&(tc_na['name'].astype(str)=='[]')&((tc_na['buckets'].astype(str)=='Bedding Variety Packs')|(tc_na['buckets'].astype(str)=='Bed Sheets'))]#[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=r'(?i)(thread.?count)|()'\n",
    "count['thread_count']=count['long_desc'].apply(lambda x: re_extract(pat, str(x)))\n",
    "count_na=count[count['thread_count'].astype(str)!='[]']\n",
    "print(len(count_na))\n",
    "count_na['Q:thread_count']=''\n",
    "match_count=count_na[['external_id','Q:thread_count']]\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY-{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=r'(?i)(solid)|()'\n",
    "df['solid']=df['value'].apply(lambda x: re_extract(pat, str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=r'(?i)Cabin Print'\n",
    "df['match']=df['long_desc'].apply(lambda x: re_extract(pat, str(x)))\n",
    "micro=x[x['match'].astype(str)!='[]']\n",
    "print(len(micro))\n",
    "micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[(df['attribute'].astype(str)=='pattern')&(df['solid'].astype(str)!='[]')&(df['resolution'].astype(str)=='rules')&(df['buckets'].astype(str)!='Window Blinds')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bed=x[x['buckets'].astype(str)=='Bedding Variety Packs']\n",
    "# pat=r'(?i)(.{0,20}solid.{0,20})|()'\n",
    "# reverse=r'(?i)(Reverses to matching solid design)|()'\n",
    "# bed['match']=bed['long_desc'].apply(lambda x: re_extract(pat, str(x)))\n",
    "# bed['reverse']=bed['long_desc'].apply(lambda x: re_extract(reverse, str(x)))\n",
    "# bed[(bed['match'].astype(str)!='[]')][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[(df['attribute'].astype(str)=='color')&((df['value'].astype(str)=='Assorted')|(df['value'].astype(str)=='assorted')|(df['value'].astype(str)=='Assorted Colors'))]\n",
    "pat=r'(?i)((?<!sticker )sheet)|()'\n",
    "x['match']=x['long_desc'].apply(lambda x: re_extract(pat, str(x)))\n",
    "x['match_name']=x['product_name'].apply(lambda x: re_extract(pat, str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[(x['match'].astype(str)!='[]')&(x['match_name'].astype(str)!='[]')])\n",
    "sheet=x[(x['match'].astype(str)!='[]')&(x['match_name'].astype(str)!='[]')]\n",
    "sheet['na']=''\n",
    "match_na=sheet[['external_id','na']]\n",
    "print(len(match_na))\n",
    "\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "    matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-AI.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', df, match_na) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[((df['bucket_id']==7309)|(df['bucket_id']==6630)|(df['bucket_id']==8131)|(df['bucket_id']==6714)|(df['bucket_id']==6670)|(df['bucket_id']==8705)|(df['bucket_id']==8823)|(df['bucket_id']==9031)|(df['bucket_id']==7452)|(df['bucket_id']==8975)|(df['bucket_id']==9668)|(df['bucket_id']==6706)|(df['bucket_id']==9143)|(df['bucket_id']==7252)|(df['bucket_id']==9268)|(df['bucket_id']==8395)|(df['bucket_id']==9667)|(df['bucket_id']==9403)|(df['bucket_id']==7906)|(df['bucket_id']==7085)|(df['bucket_id']==8670)|(df['bucket_id']==7969)|(df['bucket_id']==8958)|(df['bucket_id']==8831)|(df['bucket_id']==7930))&((df['attribute'].astype(str)=='care'))]['buckets'].explode().value_counts()                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df[(df['attribute'].astype(str)=='care')&(df['value'].astype(str)!='n/a')]['bucket_id'].explode().value_counts().reset_index().sort_values('index')['index'].to_list()))\n",
    "# df[(df['attribute'].astype(str)=='care')&(df['value'].astype(str)!='n/a')]['bucket_id'].explode().value_counts().reset_index().sort_values('index')['index'].to_list()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['attribute']=='certifications')&(df['resolution']!='rules')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=df[(df['attribute'].astype(str)=='pattern')&(df['value'].astype(str)=='Damask')&(df['resolution'].astype(str)=='rules')]\n",
    "# x['Q:pattern']='n/a'\n",
    "# match=x[['external_id','Q:pattern']]\n",
    "# match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=df[(df['attribute'].astype(str)=='personalization_type')&(df['value'].astype(str)=='Text')]\n",
    "# x['Q:personalization_type']='n/a'\n",
    "# match=x[['external_id','Q:personalization_type']]\n",
    "# print(len(match))\n",
    "# match\n",
    "# print(len(x))\n",
    "# x[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df_name(df):\n",
    "#     name =[x for x in globals() if globals()[x] is df][1]\n",
    "#     return name\n",
    "\n",
    "# def looks_good(customer, df, matches): \n",
    "#     drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "# #     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "# #     non_matches[curation_col] = r'n/a'\n",
    "# #     non_matches.to_csv(f'{drive_path}/BBBY - {attribute} - na upload {buckets}.csv',index=False)\n",
    "#     matches.to_csv(f'{drive_path}/BBBY --{get_df_name(matches)}-matches-personalization.csv',index=False) \n",
    "    \n",
    "# looks_good('Bed Bath & Beyond', df, match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# att=df[df['attribute'].astype(str)=='certifications']\n",
    "# print('Length of df: '+str(len(att)))\n",
    "# print('Top 5 Resolutions: '+str(att['resolution'].explode().value_counts().reset_index()['index'].to_list()[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res=df[df['attribute'].astype(str)=='certifications']#['resolution'].explode().value_counts()\n",
    "# print(len(res))\n",
    "# res[res['resolution'].astype(str)=='standard'].sort_values('curated_date',ascending=False)[0:500]\n",
    "# res[res['resolution'].astype(str)=='standard']['value'].explode().value_counts()#\n",
    "# df[df['attribute'].astype(str)=='battery_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=df[(df['attribute'].astype(str)=='care')]#&(df['value'].astype(str)=='UL Listed')]\n",
    "# print(len(x))\n",
    "# x['value'].explode().value_counts()\n",
    "# # x[0:500]\n",
    "# # x[x['value'].astype(str)=='All Types']\n",
    "# # x[x['value'].str.contains('All', na = False)]\n",
    "# # x[x['value'].astype(str)=='Natural']['long_desc']\n",
    "# na=x[x['value'].astype(str)=='n/a']\n",
    "# na['buckets'].explode().value_counts()\n",
    "# df=df[df['attribute']=='care']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['attribute'].explode().value_counts()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df[df['attribute'].astype(str)!='keywords']\n",
    "# print('Total SKUs not counting Keywords: '+str(len(df)))\n",
    "# df['attribute'].explode().value_counts()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na=df[df['value'].astype(str)=='n/a']\n",
    "# print('Total N/A values: '+str(len(na)))\n",
    "# na['attribute'].explode().value_counts()[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z={}\n",
    "# for idx, name in enumerate(na['attribute'].explode().value_counts()[0:50].index.tolist()):\n",
    "#     z[name]=na['attribute'].value_counts()[idx]\n",
    "# data_items = z.items()\n",
    "# data_list = list(data_items)\n",
    "# u=pd.DataFrame(data_list)\n",
    "# u.rename(columns={ u.columns[0]: \"Attribute\",u.columns[1]: \"N/A Count\" }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x={}\n",
    "# for idx, name in enumerate(df['attribute'].explode().value_counts()[0:50].index.tolist()):\n",
    "#     x[name]=df['attribute'].value_counts()[idx]\n",
    "\n",
    "# data_items = x.items()\n",
    "# data_list = list(data_items)\n",
    "# y=pd.DataFrame(data_list)\n",
    "# y.rename(columns={ y.columns[0]: \"Attribute\",y.columns[1]: \"Total Count\" }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge=y.merge(u,how='outer',left_on=['Attribute'],right_on=['Attribute'])\n",
    "# merge['percent']=round(merge['N/A Count']/merge['Total Count']*100,2)\n",
    "# merge=merge[merge['percent'].astype(str)!='nan']\n",
    "# merge=merge.sort_values('percent',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over_10k=merge[merge['Total Count']>100]\n",
    "# over_10k.sort_values('Total Count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_merge=merge[merge['percent'].astype(str)>'30'].reset_index(drop=True)\n",
    "# top_merge#.sort_values('Total Count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(top_merge)):\n",
    "#     print('                                                                 ')\n",
    "#     print('Attribute: '+str(top_merge['Attribute'][i].upper())+'________ Percent N/A:'+str(top_merge['percent'][i]))\n",
    "#     print('Number of N/A Values: '+str(top_merge['Total Count'][i]))\n",
    "#     print(df[df['attribute'].astype(str)==f\"{top_merge['Attribute'][i]}\"]['buckets'].explode().value_counts()[0:20])\n",
    "#     print('#############################################################')\n",
    "#     print('      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def na_analysis(date1,date2):\n",
    "#     print('Start Date: '+str(date1)+' End Date: '+str(date2))\n",
    "#     x=df[(df['curated_date'].astype(str)>=date1)&(df['curated_date'].astype(str)<=date2)]\n",
    "#     print('Total curated on this day: '+str(len(x)))\n",
    "#     nine_thirteen=na[(na['curated_date'].astype(str)>=date1)&(na['curated_date'].astype(str)<=date2)]\n",
    "#     print('Total N/A values this day:'+str(len(nine_thirteen)))\n",
    "#     print('Percent N/A: '+str(round((len(nine_thirteen))/(len(x))*100,2))+ '%')\n",
    "#     print(nine_thirteen['attribute'].explode().value_counts()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buckets for an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z={}\n",
    "# for idx, name in enumerate(na['buckets'].explode().value_counts()[0:50].index.tolist()):\n",
    "#     z[name]=na['buckets'].value_counts()[idx]\n",
    "# data_items = z.items()\n",
    "# data_list = list(data_items)\n",
    "# u=pd.DataFrame(data_list)\n",
    "# u.rename(columns={ u.columns[0]: \"Buckets\",u.columns[1]: \"N/A Count\" }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x={}\n",
    "# for idx, name in enumerate(df['buckets'].explode().value_counts()[0:50].index.tolist()):\n",
    "#     x[name]=df['buckets'].value_counts()[idx]\n",
    "\n",
    "# data_items = x.items()\n",
    "# data_list = list(data_items)\n",
    "# y=pd.DataFrame(data_list)\n",
    "# y.rename(columns={ y.columns[0]: \"Buckets\",y.columns[1]: \"Total Count\" }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge=y.merge(u,how='outer',left_on=['Buckets'],right_on=['Buckets'])\n",
    "# merge['percent']=round(merge['N/A Count']/merge['Total Count']*100,2)\n",
    "# merge=merge[merge['percent'].astype(str)!='nan']\n",
    "# merge=merge.sort_values('percent',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over_10k=merge[merge['Total Count']>100]\n",
    "# over_10k.sort_values('Total Count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_merge=merge[merge['percent'].astype(str)>'30'].reset_index(drop=True)\n",
    "# top_merge#.sort_values('Total Count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_merge['N/A Count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(top_merge)):\n",
    "#     print('                                                                 ')\n",
    "#     print('Buckets: '+str(top_merge['Buckets'][i].upper())+'________ Percent N/A:'+str(top_merge['percent'][i]))\n",
    "#     print('Number of N/A Values: '+str(top_merge['Total Count'][i]))\n",
    "#     print(df[df['buckets'].astype(str)==f\"{top_merge['Buckets'][i]}\"]['buckets'].explode().value_counts()[0:20])\n",
    "#     print('#############################################################')\n",
    "#     print('                                                                 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def na_analysis(date1,date2):\n",
    "#     print('Start Date: '+str(date1)+' End Date: '+str(date2))\n",
    "#     x=df[(df['curated_date'].astype(str)>=date1)&(df['curated_date'].astype(str)<=date2)]\n",
    "#     print('Total curated on this day: '+str(len(x)))\n",
    "#     nine_thirteen=na[(na['curated_date'].astype(str)>=date1)&(na['curated_date'].astype(str)<=date2)]\n",
    "#     print('Total N/A values this day:'+str(len(nine_thirteen)))\n",
    "#     print('Percent N/A: '+str(round((len(nine_thirteen))/(len(x))*100,2))+ '%')\n",
    "#     print(nine_thirteen['buckets'].explode().value_counts()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1='2022-01-11'\n",
    "# date2='2022-01-13'\n",
    "# na_analysis(date1,date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df[(df['attribute'].astype(str)=='fabric_weight_type')&(df['resolution'].astype(str)!='rules')]))\n",
    "# df[(df['attribute'].astype(str)=='fabric_weight_type')&(df['resolution'].astype(str)!='rules')][0:500]#['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1='2021-12-17'\n",
    "# date2='2021-12-19'\n",
    "# na_analysis(date1,date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1='2021-11-14'\n",
    "# date2='2021-11-15'\n",
    "# na_analysis(date1,date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1='2021-11-14'\n",
    "# date2='2021-11-15'\n",
    "# na_analysis(date1,date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1='2021-11-15'\n",
    "# date2='2021-11-16'\n",
    "# na_analysis(date1,date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1='2021-11-20'\n",
    "# date2='2021-11-20'\n",
    "# na_analysis(date1,date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1='2021-11-22'\n",
    "# date2='2021-11-22'\n",
    "# na_analysis(date1,date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1='2021-11-29'\n",
    "# date2='2021-12-04'\n",
    "# na_analysis(date1,date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1='2021-12-06'\n",
    "# date2='2021-12-06'\n",
    "# na_analysis(date1,date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(bb[(bb['value'].astype(str)=='n/a')&(bb['attribute'].astype(str)=='material')]))\n",
    "# bb[(bb['value'].astype(str)=='n/a')&(bb['attribute'].astype(str)=='material')]['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb=df[(df['curated_date'].astype(str)>'2021-11-29')&(df['curated_date'].astype(str)<'2021-12-01')]\n",
    "# print(bb['curated_date'].explode().value_counts())\n",
    "# print(len(bb))\n",
    "# bb['curation_tasks.curated_by'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(bb[(bb['curation_tasks.curated_by'].astype(str)!='762.0')]))\n",
    "# print(len(bb[(bb['curation_tasks.curated_by'].astype(str)!='762.0')&(bb['value'].astype(str)=='n/a')&(bb['buckets'].astype(str)=='Rugs & Mats')]))\n",
    "# bb[(bb['curation_tasks.curated_by'].astype(str)!='762.0')&(bb['value'].astype(str)=='n/a')&(bb['buckets'].astype(str)=='Rugs & Mats')]['attribute'].explode().value_counts()[0:500]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "from ftfy import fix_text\n",
    "# from util import UnitConversion, mapping_list_values, perl_to_posix\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_rows = 500\n",
    "from flashtext import KeywordProcessor\n",
    "from groupby_toolz import enrich_db, gcloud\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import ast\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "def query_from_file(file_name, params):\n",
    "    with open(f'{file_name}', mode='r') as f:\n",
    "        text = f.read()\n",
    "        query = text.format(**params)\n",
    "        return enrich_db(query)\n",
    "def re_extract(pattern, txt):\n",
    "    matches = re.findall(pattern, txt)\n",
    "    tmp_matches = []\n",
    "    for match in matches:\n",
    "        for tup in match:\n",
    "            if tup != '':\n",
    "                tmp_matches.append(tup)\n",
    "    return list(set(tmp_matches))\n",
    "from natsort import natsorted\n",
    "import ast\n",
    "def remove_duplicates(A):\n",
    "    [A.pop(count) for count,elem in enumerate(A) if A.count(elem)!=1]\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "formatted_attribute = 'weight'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "df = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "formatted_attribute = 'material'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "df = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['value'].astype(str)=='Fabric']['buckets'].explode().value_counts()\n",
    "fabric=df[df['value'].astype(str)=='Fabric']\n",
    "fab=fabric[(fabric['buckets'].astype(str)=='Travel Pillows')|(fabric['buckets'].astype(str)=='Tablecloths & Table Runners')].sort_values('resolution')\n",
    "print(len(fab))\n",
    "fab[curation_col]='n/a'\n",
    "match_fab=fab[['external_id',curation_col]]\n",
    "match_fab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyester=df[(df['value'].astype(str)=='Polyester')&(df['buckets'].astype(str)=='Travel Pillows')]\n",
    "print(len(polyester))\n",
    "pat=r'(?i)(microplush)|(microfiber)|()'\n",
    "polyester['matches']=polyester['long_desc'].apply(lambda x: re_extract(pat, x))\n",
    "print(len(polyester[polyester['matches'].astype(str)!='[]']))\n",
    "poly=polyester[polyester['matches'].astype(str)!='[]']\n",
    "poly[curation_col]='n/a'\n",
    "match_poly=poly[['external_id',curation_col]]\n",
    "match_poly\n",
    "poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend=df[(df['value'].astype(str)=='Polyester')]\n",
    "print(len(blend))\n",
    "pat=r'(?i)(\\d+(?<!100)\\s?\\%\\spolyester)|()'\n",
    "blend['matches']=blend['long_desc'].apply(lambda x: re_extract(pat, x))\n",
    "print(len(blend[blend['matches'].astype(str)!='[]']))\n",
    "bl=blend[blend['matches'].astype(str)!='[]']\n",
    "bl[curation_col]='Blend'\n",
    "match_bl=bl[['external_id',curation_col]]\n",
    "match_bl\n",
    "bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linen=df[(df['buckets'].astype(str)=='Tablecloths & Table Runners')]\n",
    "pat=r'(?i)(.{0,20}linen.{0,20})|()'\n",
    "linen['matches']=linen['long_desc'].apply(lambda x: re_extract(pat, x))\n",
    "\n",
    "pat_value=r'(?i)(linen)|()'\n",
    "linen['matches_value']=linen['value'].apply(lambda x: re_extract(pat_value, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin=linen[(linen['matches'].astype(str)!='[]')&(linen['matches_value'].astype(str)=='[]')]\n",
    "lin['match']=lin['value'].apply(lambda x: re.sub(r'Burlap(?!\")','[\"Burlap\",Linen\"]',str(x))).apply(lambda x: re.sub(r'Fabric(?!\")','[\"Fabric\",\"Linen\"]',str(x))).apply(lambda x: re.sub(r'Natural Material(?!\")','[\"Linen\",\"Natural Material\"]',str(x))).apply(lambda x: re.sub(r'n/a','Linen',str(x)))\n",
    "lin['match']=lin['match'].apply(lambda x: re.sub(r'(?i)Leather(?!\")','[\"Leather\",\"Linen\"]',str(x))).apply(lambda x: re.sub(r'(?i)Rubber(?!\")','[\"Rubber\",\"Linen\"]',str(x))).apply(lambda x: re.sub(r'(?i)Polyester(?!\")','[\"Linen\",\"Polyester\"]',str(x))).apply(lambda x: re.sub(r'(?i)Cotton(?!\")','[\"Cotton\",\"Linen\"]',str(x)))#.apply(lambda x: re.sub(r'\"Cotton(?=\")','Cotton\",\"Linen\"',str())).apply(lambda x: re.sub(r'Cotton(?!\")(?!\"\\,)(?!\\\"\\])','[\"Cotton\",\"Linen\"]',str())).apply(lambda x: re.sub(r'Polyester(?!\")(?!\"\\,)(?!\\\"\\])','[\"Polyester\",\"Linen\"]',str())).apply(lambda x: re.sub(r'\"Polyester(?=\")','\"Linen\",\"Polyester',str()))                                         \n",
    "print(len(lin))\n",
    "lin['match'].explode().value_counts()\n",
    "match_lin=lin[['external_id','match']]\n",
    "match_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "print(get_df_name(match_fab))\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "print(get_df_name(match_poly))\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "print(get_df_name(match_bl))\n",
    "\n",
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "print(get_df_name(match_lin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, attribute, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/BBBY - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/BBBY - {attribute}-{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', attribute, df, match_fab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, attribute, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/BBBY - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/BBBY - {attribute}-{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', attribute, df, match_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, attribute, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/BBBY - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/BBBY - {attribute}-{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', attribute, df, match_bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, attribute, df, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/BBBY - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/BBBY - {attribute}-{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', attribute, df, match_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "formatted_attribute = 'weight'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "df = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern = r\"(?i)((?<!supports)(?<!minimum)(?<!light)(?<!max)(?<!maximum)(?<!maximum child)(?<!accommodates)\\sweighs?(?!t\\scapacity)(?!ing)\\s?\\d+\\.?\\d*\\s?lb)|()\"               \n",
    "df['matches'] = df['long_desc'].apply(lambda x: re_extract(regex_pattern, str(x)))\n",
    "df['matches']=df['matches'].apply(lambda x: re.sub(r'\\[\\]','n/a',str(x))).apply(lambda x: re.sub(r'''(?i)Weighs?\\s?|\\['|'\\]''','',str(x)))\n",
    "matchdf=df[['attribute','external_id','name','long_desc','buckets','curated_date','matches']]\n",
    "matchdf.to_csv('WeightML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(df)):\n",
    "#     if df['matches'][i]!=df['value'][i]:\n",
    "#         print(df['external_id'][i])\n",
    "# # df[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "formatted_attribute = 'diameter'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "df = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=r'''(?i)(\\d+\\.\\d+.?.?.?Diam?e?t?e?r?\\b)|(\\d+.?\\d+\\/\\d+.?.?.?Diam?e?t?e?r?\\b)|((?<!\\.)(?<!\\/)\\d+(?!\\.\\d).?.?.?Diam?e?t?e?r?\\b)|((?<!\\.)(?<!\\/)\\d+(?!\\.).?.?.?Diam?e?t?e?r?\\b)|(\\d+\\.?\\d*.Inch Round)|()'''\n",
    "# pat_name=r'''(?i)(\\d+\\.?\\d*.Inch Round)|()'''\n",
    "df['matches'] = df['long_desc'].apply(lambda x: re_extract(pat, str(x)))\n",
    "# df['matches_name'] = df['name'].apply(lambda x: re_extract(pat, str(x)))\n",
    "df['matches']=df['matches'].apply(lambda x: re.sub(r'\\[\\]','n/a',str(x))).apply(lambda x: re.sub(r'''(?i)Diameter?\\s?|\\['|'\\]''','',str(x))).apply(lambda x: re.sub(r'\\\\{0,3}\"',' in',str(x))).apply(lambda x: re.sub(r\"'\\,'\",',',str(x)))\n",
    "df.to_csv('Data/diameterML')\n",
    "# matchdf=df[['attribute','external_id','name','long_desc','buckets','curated_date','matches']]\n",
    "# matchdf.to_csv('diameterML.csv')\n",
    "# df[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "formatted_attribute = 'length'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "df = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern = r\"(?i)(?<!cord.measures )(?<!capacity )((?<!\\.)(?<!\\-)(?<!\\d)(?<!\\,)\\d{1,3}(?!\\d)(?:(?:\\-?\\s?\\d+\\/\\d+)?(?:\\.\\d+)?)?\\\\?(?:(?:\")?(?:â€)?(?:'{0,2})?(?:\\Winc?h?e?s?)?(?:\\Wft)?(?:\\Wfoot)?)\\WL(?:ength|ong(?! rows)(?! lasting)(?! sleeves))?\\b)|((?:l(?:ength)?|long(?! rows)):\\s?\\d+\\s?inc?h?e?s?)|(Le?n?g?t?h?\\:\\s?10\\s?in)|((?<!\\.)(?<!\\/)\\d+(?!\\.).{0,3}\\b(?:l(?:ength))\\b)|()\"               \n",
    "df['matches'] = df['long_desc'].apply(lambda x: re_extract(regex_pattern, str(x)))\n",
    "df['matches']=df['matches'].apply(lambda x: re.sub(r'\\[\\]','n/a',str(x))).apply(lambda x: re.sub(r'''(?i)Weighs?\\s?|\\['|'\\]''','',str(x)))\n",
    "matchdf=df[['attribute','external_id','name','long_desc','buckets','curated_date','matches']]\n",
    "matchdf.to_csv('LengthML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(len(df))\n",
    "df_none=df[df['buckets'].astype(str)=='None']\n",
    "print(len(df_none))\n",
    "df=df[df['buckets'].astype(str)!='None']\n",
    "print(len(df))\n",
    "df_na=df[df['value'].astype(str)=='n/a']\n",
    "print(len(df_na))\n",
    "df_new=df[df['value'].astype(str)!='n/a']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern_length=r'(?i)\\d\\DLi?t?e?r?|()'         \n",
    "df['matches'] = df['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "df[df['matches'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['value'].astype(str)!='n/a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern_length=r'(?i).{0,40}(water.?proof).{0,40}|()'         \n",
    "df['matches'] = df['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "print(len(df))\n",
    "df_na=df[df['value'].astype(str)=='n/a']\n",
    "print(len(df_na))\n",
    "df_final=df_na[df_na['matches'].astype(str)!='[]']\n",
    "print(len(df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat='(?i)(^(?=.*?(?:water.?proof(?! liner not included)))(?:(?!never).)*$)|()'\n",
    "df_final['matches'] = df_final['long_desc'].apply(lambda x: re_extract(pat, x))\n",
    "print(len(df_final[df_final['matches'].astype(str)!='[]']))\n",
    "df_proof=df_final[df_final['matches'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proof[curation_col]='Waterproof'\n",
    "match_proof=df_proof[['external_id',curation_col]]\n",
    "match_proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=df_final\n",
    "#Fetch wordcount for each abstract\n",
    "dataset['word_count'] = dataset['long_desc'].apply(lambda x: len(str(x).split(\" \")))\n",
    "dataset[['long_desc','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Descriptive statistics of word counts\n",
    "dataset.word_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify common words\n",
    "freq = pd.Series(' '.join(dataset['long_desc']).split()).value_counts()[:20]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify uncommon words\n",
    "freq1 =  pd.Series(' '.join(dataset \n",
    "         ['long_desc']).split()).value_counts()[-20:]\n",
    "freq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizerlem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()word = \"inversely\"print(\"stemming:\",stem.stem(word))\n",
    "print(\"lemmatization:\", lem.lemmatize(word, \"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer#nltk.download('wordnet') \n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating a list of stop words and adding custom stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))##Creating a list of custom stopwords\n",
    "new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\"]\n",
    "stop_words = stop_words.union(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(len(dataset['long_desc'])):\n",
    "    #Remove punctuations\n",
    "    text = re.sub('[^a-zA-Z]', ' ', dataset['long_desc'][0:i])\n",
    "    \n",
    "    #Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    ##Convert to list from string\n",
    "    text = text.split()\n",
    "    \n",
    "    ##Stemming\n",
    "    ps=PorterStemmer()    #Lemmatisation\n",
    "    lem = WordNetLemmatizer()\n",
    "    text = [lem.lemmatize(word) for word in text if not word in  \n",
    "            stop_words] \n",
    "    text = \" \".join(text)\n",
    "    corpus.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "cv = CountVectorizer(stop_words='english') \n",
    "cv_matrix = cv.fit_transform(df_final['long_desc'][0:100]) \n",
    "# create document term matrix\n",
    "df_dtm = pd.DataFrame(cv_matrix.toarray(), columns=cv.get_feature_names())\n",
    "df_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[*df_dtm][71:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# df_dtm.plot(kind='bar')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(stop_words='english') \n",
    "# cv_matrix = cv.fit_transform(df_final['long_desc'][0:100]) \n",
    "# # create document term matrix\n",
    "# df_dtm = pd.DataFrame(cv_matrix.toarray(), columns=cv.get_feature_names())\n",
    "# df_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern_length=r'(?i)(^(?=.*?(?:(?<!use a )water.?resistant(?! liner not included)))(?:(?!never).)*$)|()'         \n",
    "df['matches'] = df['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "print(len(df))\n",
    "df_na=df[df['value'].astype(str)=='n/a']\n",
    "print(len(df_na))\n",
    "df_final_resist=df_na[df_na['matches'].astype(str)!='[]']\n",
    "print(len(df_final_resist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_resist[curation_col]='Water Resistant'\n",
    "match_resist=df_final_resist[['external_id',curation_col]]\n",
    "match_resist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "formatted_attribute = 'Care'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "#           'buckets': str(buckets.split('\\t'))[1:-1],\n",
    "#           'value':value,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "care = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "\n",
    "print(len(care))\n",
    "cares=care[care['buckets'].astype(str)=='None']\n",
    "print(len(cares))\n",
    "care=care[care['buckets'].astype(str)!='None']\n",
    "care['bucket_id']=care['bucket_id'].astype(int)\n",
    "print(len(care))\n",
    "care_na=care[care['value'].astype(str)=='n/a']\n",
    "print(len(care_na))\n",
    "care.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throws=care[care['buckets'].astype(str)=='Throw/Decorative Pillows']\n",
    "# print(len(throws[throws['value'].astype(str)=='n/a']))\n",
    "throw_na=throws[throws['value'].astype(str)=='n/a']\n",
    "throw_na[curation_col]=''\n",
    "match_throw_na=throw_na[['external_id',curation_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(throws))\n",
    "regex_pat=r'(?i)(tumble.?dry)|()'  \n",
    "throws['matches'] = throws['long_desc'].apply(lambda x: re_extract(regex_pat, x))\n",
    "throws['matches'].explode().value_counts()\n",
    "throws[throws['matches'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['Percent N/A']>=0.9]['Bucket Id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_list=list(set(care['bucket_id']))\n",
    "df = pd.DataFrame([bucket_list[i], len(care[care['bucket_id']==bucket_list[i]]), round(len(care_na[care_na['bucket_id']==bucket_list[i]])/len(care[care['bucket_id']==bucket_list[i]]),2)] for i in range(len(bucket_list)))\n",
    "df.rename({0: \"Bucket Id\", 1: \"Length\", 2: \"Percent N/A\"}, axis='columns', inplace =True)\n",
    "df.sort_values(by=['Percent N/A'], ascending=False, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pat=r'(?i)(professional upholstery)|(spot.?clean)|(vacuum)|(wipe.?clean)|(air.?dry)|(dry.?clean)|(spot.?clean)|()'  \n",
    "care_na['done'] = care_na['long_desc'].apply(lambda x: re_extract(regex_pat, x))\n",
    "print(len(care_na))\n",
    "care_na=care_na[care_na['done'].astype(str)=='[]']\n",
    "print(len(care_na))\n",
    "del care_na['done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex_pattern_length=r'(?i)(professional upholstery)|(spot clean)|(vacuum)|(wipe clean)|(air dry)|(dry clean)|(tumble dry)||(washable)|(dishwasher safe)|(disposable)|(detergent safe)|(dry clean)|(gentle wash)|(hand wash)|(line dry)|(machine washable)|()'  \n",
    "# care_na['matches'] = care_na['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "# td_care_na=care_na[care_na['matches'].astype(str)!='[]']\n",
    "# td_care_na['matches']=td_care_na['matches'].apply(lambda x: x.capitalize())\n",
    "# td_care_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(td_care_na))\n",
    "td_care_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (?i)|(professional upholstery)|(.{0,20}removable.{0,20})|(spot.?clean)|(.{0,20}steam.{0,20})|(.{0,20}tumble.?dry.{0,20})|(vacuum)|(.{0,20}washable.{0,20})|(.{0,20}wipe.?clean.{0,20})|(air.?dry)|(.{0,20}dishwasher.{0,20})|(.{0,20}disposable.{0,20})|(.{0,20}detergent.{0,20})|(dry.?clean)|(.{0,20}gentle.{0,20})|(.{0,20}hand.?wash)|(.{0,20}line.?dry.{0,20})|(.{0,20}machine.?wash.{0,20})\n",
    "regex_pattern_length=r'(?i)(.{0,20}tumble.?dry.{0,20})|(.{0,20}washable.{0,20})|(.{0,20}dishwasher.{0,20})|(.{0,20}disposable.{0,20})|(.{0,20}detergent.{0,20})|(dry.?clean)|(.{0,20}gentle.?wash.{0,20})|(.{0,20}hand.?wash)|(.{0,20}line.?dry.{0,20})|(.{0,20}machine.?wash.{0,20})|()'  \n",
    "care_na['matches'] = care_na['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "print(len(care_na))\n",
    "print(len(care_na[care_na['matches'].astype(str)=='[]']))\n",
    "print(len(care_na[care_na['matches'].astype(str)!='[]']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "care_na[care_na['matches'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_match=care_na[care_na['matches'].astype(str)=='[]']\n",
    "print(len(no_match[no_match['buckets'].astype(str)!='None']))\n",
    "no_match[no_match['buckets'].astype(str)!='None'][500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern_length=r'(?i)(.{0,40}garden.?hose.{0,40})|()'  \n",
    "no_match['matchez'] = no_match['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "no_match[no_match['matchez'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern_length=r'(?i)(.{0,40}non.?skid.?pad.{0,40})|(.{0,40}assembly.?required.{0,40})|(.{0,40}garden.?hose.{0,40})|()'  \n",
    "no_match['matchez'] = no_match['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "print(len(no_match[no_match['matchez'].astype(str)!='[]']))\n",
    "no_match['matchez'].explode().value_counts()[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooktop Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric, glass top, gas, and induction.  \n",
    "\n",
    "customer_id = '5'\n",
    "formatted_attribute = 'Cooktop Compatibility'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "#           'buckets': str(buckets.split('\\t'))[1:-1],\n",
    "#           'value':value,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "cooktop = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "print(len(cooktop))\n",
    "cooktop.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern_length=r'(?i)(all.?stove.?types)|(on all types of stove.?tops)|(on all stove.?tops)|(with all stove.?tops)|(for all stove.?tops)|(with all stove.?tops)|(will all stove.?tops)|(with all cooking surfaces)|(no matter what heat source)|(with all heati?n?g? sources)|(on any heat source)|(All range capable)|(on all heat sources)|()'  \n",
    "cooktop['matches'] = cooktop['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "cooktop_final=cooktop[cooktop['matches'].astype(str)!='[]']\n",
    "cooktop_final[curation_col]=\"Electric,Gas,Glass Top,Induction\"\n",
    "cooktop_final[curation_col]=cooktop_final[curation_col].apply(lambda x: str(f'[\"{x}\"]')).apply(lambda x: re.sub(r',','\",\"',str(x)))\n",
    "matches_final=cooktop_final[['external_id',curation_col]]\n",
    "print(len(matches_final))\n",
    "# matches_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_df=cooktop[cooktop['matches'].astype(str)=='[]']\n",
    "regex_pattern_length=r'(?i)(electric.(?!.{0,20}kettle)(?!Casserole)(?!Wok)(?!Non.?Stick))|(glass.(?:(?:top)|(?:cook.?top)|(?:stove.?top))+)|(gas\\b)|((?<!non)(?<!except.)induction)|(gas and electric stovetops)|(glass.?stove.?top)|()' \n",
    "next_df['matchez'] = next_df['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "indiv=next_df[next_df['matchez'].astype(str)!='[]']\n",
    "print(len(indiv))\n",
    "\n",
    "indiv['matchez']=indiv['matchez'].apply(lambda x: str(x).title()).apply(lambda x: re.sub(r' ','',str(x))).apply(lambda x: re.sub(r\"','\",'\",\"',str(x))).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x)))                                                    \n",
    "indiv['matchez']=indiv['matchez'].apply(lambda x: remove_duplicates([n.strip() for n in ast.literal_eval(x)]))\n",
    "indiv['matchez']=indiv['matchez'].apply(lambda x: sorted(x))\n",
    "indiv['matchez']=indiv['matchez'].apply(lambda x: str(x).title()).apply(lambda x: re.sub(r' ','',str(x))).apply(lambda x: re.sub(r\"','\",'\",\"',str(x))).apply(lambda x: re.sub(r\"\\['\",'[\"',str(x))).apply(lambda x: re.sub(r\"'\\]\",'\"]',str(x))).apply(lambda x: re.sub(r\"(?i)stove.?top|cooktop\",' Top',str(x))).apply(lambda x: re.sub(r\"(?i)glasstop\",'Glass Top',str(x))).apply(lambda x: re.sub(r',\",\"','\",\"',str(x))).apply(lambda x: re.sub(r'\\.','',str(x)))\n",
    "indiv[curation_col]=indiv['matchez']\n",
    "\n",
    "matches_indiv=indiv[['external_id',curation_col]]\n",
    "matches_indiv.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(last))\n",
    "last[curation_col]=''\n",
    "match_last=last[['external_id',curation_col]]\n",
    "# match_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(next_df[(next_df['matchez'].astype(str)=='[]')&(next_df['matches'].astype(str)=='[]')]))\n",
    "last=next_df[(next_df['matchez'].astype(str)=='[]')&(next_df['matches'].astype(str)=='[]')]\n",
    "regex_pattern_length=r'(?i)(electric)|(glass)|(gas\\b)|(induction)|(gas and electric stovetops)|(glass.?stove.?top)|()' \n",
    "last['matches'] = last['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "# last[last['matches'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "formatted_attribute = 'Material'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_').replace('/','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "#           'buckets': str(buckets.split('\\t'))[1:-1],\n",
    "#           'value':value,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "material = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "print(len(material))\n",
    "material.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern_length=r'(?i)(Polypropylene)|()' \n",
    "material['matches'] = material['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "print(len(material[material['matches'].astype(str)!='[]']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly=material[material['buckets'].astype(str)=='Rugs & Mats B']\n",
    "regex_pattern_length=r'(?i)(Polypropylene)|()' \n",
    "poly['matches'] = poly['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "poly[poly['matches'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polypropylene=poly[poly['matches'].astype(str)!='[]']\n",
    "print(len(polypropylene))\n",
    "polypropylene[curation_col]='Polypropylene'\n",
    "match_poly=polypropylene[['external_id',curation_col]]\n",
    "polypropylene[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material=material[material['buckets'].astype(str)=='Prints, Posters, & Paintings']\n",
    "material['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " material_an=material[material['value'].astype(str)=='n/a']\n",
    "print(len(material_an))\n",
    "pat_canvas='(?i)(canvas)|()'  \n",
    "material_an['canvas'] = material_an['long_desc'].apply(lambda x: re_extract(pat_canvas, x))\n",
    "material_an=material_an[material_an['canvas'].astype(str)!='[]']\n",
    "# print(len(material_an))\n",
    "# pat_indoorr='(?i)|(polystyrene)|(glass)|((?<!\\/)wood\\b.{0,10}frame(?!\\/))|(paper\\b)|()'  \n",
    "# material_an['matches'] = material_an['long_desc'].apply(lambda x: re_extract(pat_indoorr, x))\n",
    "# print(len(material_an[material_an['matches'].astype(str)=='[]']))\n",
    "# material_an[material_an['matches'].astype(str)!='[]'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_an[curation_col]='Canvas'\n",
    "match_canvas=material_an[['external_id',curation_col]]\n",
    "match_canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mount Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_id = '5'\n",
    "# formatted_attribute = 'Mount Type'\n",
    "# attribute = formatted_attribute.lower().replace(' ','_').replace('-','_').replace('/','_')\n",
    "# customer_name='%bedbathandbeyond%'\n",
    "\n",
    "# params = {'customer_id': customer_id ,\n",
    "#           'attribute': attribute,\n",
    "# #           'buckets': str(buckets.split('\\t'))[1:-1],\n",
    "# #           'value':value,\n",
    "#           'customer_name':customer_name\n",
    "#          }\n",
    "# curation_col = f'Q:{attribute}'\n",
    "# mount = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "# print(len(mount))\n",
    "# mount.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pat_indoorr='(?i)(freestanding)|()'  \n",
    "# mount['matches'] = mount['value'].apply(lambda x: re_extract(pat_indoorr, x))\n",
    "# mount_type=mount[mount['matches'].astype(str)!='[]']\n",
    "# mount_type['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(mount_type[(mount_type['buckets'].astype(str)=='Shelves & Shelving Units')]))\n",
    "# mount_type[(mount_type['buckets'].astype(str)=='Shelves & Shelving Units')][0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "formatted_attribute = 'Light Filtration'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_').replace('/','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "#           'buckets': str(buckets.split('\\t'))[1:-1],\n",
    "#           'value':value,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "light = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "print(len(light))\n",
    "light.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_bath='(?i)(.{0,40}blackout.{0,40})|()'  \n",
    "light['matches'] = light['long_desc'].apply(lambda x: re_extract(pat_bath, x))\n",
    "black=light[light['matches'].astype(str)!='[]']\n",
    "blackout_df=black[black['value'].astype(str)=='Room Darkening']\n",
    "blackout_df['value'].explode().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blackout_df[curation_col]='[\"Blackout\",\"Room Darkening\"]'\n",
    "# match_bo=blackout_df[['external_id',curation_col]]\n",
    "# match_bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_bath='(?i)(.{0,40}Room.?Darkening.{0,40})|()'  \n",
    "light['matches'] = light['long_desc'].apply(lambda x: re_extract(pat_bath, x))\n",
    "room=light[light['matches'].astype(str)!='[]']\n",
    "room_darkening=room[(room['value']!='Room Darkening')&(room['value']!='[\"Blackout\",\"Room Darkening\"]')&(room['value']!='[\"Blackout\",\"Room Darkening\",\"Sheer\"]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(room_darkening))\n",
    "blackout=room_darkening[room_darkening['value'].astype(str)=='Blackout']\n",
    "na=room_darkening[room_darkening['value'].astype(str)=='n/a']\n",
    "bo_lf=room_darkening[room_darkening['value'].astype(str)=='[\"Blackout\",\"Light Filtering\"]']\n",
    "sheer=room_darkening[room_darkening['value'].astype(str)=='Sheer']\n",
    "light_filtering=room_darkening[room_darkening['value'].astype(str)=='Light Filtering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# light_filtering[curation_col]='[\"Light Filtering\",\"Room Darkening\"]'\n",
    "# match_lf=light_filtering[['external_id',curation_col]]\n",
    "# match_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheer[curation_col]='[\"Room Darkening\",\"Sheer\"]'\n",
    "# match_sheer=sheer[['external_id',curation_col]]\n",
    "# match_sheer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bo_lf[curation_col]='[\"Blackout\",\"Light Filtering\",\"Room Darkening\"]'\n",
    "# match_bolf=bo_lf[['external_id',curation_col]]\n",
    "# match_bolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blackout[curation_col]='[\"Blackout\",\"Room Darkening\"]'\n",
    "# match_blackout=blackout[['external_id',curation_col]]\n",
    "# match_blackout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na[curation_col]='Room Darkening'\n",
    "# match_na=na[['external_id',curation_col]]\n",
    "# match_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indoor Outdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = '5'\n",
    "formatted_attribute = 'indoor_outdoor'\n",
    "attribute = formatted_attribute.lower().replace(' ','_').replace('-','_').replace('/','_')\n",
    "customer_name='%bedbathandbeyond%'\n",
    "\n",
    "params = {'customer_id': customer_id ,\n",
    "          'attribute': attribute,\n",
    "#           'buckets': str(buckets.split('\\t'))[1:-1],\n",
    "#           'value':value,\n",
    "          'customer_name':customer_name\n",
    "         }\n",
    "curation_col = f'Q:{attribute}'\n",
    "indoor = query_from_file(file_name='../query/curated_products_VBOutDiamMM_buckets.sql', params=params)\n",
    "print(len(indoor))\n",
    "indoor.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indoor['buckets'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window=room[room['buckets'].astype(str)=='Window Blinds']\n",
    "# print(len(window))\n",
    "# window['value'].explode().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(window[window['value'].astype(str)=='Indoor & Outdoor']))\n",
    "# indoor_outdoor=window[window['value'].astype(str)=='Indoor & Outdoor']\n",
    "# # indoor_outdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdoor=window[window['value'].astype(str)=='Outdoor']\n",
    "# outdoor[curation_col]='n/a'\n",
    "# match_outdoor=outdoor[['external_id',curation_col]]\n",
    "# match_outdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indoor_out=window[window['value'].astype(str)=='Indoor & Outdoor']\n",
    "indoor_out[curation_col]='n/a'\n",
    "match_in_out=indoor_out[['external_id',curation_col]]\n",
    "# match_in_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern_length=r'(?i)(water.?resistant)|(water.?proof)|()'  \n",
    "indoor['water'] = indoor['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "print(len(indoor[indoor['water'].astype(str)!='[]']))\n",
    "water=indoor[indoor['water'].astype(str)!='[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_idod=water[water['value'].astype(str)=='Indoor & Outdoor']\n",
    "print(len(water_idod[(water_idod['buckets'].astype(str)=='Tablecloths & Table Runners')|(water_idod['buckets'].astype(str)=='Rugs & Mats')|(water_idod['buckets'].astype(str)=='Rugs & Mats B')]))\n",
    "tc_rm=water_idod[(water_idod['buckets'].astype(str)=='Tablecloths & Table Runners')|(water_idod['buckets'].astype(str)=='Rugs & Mats')]\n",
    "print(len(water_idod[(water_idod['buckets'].astype(str)!='Tablecloths & Table Runners')&(water_idod['buckets'].astype(str)!='Rugs & Mats')]))\n",
    "# water_idod[(water_idod['buckets'].astype(str)!='Tablecloths & Table Runners')&(water_idod['buckets'].astype(str)!='Rugs & Mats')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_na=water[water['value'].astype(str)=='n/a']\n",
    "curtain=water_na[water_na['buckets'].astype(str)=='Curtains']\n",
    "regex_pattern_length=r'(?i)(shower)|(bath)|()'  \n",
    "curtain['curtain'] = curtain['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "curtain[curtain['curtain'].astype(str)=='[]']\n",
    "# curtain\n",
    "water_office=water[water['buckets'].astype(str)=='Office Chairs']\n",
    "print(len(water_office))\n",
    "# water_office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(water_idod[(water_idod['buckets'].astype(str)=='Tablecloths & Table Runners')|(water_idod['buckets'].astype(str)=='Rugs & Mats')|(water_idod['buckets'].astype(str)=='Rugs & Mats B')]))\n",
    "rugs=water[(water['buckets'].astype(str)=='Tablecloths & Table Runners')|(water['buckets'].astype(str)=='Rugs & Mats')|(water['buckets'].astype(str)=='Rugs & Mats B')]\n",
    "regex_pattern_length=r'(?i)(indoor.{0,10}outdoor)|(table.?cloth)|()'  \n",
    "rugs['indoor'] = rugs['long_desc'].apply(lambda x: re_extract(regex_pattern_length, x))\n",
    "regex_pattern_area=r'(?i)(area.?rug)|(runner)|(kitchen)|(bath)|(anti.?fatigue)|(accent)|(shower)|()'  \n",
    "# rugs['area'] = rugs['name'].apply(lambda x: re_extract(regex_pattern_area, x))\n",
    "# rugs=rugs[(rugs['area'].astype(str)=='[]')]\n",
    "print(len(rugs[(rugs['indoor'].astype(str)=='[]')&(rugs['value'].astype(str)!='Outdoor')]))\n",
    "# rugs[(rugs['indoor'].astype(str)=='[]')&(rugs['value'].astype(str)!='Outdoor')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][1]\n",
    "    return name\n",
    "\n",
    "def looks_good(customer, attribute, matches): \n",
    "    drive_path = f'G:/Shared drives/GroupBy Public/Customer Success/.Enrich/Platform Upload Trail/{customer}/_Ready For Upload' \n",
    "#     non_matches = df[df['matches'].astype(str) == '[]']\n",
    "#     non_matches[curation_col] = r'n/a'\n",
    "#     non_matches.to_csv(f'{drive_path}/BBBY - {attribute} - na upload {buckets}.csv',index=False)\n",
    "    matches.to_csv(f'{drive_path}/BBBY - {attribute}-{get_df_name(matches)}-matches.csv',index=False) \n",
    "    \n",
    "looks_good('Bed Bath & Beyond', attribute, match_throw_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
